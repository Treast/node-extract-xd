/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/.pnpm/bl@1.2.3/node_modules/bl/bl.js":
/*!***********************************************************!*\
  !*** ./node_modules/.pnpm/bl@1.2.3/node_modules/bl/bl.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var DuplexStream = __webpack_require__(/*! readable-stream/duplex */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/duplex.js\")\n  , util         = __webpack_require__(/*! util */ \"util\")\n  , Buffer       = (__webpack_require__(/*! safe-buffer */ \"./node_modules/.pnpm/safe-buffer@5.2.1/node_modules/safe-buffer/index.js\").Buffer)\n\n\nfunction BufferList (callback) {\n  if (!(this instanceof BufferList))\n    return new BufferList(callback)\n\n  this._bufs  = []\n  this.length = 0\n\n  if (typeof callback == 'function') {\n    this._callback = callback\n\n    var piper = function piper (err) {\n      if (this._callback) {\n        this._callback(err)\n        this._callback = null\n      }\n    }.bind(this)\n\n    this.on('pipe', function onPipe (src) {\n      src.on('error', piper)\n    })\n    this.on('unpipe', function onUnpipe (src) {\n      src.removeListener('error', piper)\n    })\n  } else {\n    this.append(callback)\n  }\n\n  DuplexStream.call(this)\n}\n\n\nutil.inherits(BufferList, DuplexStream)\n\n\nBufferList.prototype._offset = function _offset (offset) {\n  var tot = 0, i = 0, _t\n  if (offset === 0) return [ 0, 0 ]\n  for (; i < this._bufs.length; i++) {\n    _t = tot + this._bufs[i].length\n    if (offset < _t || i == this._bufs.length - 1)\n      return [ i, offset - tot ]\n    tot = _t\n  }\n}\n\n\nBufferList.prototype.append = function append (buf) {\n  var i = 0\n\n  if (Buffer.isBuffer(buf)) {\n    this._appendBuffer(buf);\n  } else if (Array.isArray(buf)) {\n    for (; i < buf.length; i++)\n      this.append(buf[i])\n  } else if (buf instanceof BufferList) {\n    // unwrap argument into individual BufferLists\n    for (; i < buf._bufs.length; i++)\n      this.append(buf._bufs[i])\n  } else if (buf != null) {\n    // coerce number arguments to strings, since Buffer(number) does\n    // uninitialized memory allocation\n    if (typeof buf == 'number')\n      buf = buf.toString()\n\n    this._appendBuffer(Buffer.from(buf));\n  }\n\n  return this\n}\n\n\nBufferList.prototype._appendBuffer = function appendBuffer (buf) {\n  this._bufs.push(buf)\n  this.length += buf.length\n}\n\n\nBufferList.prototype._write = function _write (buf, encoding, callback) {\n  this._appendBuffer(buf)\n\n  if (typeof callback == 'function')\n    callback()\n}\n\n\nBufferList.prototype._read = function _read (size) {\n  if (!this.length)\n    return this.push(null)\n\n  size = Math.min(size, this.length)\n  this.push(this.slice(0, size))\n  this.consume(size)\n}\n\n\nBufferList.prototype.end = function end (chunk) {\n  DuplexStream.prototype.end.call(this, chunk)\n\n  if (this._callback) {\n    this._callback(null, this.slice())\n    this._callback = null\n  }\n}\n\n\nBufferList.prototype.get = function get (index) {\n  return this.slice(index, index + 1)[0]\n}\n\n\nBufferList.prototype.slice = function slice (start, end) {\n  if (typeof start == 'number' && start < 0)\n    start += this.length\n  if (typeof end == 'number' && end < 0)\n    end += this.length\n  return this.copy(null, 0, start, end)\n}\n\n\nBufferList.prototype.copy = function copy (dst, dstStart, srcStart, srcEnd) {\n  if (typeof srcStart != 'number' || srcStart < 0)\n    srcStart = 0\n  if (typeof srcEnd != 'number' || srcEnd > this.length)\n    srcEnd = this.length\n  if (srcStart >= this.length)\n    return dst || Buffer.alloc(0)\n  if (srcEnd <= 0)\n    return dst || Buffer.alloc(0)\n\n  var copy   = !!dst\n    , off    = this._offset(srcStart)\n    , len    = srcEnd - srcStart\n    , bytes  = len\n    , bufoff = (copy && dstStart) || 0\n    , start  = off[1]\n    , l\n    , i\n\n  // copy/slice everything\n  if (srcStart === 0 && srcEnd == this.length) {\n    if (!copy) { // slice, but full concat if multiple buffers\n      return this._bufs.length === 1\n        ? this._bufs[0]\n        : Buffer.concat(this._bufs, this.length)\n    }\n\n    // copy, need to copy individual buffers\n    for (i = 0; i < this._bufs.length; i++) {\n      this._bufs[i].copy(dst, bufoff)\n      bufoff += this._bufs[i].length\n    }\n\n    return dst\n  }\n\n  // easy, cheap case where it's a subset of one of the buffers\n  if (bytes <= this._bufs[off[0]].length - start) {\n    return copy\n      ? this._bufs[off[0]].copy(dst, dstStart, start, start + bytes)\n      : this._bufs[off[0]].slice(start, start + bytes)\n  }\n\n  if (!copy) // a slice, we need something to copy in to\n    dst = Buffer.allocUnsafe(len)\n\n  for (i = off[0]; i < this._bufs.length; i++) {\n    l = this._bufs[i].length - start\n\n    if (bytes > l) {\n      this._bufs[i].copy(dst, bufoff, start)\n      bufoff += l\n    } else {\n      this._bufs[i].copy(dst, bufoff, start, start + bytes)\n      bufoff += l\n      break\n    }\n\n    bytes -= l\n\n    if (start)\n      start = 0\n  }\n\n  // safeguard so that we don't return uninitialized memory\n  if (dst.length > bufoff) return dst.slice(0, bufoff)\n\n  return dst\n}\n\nBufferList.prototype.shallowSlice = function shallowSlice (start, end) {\n  start = start || 0\n  end = end || this.length\n\n  if (start < 0)\n    start += this.length\n  if (end < 0)\n    end += this.length\n\n  var startOffset = this._offset(start)\n    , endOffset = this._offset(end)\n    , buffers = this._bufs.slice(startOffset[0], endOffset[0] + 1)\n\n  if (endOffset[1] == 0)\n    buffers.pop()\n  else\n    buffers[buffers.length-1] = buffers[buffers.length-1].slice(0, endOffset[1])\n\n  if (startOffset[1] != 0)\n    buffers[0] = buffers[0].slice(startOffset[1])\n\n  return new BufferList(buffers)\n}\n\nBufferList.prototype.toString = function toString (encoding, start, end) {\n  return this.slice(start, end).toString(encoding)\n}\n\nBufferList.prototype.consume = function consume (bytes) {\n  // first, normalize the argument, in accordance with how Buffer does it\n  bytes = Math.trunc(bytes)\n  // do nothing if not a positive number\n  if (Number.isNaN(bytes) || bytes <= 0) return this\n\n  while (this._bufs.length) {\n    if (bytes >= this._bufs[0].length) {\n      bytes -= this._bufs[0].length\n      this.length -= this._bufs[0].length\n      this._bufs.shift()\n    } else {\n      this._bufs[0] = this._bufs[0].slice(bytes)\n      this.length -= bytes\n      break\n    }\n  }\n  return this\n}\n\n\nBufferList.prototype.duplicate = function duplicate () {\n  var i = 0\n    , copy = new BufferList()\n\n  for (; i < this._bufs.length; i++)\n    copy.append(this._bufs[i])\n\n  return copy\n}\n\n\nBufferList.prototype.destroy = function destroy () {\n  this._bufs.length = 0\n  this.length = 0\n  this.push(null)\n}\n\n\n;(function () {\n  var methods = {\n      'readDoubleBE' : 8\n    , 'readDoubleLE' : 8\n    , 'readFloatBE'  : 4\n    , 'readFloatLE'  : 4\n    , 'readInt32BE'  : 4\n    , 'readInt32LE'  : 4\n    , 'readUInt32BE' : 4\n    , 'readUInt32LE' : 4\n    , 'readInt16BE'  : 2\n    , 'readInt16LE'  : 2\n    , 'readUInt16BE' : 2\n    , 'readUInt16LE' : 2\n    , 'readInt8'     : 1\n    , 'readUInt8'    : 1\n  }\n\n  for (var m in methods) {\n    (function (m) {\n      BufferList.prototype[m] = function (offset) {\n        return this.slice(offset, offset + methods[m])[m](0)\n      }\n    }(m))\n  }\n}())\n\n\nmodule.exports = BufferList\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/bl@1.2.3/node_modules/bl/bl.js?");

/***/ }),

/***/ "./node_modules/.pnpm/buffer-alloc-unsafe@1.1.0/node_modules/buffer-alloc-unsafe/index.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/.pnpm/buffer-alloc-unsafe@1.1.0/node_modules/buffer-alloc-unsafe/index.js ***!
  \************************************************************************************************/
/***/ ((module) => {

eval("function allocUnsafe (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  }\n\n  if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n\n  if (Buffer.allocUnsafe) {\n    return Buffer.allocUnsafe(size)\n  } else {\n    return new Buffer(size)\n  }\n}\n\nmodule.exports = allocUnsafe\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/buffer-alloc-unsafe@1.1.0/node_modules/buffer-alloc-unsafe/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/buffer-alloc@1.2.0/node_modules/buffer-alloc/index.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/.pnpm/buffer-alloc@1.2.0/node_modules/buffer-alloc/index.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var bufferFill = __webpack_require__(/*! buffer-fill */ \"./node_modules/.pnpm/buffer-fill@1.0.0/node_modules/buffer-fill/index.js\")\nvar allocUnsafe = __webpack_require__(/*! buffer-alloc-unsafe */ \"./node_modules/.pnpm/buffer-alloc-unsafe@1.1.0/node_modules/buffer-alloc-unsafe/index.js\")\n\nmodule.exports = function alloc (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  }\n\n  if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n\n  if (Buffer.alloc) {\n    return Buffer.alloc(size, fill, encoding)\n  }\n\n  var buffer = allocUnsafe(size)\n\n  if (size === 0) {\n    return buffer\n  }\n\n  if (fill === undefined) {\n    return bufferFill(buffer, 0)\n  }\n\n  if (typeof encoding !== 'string') {\n    encoding = undefined\n  }\n\n  return bufferFill(buffer, fill, encoding)\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/buffer-alloc@1.2.0/node_modules/buffer-alloc/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/buffer-crc32@0.2.13/node_modules/buffer-crc32/index.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/.pnpm/buffer-crc32@0.2.13/node_modules/buffer-crc32/index.js ***!
  \***********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Buffer = (__webpack_require__(/*! buffer */ \"buffer\").Buffer);\n\nvar CRC_TABLE = [\n  0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419,\n  0x706af48f, 0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4,\n  0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07,\n  0x90bf1d91, 0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de,\n  0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7, 0x136c9856,\n  0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9,\n  0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4,\n  0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n  0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3,\n  0x45df5c75, 0xdcd60dcf, 0xabd13d59, 0x26d930ac, 0x51de003a,\n  0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599,\n  0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,\n  0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190,\n  0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f,\n  0x9fbfe4a5, 0xe8b8d433, 0x7807c9a2, 0x0f00f934, 0x9609a88e,\n  0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n  0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed,\n  0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,\n  0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3,\n  0xfbd44c65, 0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2,\n  0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a,\n  0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5,\n  0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa, 0xbe0b1010,\n  0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n  0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17,\n  0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6,\n  0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615,\n  0x73dc1683, 0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8,\n  0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1, 0xf00f9344,\n  0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb,\n  0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a,\n  0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n  0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1,\n  0xa6bc5767, 0x3fb506dd, 0x48b2364b, 0xd80d2bda, 0xaf0a1b4c,\n  0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef,\n  0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,\n  0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe,\n  0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31,\n  0x2cd99e8b, 0x5bdeae1d, 0x9b64c2b0, 0xec63f226, 0x756aa39c,\n  0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n  0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b,\n  0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242,\n  0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1,\n  0x18b74777, 0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c,\n  0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45, 0xa00ae278,\n  0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7,\n  0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc, 0x40df0b66,\n  0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n  0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605,\n  0xcdd70693, 0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8,\n  0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b,\n  0x2d02ef8d\n];\n\nif (typeof Int32Array !== 'undefined') {\n  CRC_TABLE = new Int32Array(CRC_TABLE);\n}\n\nfunction ensureBuffer(input) {\n  if (Buffer.isBuffer(input)) {\n    return input;\n  }\n\n  var hasNewBufferAPI =\n      typeof Buffer.alloc === \"function\" &&\n      typeof Buffer.from === \"function\";\n\n  if (typeof input === \"number\") {\n    return hasNewBufferAPI ? Buffer.alloc(input) : new Buffer(input);\n  }\n  else if (typeof input === \"string\") {\n    return hasNewBufferAPI ? Buffer.from(input) : new Buffer(input);\n  }\n  else {\n    throw new Error(\"input must be buffer, number, or string, received \" +\n                    typeof input);\n  }\n}\n\nfunction bufferizeInt(num) {\n  var tmp = ensureBuffer(4);\n  tmp.writeInt32BE(num, 0);\n  return tmp;\n}\n\nfunction _crc32(buf, previous) {\n  buf = ensureBuffer(buf);\n  if (Buffer.isBuffer(previous)) {\n    previous = previous.readUInt32BE(0);\n  }\n  var crc = ~~previous ^ -1;\n  for (var n = 0; n < buf.length; n++) {\n    crc = CRC_TABLE[(crc ^ buf[n]) & 0xff] ^ (crc >>> 8);\n  }\n  return (crc ^ -1);\n}\n\nfunction crc32() {\n  return bufferizeInt(_crc32.apply(null, arguments));\n}\ncrc32.signed = function () {\n  return _crc32.apply(null, arguments);\n};\ncrc32.unsigned = function () {\n  return _crc32.apply(null, arguments) >>> 0;\n};\n\nmodule.exports = crc32;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/buffer-crc32@0.2.13/node_modules/buffer-crc32/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/buffer-fill@1.0.0/node_modules/buffer-fill/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/buffer-fill@1.0.0/node_modules/buffer-fill/index.js ***!
  \********************************************************************************/
/***/ ((module) => {

eval("/* Node.js 6.4.0 and up has full support */\nvar hasFullSupport = (function () {\n  try {\n    if (!Buffer.isEncoding('latin1')) {\n      return false\n    }\n\n    var buf = Buffer.alloc ? Buffer.alloc(4) : new Buffer(4)\n\n    buf.fill('ab', 'ucs2')\n\n    return (buf.toString('hex') === '61006200')\n  } catch (_) {\n    return false\n  }\n}())\n\nfunction isSingleByte (val) {\n  return (val.length === 1 && val.charCodeAt(0) < 256)\n}\n\nfunction fillWithNumber (buffer, val, start, end) {\n  if (start < 0 || end > buffer.length) {\n    throw new RangeError('Out of range index')\n  }\n\n  start = start >>> 0\n  end = end === undefined ? buffer.length : end >>> 0\n\n  if (end > start) {\n    buffer.fill(val, start, end)\n  }\n\n  return buffer\n}\n\nfunction fillWithBuffer (buffer, val, start, end) {\n  if (start < 0 || end > buffer.length) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return buffer\n  }\n\n  start = start >>> 0\n  end = end === undefined ? buffer.length : end >>> 0\n\n  var pos = start\n  var len = val.length\n  while (pos <= (end - len)) {\n    val.copy(buffer, pos)\n    pos += len\n  }\n\n  if (pos !== end) {\n    val.copy(buffer, pos, 0, end - pos)\n  }\n\n  return buffer\n}\n\nfunction fill (buffer, val, start, end, encoding) {\n  if (hasFullSupport) {\n    return buffer.fill(val, start, end, encoding)\n  }\n\n  if (typeof val === 'number') {\n    return fillWithNumber(buffer, val, start, end)\n  }\n\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = buffer.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = buffer.length\n    }\n\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n\n    if (encoding === 'latin1') {\n      encoding = 'binary'\n    }\n\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n\n    if (val === '') {\n      return fillWithNumber(buffer, 0, start, end)\n    }\n\n    if (isSingleByte(val)) {\n      return fillWithNumber(buffer, val.charCodeAt(0), start, end)\n    }\n\n    val = new Buffer(val, encoding)\n  }\n\n  if (Buffer.isBuffer(val)) {\n    return fillWithBuffer(buffer, val, start, end)\n  }\n\n  // Other values (e.g. undefined, boolean, object) results in zero-fill\n  return fillWithNumber(buffer, 0, start, end)\n}\n\nmodule.exports = fill\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/buffer-fill@1.0.0/node_modules/buffer-fill/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = __webpack_require__(/*! buffer */ \"buffer\").Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js?");

/***/ }),

/***/ "./node_modules/.pnpm/decompress-tar@4.1.1/node_modules/decompress-tar/index.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/.pnpm/decompress-tar@4.1.1/node_modules/decompress-tar/index.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst fileType = __webpack_require__(/*! file-type */ \"./node_modules/.pnpm/file-type@5.2.0/node_modules/file-type/index.js\");\nconst isStream = __webpack_require__(/*! is-stream */ \"./node_modules/.pnpm/is-stream@1.1.0/node_modules/is-stream/index.js\");\nconst tarStream = __webpack_require__(/*! tar-stream */ \"./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/index.js\");\n\nmodule.exports = () => input => {\n\tif (!Buffer.isBuffer(input) && !isStream(input)) {\n\t\treturn Promise.reject(new TypeError(`Expected a Buffer or Stream, got ${typeof input}`));\n\t}\n\n\tif (Buffer.isBuffer(input) && (!fileType(input) || fileType(input).ext !== 'tar')) {\n\t\treturn Promise.resolve([]);\n\t}\n\n\tconst extract = tarStream.extract();\n\tconst files = [];\n\n\textract.on('entry', (header, stream, cb) => {\n\t\tconst chunk = [];\n\n\t\tstream.on('data', data => chunk.push(data));\n\t\tstream.on('end', () => {\n\t\t\tconst file = {\n\t\t\t\tdata: Buffer.concat(chunk),\n\t\t\t\tmode: header.mode,\n\t\t\t\tmtime: header.mtime,\n\t\t\t\tpath: header.name,\n\t\t\t\ttype: header.type\n\t\t\t};\n\n\t\t\tif (header.type === 'symlink' || header.type === 'link') {\n\t\t\t\tfile.linkname = header.linkname;\n\t\t\t}\n\n\t\t\tfiles.push(file);\n\t\t\tcb();\n\t\t});\n\t});\n\n\tconst promise = new Promise((resolve, reject) => {\n\t\tif (!Buffer.isBuffer(input)) {\n\t\t\tinput.on('error', reject);\n\t\t}\n\n\t\textract.on('finish', () => resolve(files));\n\t\textract.on('error', reject);\n\t});\n\n\textract.then = promise.then.bind(promise);\n\textract.catch = promise.catch.bind(promise);\n\n\tif (Buffer.isBuffer(input)) {\n\t\textract.end(input);\n\t} else {\n\t\tinput.pipe(extract);\n\t}\n\n\treturn extract;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/decompress-tar@4.1.1/node_modules/decompress-tar/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/decompress-tarbz2@4.1.1/node_modules/decompress-tarbz2/index.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/.pnpm/decompress-tarbz2@4.1.1/node_modules/decompress-tarbz2/index.js ***!
  \********************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst decompressTar = __webpack_require__(/*! decompress-tar */ \"./node_modules/.pnpm/decompress-tar@4.1.1/node_modules/decompress-tar/index.js\");\nconst fileType = __webpack_require__(/*! file-type */ \"./node_modules/.pnpm/file-type@6.2.0/node_modules/file-type/index.js\");\nconst isStream = __webpack_require__(/*! is-stream */ \"./node_modules/.pnpm/is-stream@1.1.0/node_modules/is-stream/index.js\");\nconst seekBzip = __webpack_require__(/*! seek-bzip */ \"./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/index.js\");\nconst unbzip2Stream = __webpack_require__(/*! unbzip2-stream */ \"./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/index.js\");\n\nmodule.exports = () => input => {\n\tif (!Buffer.isBuffer(input) && !isStream(input)) {\n\t\treturn Promise.reject(new TypeError(`Expected a Buffer or Stream, got ${typeof input}`));\n\t}\n\n\tif (Buffer.isBuffer(input) && (!fileType(input) || fileType(input).ext !== 'bz2')) {\n\t\treturn Promise.resolve([]);\n\t}\n\n\tif (Buffer.isBuffer(input)) {\n\t\treturn decompressTar()(seekBzip.decode(input));\n\t}\n\n\treturn decompressTar()(input.pipe(unbzip2Stream()));\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/decompress-tarbz2@4.1.1/node_modules/decompress-tarbz2/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/decompress-targz@4.1.1/node_modules/decompress-targz/index.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/decompress-targz@4.1.1/node_modules/decompress-targz/index.js ***!
  \******************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst zlib = __webpack_require__(/*! zlib */ \"zlib\");\nconst decompressTar = __webpack_require__(/*! decompress-tar */ \"./node_modules/.pnpm/decompress-tar@4.1.1/node_modules/decompress-tar/index.js\");\nconst fileType = __webpack_require__(/*! file-type */ \"./node_modules/.pnpm/file-type@5.2.0/node_modules/file-type/index.js\");\nconst isStream = __webpack_require__(/*! is-stream */ \"./node_modules/.pnpm/is-stream@1.1.0/node_modules/is-stream/index.js\");\n\nmodule.exports = () => input => {\n\tif (!Buffer.isBuffer(input) && !isStream(input)) {\n\t\treturn Promise.reject(new TypeError(`Expected a Buffer or Stream, got ${typeof input}`));\n\t}\n\n\tif (Buffer.isBuffer(input) && (!fileType(input) || fileType(input).ext !== 'gz')) {\n\t\treturn Promise.resolve([]);\n\t}\n\n\tconst unzip = zlib.createGunzip();\n\tconst result = decompressTar()(unzip);\n\n\tif (Buffer.isBuffer(input)) {\n\t\tunzip.end(input);\n\t} else {\n\t\tinput.pipe(unzip);\n\t}\n\n\treturn result;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/decompress-targz@4.1.1/node_modules/decompress-targz/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/decompress-unzip@4.0.1/node_modules/decompress-unzip/index.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/decompress-unzip@4.0.1/node_modules/decompress-unzip/index.js ***!
  \******************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst fileType = __webpack_require__(/*! file-type */ \"./node_modules/.pnpm/file-type@3.9.0/node_modules/file-type/index.js\");\nconst getStream = __webpack_require__(/*! get-stream */ \"./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/index.js\");\nconst pify = __webpack_require__(/*! pify */ \"./node_modules/.pnpm/pify@2.3.0/node_modules/pify/index.js\");\nconst yauzl = __webpack_require__(/*! yauzl */ \"./node_modules/.pnpm/yauzl@2.10.0/node_modules/yauzl/index.js\");\n\nconst getType = (entry, mode) => {\n\tconst IFMT = 61440;\n\tconst IFDIR = 16384;\n\tconst IFLNK = 40960;\n\tconst madeBy = entry.versionMadeBy >> 8;\n\n\tif ((mode & IFMT) === IFLNK) {\n\t\treturn 'symlink';\n\t}\n\n\tif ((mode & IFMT) === IFDIR || (madeBy === 0 && entry.externalFileAttributes === 16)) {\n\t\treturn 'directory';\n\t}\n\n\treturn 'file';\n};\n\nconst extractEntry = (entry, zip) => {\n\tconst file = {\n\t\tmode: (entry.externalFileAttributes >> 16) & 0xFFFF,\n\t\tmtime: entry.getLastModDate(),\n\t\tpath: entry.fileName\n\t};\n\n\tfile.type = getType(entry, file.mode);\n\n\tif (file.mode === 0 && file.type === 'directory') {\n\t\tfile.mode = 493;\n\t}\n\n\tif (file.mode === 0) {\n\t\tfile.mode = 420;\n\t}\n\n\treturn pify(zip.openReadStream.bind(zip))(entry)\n\t\t.then(getStream.buffer)\n\t\t.then(buf => {\n\t\t\tfile.data = buf;\n\n\t\t\tif (file.type === 'symlink') {\n\t\t\t\tfile.linkname = buf.toString();\n\t\t\t}\n\n\t\t\treturn file;\n\t\t})\n\t\t.catch(err => {\n\t\t\tzip.close();\n\t\t\tthrow err;\n\t\t});\n};\n\nconst extractFile = zip => new Promise((resolve, reject) => {\n\tconst files = [];\n\n\tzip.readEntry();\n\n\tzip.on('entry', entry => {\n\t\textractEntry(entry, zip)\n\t\t\t.catch(reject)\n\t\t\t.then(file => {\n\t\t\t\tfiles.push(file);\n\t\t\t\tzip.readEntry();\n\t\t\t});\n\t});\n\n\tzip.on('error', reject);\n\tzip.on('end', () => resolve(files));\n});\n\nmodule.exports = () => buf => {\n\tif (!Buffer.isBuffer(buf)) {\n\t\treturn Promise.reject(new TypeError(`Expected a Buffer, got ${typeof buf}`));\n\t}\n\n\tif (!fileType(buf) || fileType(buf).ext !== 'zip') {\n\t\treturn Promise.resolve([]);\n\t}\n\n\treturn pify(yauzl.fromBuffer)(buf, {lazyEntries: true}).then(extractFile);\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/decompress-unzip@4.0.1/node_modules/decompress-unzip/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/decompress@4.2.1/node_modules/decompress/index.js":
/*!******************************************************************************!*\
  !*** ./node_modules/.pnpm/decompress@4.2.1/node_modules/decompress/index.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst path = __webpack_require__(/*! path */ \"path\");\nconst fs = __webpack_require__(/*! graceful-fs */ \"./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/graceful-fs.js\");\nconst decompressTar = __webpack_require__(/*! decompress-tar */ \"./node_modules/.pnpm/decompress-tar@4.1.1/node_modules/decompress-tar/index.js\");\nconst decompressTarbz2 = __webpack_require__(/*! decompress-tarbz2 */ \"./node_modules/.pnpm/decompress-tarbz2@4.1.1/node_modules/decompress-tarbz2/index.js\");\nconst decompressTargz = __webpack_require__(/*! decompress-targz */ \"./node_modules/.pnpm/decompress-targz@4.1.1/node_modules/decompress-targz/index.js\");\nconst decompressUnzip = __webpack_require__(/*! decompress-unzip */ \"./node_modules/.pnpm/decompress-unzip@4.0.1/node_modules/decompress-unzip/index.js\");\nconst makeDir = __webpack_require__(/*! make-dir */ \"./node_modules/.pnpm/make-dir@1.3.0/node_modules/make-dir/index.js\");\nconst pify = __webpack_require__(/*! pify */ \"./node_modules/.pnpm/pify@2.3.0/node_modules/pify/index.js\");\nconst stripDirs = __webpack_require__(/*! strip-dirs */ \"./node_modules/.pnpm/strip-dirs@2.1.0/node_modules/strip-dirs/index.js\");\n\nconst fsP = pify(fs);\n\nconst runPlugins = (input, opts) => {\n\tif (opts.plugins.length === 0) {\n\t\treturn Promise.resolve([]);\n\t}\n\n\treturn Promise.all(opts.plugins.map(x => x(input, opts))).then(files => files.reduce((a, b) => a.concat(b)));\n};\n\nconst safeMakeDir = (dir, realOutputPath) => {\n\treturn fsP.realpath(dir)\n\t\t.catch(_ => {\n\t\t\tconst parent = path.dirname(dir);\n\t\t\treturn safeMakeDir(parent, realOutputPath);\n\t\t})\n\t\t.then(realParentPath => {\n\t\t\tif (realParentPath.indexOf(realOutputPath) !== 0) {\n\t\t\t\tthrow (new Error('Refusing to create a directory outside the output path.'));\n\t\t\t}\n\n\t\t\treturn makeDir(dir).then(fsP.realpath);\n\t\t});\n};\n\nconst preventWritingThroughSymlink = (destination, realOutputPath) => {\n\treturn fsP.readlink(destination)\n\t\t.catch(_ => {\n\t\t\t// Either no file exists, or it's not a symlink. In either case, this is\n\t\t\t// not an escape we need to worry about in this phase.\n\t\t\treturn null;\n\t\t})\n\t\t.then(symlinkPointsTo => {\n\t\t\tif (symlinkPointsTo) {\n\t\t\t\tthrow new Error('Refusing to write into a symlink');\n\t\t\t}\n\n\t\t\t// No symlink exists at `destination`, so we can continue\n\t\t\treturn realOutputPath;\n\t\t});\n};\n\nconst extractFile = (input, output, opts) => runPlugins(input, opts).then(files => {\n\tif (opts.strip > 0) {\n\t\tfiles = files\n\t\t\t.map(x => {\n\t\t\t\tx.path = stripDirs(x.path, opts.strip);\n\t\t\t\treturn x;\n\t\t\t})\n\t\t\t.filter(x => x.path !== '.');\n\t}\n\n\tif (typeof opts.filter === 'function') {\n\t\tfiles = files.filter(opts.filter);\n\t}\n\n\tif (typeof opts.map === 'function') {\n\t\tfiles = files.map(opts.map);\n\t}\n\n\tif (!output) {\n\t\treturn files;\n\t}\n\n\treturn Promise.all(files.map(x => {\n\t\tconst dest = path.join(output, x.path);\n\t\tconst mode = x.mode & ~process.umask();\n\t\tconst now = new Date();\n\n\t\tif (x.type === 'directory') {\n\t\t\treturn makeDir(output)\n\t\t\t\t.then(outputPath => fsP.realpath(outputPath))\n\t\t\t\t.then(realOutputPath => safeMakeDir(dest, realOutputPath))\n\t\t\t\t.then(() => fsP.utimes(dest, now, x.mtime))\n\t\t\t\t.then(() => x);\n\t\t}\n\n\t\treturn makeDir(output)\n\t\t\t.then(outputPath => fsP.realpath(outputPath))\n\t\t\t.then(realOutputPath => {\n\t\t\t\t// Attempt to ensure parent directory exists (failing if it's outside the output dir)\n\t\t\t\treturn safeMakeDir(path.dirname(dest), realOutputPath)\n\t\t\t\t\t.then(() => realOutputPath);\n\t\t\t})\n\t\t\t.then(realOutputPath => {\n\t\t\t\tif (x.type === 'file') {\n\t\t\t\t\treturn preventWritingThroughSymlink(dest, realOutputPath);\n\t\t\t\t}\n\n\t\t\t\treturn realOutputPath;\n\t\t\t})\n\t\t\t.then(realOutputPath => {\n\t\t\t\treturn fsP.realpath(path.dirname(dest))\n\t\t\t\t\t.then(realDestinationDir => {\n\t\t\t\t\t\tif (realDestinationDir.indexOf(realOutputPath) !== 0) {\n\t\t\t\t\t\t\tthrow (new Error('Refusing to write outside output directory: ' + realDestinationDir));\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t})\n\t\t\t.then(() => {\n\t\t\t\tif (x.type === 'link') {\n\t\t\t\t\treturn fsP.link(x.linkname, dest);\n\t\t\t\t}\n\n\t\t\t\tif (x.type === 'symlink' && process.platform === 'win32') {\n\t\t\t\t\treturn fsP.link(x.linkname, dest);\n\t\t\t\t}\n\n\t\t\t\tif (x.type === 'symlink') {\n\t\t\t\t\treturn fsP.symlink(x.linkname, dest);\n\t\t\t\t}\n\n\t\t\t\treturn fsP.writeFile(dest, x.data, {mode});\n\t\t\t})\n\t\t\t.then(() => x.type === 'file' && fsP.utimes(dest, now, x.mtime))\n\t\t\t.then(() => x);\n\t}));\n});\n\nmodule.exports = (input, output, opts) => {\n\tif (typeof input !== 'string' && !Buffer.isBuffer(input)) {\n\t\treturn Promise.reject(new TypeError('Input file required'));\n\t}\n\n\tif (typeof output === 'object') {\n\t\topts = output;\n\t\toutput = null;\n\t}\n\n\topts = Object.assign({plugins: [\n\t\tdecompressTar(),\n\t\tdecompressTarbz2(),\n\t\tdecompressTargz(),\n\t\tdecompressUnzip()\n\t]}, opts);\n\n\tconst read = typeof input === 'string' ? fsP.readFile(input) : Promise.resolve(input);\n\n\treturn read.then(buf => extractFile(buf, output, opts));\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/decompress@4.2.1/node_modules/decompress/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/end-of-stream@1.4.4/node_modules/end-of-stream/index.js":
/*!************************************************************************************!*\
  !*** ./node_modules/.pnpm/end-of-stream@1.4.4/node_modules/end-of-stream/index.js ***!
  \************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var once = __webpack_require__(/*! once */ \"./node_modules/.pnpm/once@1.4.0/node_modules/once/once.js\");\n\nvar noop = function() {};\n\nvar isRequest = function(stream) {\n\treturn stream.setHeader && typeof stream.abort === 'function';\n};\n\nvar isChildProcess = function(stream) {\n\treturn stream.stdio && Array.isArray(stream.stdio) && stream.stdio.length === 3\n};\n\nvar eos = function(stream, opts, callback) {\n\tif (typeof opts === 'function') return eos(stream, null, opts);\n\tif (!opts) opts = {};\n\n\tcallback = once(callback || noop);\n\n\tvar ws = stream._writableState;\n\tvar rs = stream._readableState;\n\tvar readable = opts.readable || (opts.readable !== false && stream.readable);\n\tvar writable = opts.writable || (opts.writable !== false && stream.writable);\n\tvar cancelled = false;\n\n\tvar onlegacyfinish = function() {\n\t\tif (!stream.writable) onfinish();\n\t};\n\n\tvar onfinish = function() {\n\t\twritable = false;\n\t\tif (!readable) callback.call(stream);\n\t};\n\n\tvar onend = function() {\n\t\treadable = false;\n\t\tif (!writable) callback.call(stream);\n\t};\n\n\tvar onexit = function(exitCode) {\n\t\tcallback.call(stream, exitCode ? new Error('exited with error code: ' + exitCode) : null);\n\t};\n\n\tvar onerror = function(err) {\n\t\tcallback.call(stream, err);\n\t};\n\n\tvar onclose = function() {\n\t\tprocess.nextTick(onclosenexttick);\n\t};\n\n\tvar onclosenexttick = function() {\n\t\tif (cancelled) return;\n\t\tif (readable && !(rs && (rs.ended && !rs.destroyed))) return callback.call(stream, new Error('premature close'));\n\t\tif (writable && !(ws && (ws.ended && !ws.destroyed))) return callback.call(stream, new Error('premature close'));\n\t};\n\n\tvar onrequest = function() {\n\t\tstream.req.on('finish', onfinish);\n\t};\n\n\tif (isRequest(stream)) {\n\t\tstream.on('complete', onfinish);\n\t\tstream.on('abort', onclose);\n\t\tif (stream.req) onrequest();\n\t\telse stream.on('request', onrequest);\n\t} else if (writable && !ws) { // legacy streams\n\t\tstream.on('end', onlegacyfinish);\n\t\tstream.on('close', onlegacyfinish);\n\t}\n\n\tif (isChildProcess(stream)) stream.on('exit', onexit);\n\n\tstream.on('end', onend);\n\tstream.on('finish', onfinish);\n\tif (opts.error !== false) stream.on('error', onerror);\n\tstream.on('close', onclose);\n\n\treturn function() {\n\t\tcancelled = true;\n\t\tstream.removeListener('complete', onfinish);\n\t\tstream.removeListener('abort', onclose);\n\t\tstream.removeListener('request', onrequest);\n\t\tif (stream.req) stream.req.removeListener('finish', onfinish);\n\t\tstream.removeListener('end', onlegacyfinish);\n\t\tstream.removeListener('close', onlegacyfinish);\n\t\tstream.removeListener('finish', onfinish);\n\t\tstream.removeListener('exit', onexit);\n\t\tstream.removeListener('end', onend);\n\t\tstream.removeListener('error', onerror);\n\t\tstream.removeListener('close', onclose);\n\t};\n};\n\nmodule.exports = eos;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/end-of-stream@1.4.4/node_modules/end-of-stream/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/fd-slicer@1.1.0/node_modules/fd-slicer/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/fd-slicer@1.1.0/node_modules/fd-slicer/index.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("var fs = __webpack_require__(/*! fs */ \"fs\");\nvar util = __webpack_require__(/*! util */ \"util\");\nvar stream = __webpack_require__(/*! stream */ \"stream\");\nvar Readable = stream.Readable;\nvar Writable = stream.Writable;\nvar PassThrough = stream.PassThrough;\nvar Pend = __webpack_require__(/*! pend */ \"./node_modules/.pnpm/pend@1.2.0/node_modules/pend/index.js\");\nvar EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\n\nexports.createFromBuffer = createFromBuffer;\nexports.createFromFd = createFromFd;\nexports.BufferSlicer = BufferSlicer;\nexports.FdSlicer = FdSlicer;\n\nutil.inherits(FdSlicer, EventEmitter);\nfunction FdSlicer(fd, options) {\n  options = options || {};\n  EventEmitter.call(this);\n\n  this.fd = fd;\n  this.pend = new Pend();\n  this.pend.max = 1;\n  this.refCount = 0;\n  this.autoClose = !!options.autoClose;\n}\n\nFdSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.read(self.fd, buffer, offset, length, position, function(err, bytesRead, buffer) {\n      cb();\n      callback(err, bytesRead, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.write(self.fd, buffer, offset, length, position, function(err, written, buffer) {\n      cb();\n      callback(err, written, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.createReadStream = function(options) {\n  return new ReadStream(this, options);\n};\n\nFdSlicer.prototype.createWriteStream = function(options) {\n  return new WriteStream(this, options);\n};\n\nFdSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nFdSlicer.prototype.unref = function() {\n  var self = this;\n  self.refCount -= 1;\n\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n\n  if (self.autoClose) {\n    fs.close(self.fd, onCloseDone);\n  }\n\n  function onCloseDone(err) {\n    if (err) {\n      self.emit('error', err);\n    } else {\n      self.emit('close');\n    }\n  }\n};\n\nutil.inherits(ReadStream, Readable);\nfunction ReadStream(context, options) {\n  options = options || {};\n  Readable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = options.end;\n  this.pos = this.start;\n  this.destroyed = false;\n}\n\nReadStream.prototype._read = function(n) {\n  var self = this;\n  if (self.destroyed) return;\n\n  var toRead = Math.min(self._readableState.highWaterMark, n);\n  if (self.endOffset != null) {\n    toRead = Math.min(toRead, self.endOffset - self.pos);\n  }\n  if (toRead <= 0) {\n    self.destroyed = true;\n    self.push(null);\n    self.context.unref();\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    var buffer = new Buffer(toRead);\n    fs.read(self.context.fd, buffer, 0, toRead, self.pos, function(err, bytesRead) {\n      if (err) {\n        self.destroy(err);\n      } else if (bytesRead === 0) {\n        self.destroyed = true;\n        self.push(null);\n        self.context.unref();\n      } else {\n        self.pos += bytesRead;\n        self.push(buffer.slice(0, bytesRead));\n      }\n      cb();\n    });\n  });\n};\n\nReadStream.prototype.destroy = function(err) {\n  if (this.destroyed) return;\n  err = err || new Error(\"stream destroyed\");\n  this.destroyed = true;\n  this.emit('error', err);\n  this.context.unref();\n};\n\nutil.inherits(WriteStream, Writable);\nfunction WriteStream(context, options) {\n  options = options || {};\n  Writable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = (options.end == null) ? Infinity : +options.end;\n  this.bytesWritten = 0;\n  this.pos = this.start;\n  this.destroyed = false;\n\n  this.on('finish', this.destroy.bind(this));\n}\n\nWriteStream.prototype._write = function(buffer, encoding, callback) {\n  var self = this;\n  if (self.destroyed) return;\n\n  if (self.pos + buffer.length > self.endOffset) {\n    var err = new Error(\"maximum file length exceeded\");\n    err.code = 'ETOOBIG';\n    self.destroy();\n    callback(err);\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    fs.write(self.context.fd, buffer, 0, buffer.length, self.pos, function(err, bytes) {\n      if (err) {\n        self.destroy();\n        cb();\n        callback(err);\n      } else {\n        self.bytesWritten += bytes;\n        self.pos += bytes;\n        self.emit('progress');\n        cb();\n        callback();\n      }\n    });\n  });\n};\n\nWriteStream.prototype.destroy = function() {\n  if (this.destroyed) return;\n  this.destroyed = true;\n  this.context.unref();\n};\n\nutil.inherits(BufferSlicer, EventEmitter);\nfunction BufferSlicer(buffer, options) {\n  EventEmitter.call(this);\n\n  options = options || {};\n  this.refCount = 0;\n  this.buffer = buffer;\n  this.maxChunkSize = options.maxChunkSize || Number.MAX_SAFE_INTEGER;\n}\n\nBufferSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var end = position + length;\n  var delta = end - this.buffer.length;\n  var written = (delta > 0) ? delta : length;\n  this.buffer.copy(buffer, offset, position, end);\n  setImmediate(function() {\n    callback(null, written);\n  });\n};\n\nBufferSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  buffer.copy(this.buffer, position, offset, offset + length);\n  setImmediate(function() {\n    callback(null, length, buffer);\n  });\n};\n\nBufferSlicer.prototype.createReadStream = function(options) {\n  options = options || {};\n  var readStream = new PassThrough(options);\n  readStream.destroyed = false;\n  readStream.start = options.start || 0;\n  readStream.endOffset = options.end;\n  // by the time this function returns, we'll be done.\n  readStream.pos = readStream.endOffset || this.buffer.length;\n\n  // respect the maxChunkSize option to slice up the chunk into smaller pieces.\n  var entireSlice = this.buffer.slice(readStream.start, readStream.pos);\n  var offset = 0;\n  while (true) {\n    var nextOffset = offset + this.maxChunkSize;\n    if (nextOffset >= entireSlice.length) {\n      // last chunk\n      if (offset < entireSlice.length) {\n        readStream.write(entireSlice.slice(offset, entireSlice.length));\n      }\n      break;\n    }\n    readStream.write(entireSlice.slice(offset, nextOffset));\n    offset = nextOffset;\n  }\n\n  readStream.end();\n  readStream.destroy = function() {\n    readStream.destroyed = true;\n  };\n  return readStream;\n};\n\nBufferSlicer.prototype.createWriteStream = function(options) {\n  var bufferSlicer = this;\n  options = options || {};\n  var writeStream = new Writable(options);\n  writeStream.start = options.start || 0;\n  writeStream.endOffset = (options.end == null) ? this.buffer.length : +options.end;\n  writeStream.bytesWritten = 0;\n  writeStream.pos = writeStream.start;\n  writeStream.destroyed = false;\n  writeStream._write = function(buffer, encoding, callback) {\n    if (writeStream.destroyed) return;\n\n    var end = writeStream.pos + buffer.length;\n    if (end > writeStream.endOffset) {\n      var err = new Error(\"maximum file length exceeded\");\n      err.code = 'ETOOBIG';\n      writeStream.destroyed = true;\n      callback(err);\n      return;\n    }\n    buffer.copy(bufferSlicer.buffer, writeStream.pos, 0, buffer.length);\n\n    writeStream.bytesWritten += buffer.length;\n    writeStream.pos = end;\n    writeStream.emit('progress');\n    callback();\n  };\n  writeStream.destroy = function() {\n    writeStream.destroyed = true;\n  };\n  return writeStream;\n};\n\nBufferSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nBufferSlicer.prototype.unref = function() {\n  this.refCount -= 1;\n\n  if (this.refCount < 0) {\n    throw new Error(\"invalid unref\");\n  }\n};\n\nfunction createFromBuffer(buffer, options) {\n  return new BufferSlicer(buffer, options);\n}\n\nfunction createFromFd(fd, options) {\n  return new FdSlicer(fd, options);\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/fd-slicer@1.1.0/node_modules/fd-slicer/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/file-type@3.9.0/node_modules/file-type/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@3.9.0/node_modules/file-type/index.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = function (buf) {\n\tif (!(buf && buf.length > 1)) {\n\t\treturn null;\n\t}\n\n\tif (buf[0] === 0xFF && buf[1] === 0xD8 && buf[2] === 0xFF) {\n\t\treturn {\n\t\t\text: 'jpg',\n\t\t\tmime: 'image/jpeg'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x89 && buf[1] === 0x50 && buf[2] === 0x4E && buf[3] === 0x47) {\n\t\treturn {\n\t\t\text: 'png',\n\t\t\tmime: 'image/png'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x47 && buf[1] === 0x49 && buf[2] === 0x46) {\n\t\treturn {\n\t\t\text: 'gif',\n\t\t\tmime: 'image/gif'\n\t\t};\n\t}\n\n\tif (buf[8] === 0x57 && buf[9] === 0x45 && buf[10] === 0x42 && buf[11] === 0x50) {\n\t\treturn {\n\t\t\text: 'webp',\n\t\t\tmime: 'image/webp'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x46 && buf[1] === 0x4C && buf[2] === 0x49 && buf[3] === 0x46) {\n\t\treturn {\n\t\t\text: 'flif',\n\t\t\tmime: 'image/flif'\n\t\t};\n\t}\n\n\t// needs to be before `tif` check\n\tif (((buf[0] === 0x49 && buf[1] === 0x49 && buf[2] === 0x2A && buf[3] === 0x0) || (buf[0] === 0x4D && buf[1] === 0x4D && buf[2] === 0x0 && buf[3] === 0x2A)) && buf[8] === 0x43 && buf[9] === 0x52) {\n\t\treturn {\n\t\t\text: 'cr2',\n\t\t\tmime: 'image/x-canon-cr2'\n\t\t};\n\t}\n\n\tif ((buf[0] === 0x49 && buf[1] === 0x49 && buf[2] === 0x2A && buf[3] === 0x0) || (buf[0] === 0x4D && buf[1] === 0x4D && buf[2] === 0x0 && buf[3] === 0x2A)) {\n\t\treturn {\n\t\t\text: 'tif',\n\t\t\tmime: 'image/tiff'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x42 && buf[1] === 0x4D) {\n\t\treturn {\n\t\t\text: 'bmp',\n\t\t\tmime: 'image/bmp'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x49 && buf[1] === 0x49 && buf[2] === 0xBC) {\n\t\treturn {\n\t\t\text: 'jxr',\n\t\t\tmime: 'image/vnd.ms-photo'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x38 && buf[1] === 0x42 && buf[2] === 0x50 && buf[3] === 0x53) {\n\t\treturn {\n\t\t\text: 'psd',\n\t\t\tmime: 'image/vnd.adobe.photoshop'\n\t\t};\n\t}\n\n\t// needs to be before `zip` check\n\tif (buf[0] === 0x50 && buf[1] === 0x4B && buf[2] === 0x3 && buf[3] === 0x4 && buf[30] === 0x6D && buf[31] === 0x69 && buf[32] === 0x6D && buf[33] === 0x65 && buf[34] === 0x74 && buf[35] === 0x79 && buf[36] === 0x70 && buf[37] === 0x65 && buf[38] === 0x61 && buf[39] === 0x70 && buf[40] === 0x70 && buf[41] === 0x6C && buf[42] === 0x69 && buf[43] === 0x63 && buf[44] === 0x61 && buf[45] === 0x74 && buf[46] === 0x69 && buf[47] === 0x6F && buf[48] === 0x6E && buf[49] === 0x2F && buf[50] === 0x65 && buf[51] === 0x70 && buf[52] === 0x75 && buf[53] === 0x62 && buf[54] === 0x2B && buf[55] === 0x7A && buf[56] === 0x69 && buf[57] === 0x70) {\n\t\treturn {\n\t\t\text: 'epub',\n\t\t\tmime: 'application/epub+zip'\n\t\t};\n\t}\n\n\t// needs to be before `zip` check\n\t// assumes signed .xpi from addons.mozilla.org\n\tif (buf[0] === 0x50 && buf[1] === 0x4B && buf[2] === 0x3 && buf[3] === 0x4 && buf[30] === 0x4D && buf[31] === 0x45 && buf[32] === 0x54 && buf[33] === 0x41 && buf[34] === 0x2D && buf[35] === 0x49 && buf[36] === 0x4E && buf[37] === 0x46 && buf[38] === 0x2F && buf[39] === 0x6D && buf[40] === 0x6F && buf[41] === 0x7A && buf[42] === 0x69 && buf[43] === 0x6C && buf[44] === 0x6C && buf[45] === 0x61 && buf[46] === 0x2E && buf[47] === 0x72 && buf[48] === 0x73 && buf[49] === 0x61) {\n\t\treturn {\n\t\t\text: 'xpi',\n\t\t\tmime: 'application/x-xpinstall'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x50 && buf[1] === 0x4B && (buf[2] === 0x3 || buf[2] === 0x5 || buf[2] === 0x7) && (buf[3] === 0x4 || buf[3] === 0x6 || buf[3] === 0x8)) {\n\t\treturn {\n\t\t\text: 'zip',\n\t\t\tmime: 'application/zip'\n\t\t};\n\t}\n\n\tif (buf[257] === 0x75 && buf[258] === 0x73 && buf[259] === 0x74 && buf[260] === 0x61 && buf[261] === 0x72) {\n\t\treturn {\n\t\t\text: 'tar',\n\t\t\tmime: 'application/x-tar'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x52 && buf[1] === 0x61 && buf[2] === 0x72 && buf[3] === 0x21 && buf[4] === 0x1A && buf[5] === 0x7 && (buf[6] === 0x0 || buf[6] === 0x1)) {\n\t\treturn {\n\t\t\text: 'rar',\n\t\t\tmime: 'application/x-rar-compressed'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x1F && buf[1] === 0x8B && buf[2] === 0x8) {\n\t\treturn {\n\t\t\text: 'gz',\n\t\t\tmime: 'application/gzip'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x42 && buf[1] === 0x5A && buf[2] === 0x68) {\n\t\treturn {\n\t\t\text: 'bz2',\n\t\t\tmime: 'application/x-bzip2'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x37 && buf[1] === 0x7A && buf[2] === 0xBC && buf[3] === 0xAF && buf[4] === 0x27 && buf[5] === 0x1C) {\n\t\treturn {\n\t\t\text: '7z',\n\t\t\tmime: 'application/x-7z-compressed'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x78 && buf[1] === 0x01) {\n\t\treturn {\n\t\t\text: 'dmg',\n\t\t\tmime: 'application/x-apple-diskimage'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[0] === 0x0 && buf[1] === 0x0 && buf[2] === 0x0 && (buf[3] === 0x18 || buf[3] === 0x20) && buf[4] === 0x66 && buf[5] === 0x74 && buf[6] === 0x79 && buf[7] === 0x70) ||\n\t\t(buf[0] === 0x33 && buf[1] === 0x67 && buf[2] === 0x70 && buf[3] === 0x35) ||\n\t\t(buf[0] === 0x0 && buf[1] === 0x0 && buf[2] === 0x0 && buf[3] === 0x1C && buf[4] === 0x66 && buf[5] === 0x74 && buf[6] === 0x79 && buf[7] === 0x70 && buf[8] === 0x6D && buf[9] === 0x70 && buf[10] === 0x34 && buf[11] === 0x32 && buf[16] === 0x6D && buf[17] === 0x70 && buf[18] === 0x34 && buf[19] === 0x31 && buf[20] === 0x6D && buf[21] === 0x70 && buf[22] === 0x34 && buf[23] === 0x32 && buf[24] === 0x69 && buf[25] === 0x73 && buf[26] === 0x6F && buf[27] === 0x6D) ||\n\t\t(buf[0] === 0x0 && buf[1] === 0x0 && buf[2] === 0x0 && buf[3] === 0x1C && buf[4] === 0x66 && buf[5] === 0x74 && buf[6] === 0x79 && buf[7] === 0x70 && buf[8] === 0x69 && buf[9] === 0x73 && buf[10] === 0x6F && buf[11] === 0x6D) ||\n\t\t(buf[0] === 0x0 && buf[1] === 0x0 && buf[2] === 0x0 && buf[3] === 0x1c && buf[4] === 0x66 && buf[5] === 0x74 && buf[6] === 0x79 && buf[7] === 0x70 && buf[8] === 0x6D && buf[9] === 0x70 && buf[10] === 0x34 && buf[11] === 0x32 && buf[12] === 0x0 && buf[13] === 0x0 && buf[14] === 0x0 && buf[15] === 0x0)\n\t) {\n\t\treturn {\n\t\t\text: 'mp4',\n\t\t\tmime: 'video/mp4'\n\t\t};\n\t}\n\n\tif ((buf[0] === 0x0 && buf[1] === 0x0 && buf[2] === 0x0 && buf[3] === 0x1C && buf[4] === 0x66 && buf[5] === 0x74 && buf[6] === 0x79 && buf[7] === 0x70 && buf[8] === 0x4D && buf[9] === 0x34 && buf[10] === 0x56)) {\n\t\treturn {\n\t\t\text: 'm4v',\n\t\t\tmime: 'video/x-m4v'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x4D && buf[1] === 0x54 && buf[2] === 0x68 && buf[3] === 0x64) {\n\t\treturn {\n\t\t\text: 'mid',\n\t\t\tmime: 'audio/midi'\n\t\t};\n\t}\n\n\t// needs to be before the `webm` check\n\tif (buf[31] === 0x6D && buf[32] === 0x61 && buf[33] === 0x74 && buf[34] === 0x72 && buf[35] === 0x6f && buf[36] === 0x73 && buf[37] === 0x6B && buf[38] === 0x61) {\n\t\treturn {\n\t\t\text: 'mkv',\n\t\t\tmime: 'video/x-matroska'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x1A && buf[1] === 0x45 && buf[2] === 0xDF && buf[3] === 0xA3) {\n\t\treturn {\n\t\t\text: 'webm',\n\t\t\tmime: 'video/webm'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x0 && buf[1] === 0x0 && buf[2] === 0x0 && buf[3] === 0x14 && buf[4] === 0x66 && buf[5] === 0x74 && buf[6] === 0x79 && buf[7] === 0x70) {\n\t\treturn {\n\t\t\text: 'mov',\n\t\t\tmime: 'video/quicktime'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x52 && buf[1] === 0x49 && buf[2] === 0x46 && buf[3] === 0x46 && buf[8] === 0x41 && buf[9] === 0x56 && buf[10] === 0x49) {\n\t\treturn {\n\t\t\text: 'avi',\n\t\t\tmime: 'video/x-msvideo'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x30 && buf[1] === 0x26 && buf[2] === 0xB2 && buf[3] === 0x75 && buf[4] === 0x8E && buf[5] === 0x66 && buf[6] === 0xCF && buf[7] === 0x11 && buf[8] === 0xA6 && buf[9] === 0xD9) {\n\t\treturn {\n\t\t\text: 'wmv',\n\t\t\tmime: 'video/x-ms-wmv'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x0 && buf[1] === 0x0 && buf[2] === 0x1 && buf[3].toString(16)[0] === 'b') {\n\t\treturn {\n\t\t\text: 'mpg',\n\t\t\tmime: 'video/mpeg'\n\t\t};\n\t}\n\n\tif ((buf[0] === 0x49 && buf[1] === 0x44 && buf[2] === 0x33) || (buf[0] === 0xFF && buf[1] === 0xfb)) {\n\t\treturn {\n\t\t\text: 'mp3',\n\t\t\tmime: 'audio/mpeg'\n\t\t};\n\t}\n\n\tif ((buf[4] === 0x66 && buf[5] === 0x74 && buf[6] === 0x79 && buf[7] === 0x70 && buf[8] === 0x4D && buf[9] === 0x34 && buf[10] === 0x41) || (buf[0] === 0x4D && buf[1] === 0x34 && buf[2] === 0x41 && buf[3] === 0x20)) {\n\t\treturn {\n\t\t\text: 'm4a',\n\t\t\tmime: 'audio/m4a'\n\t\t};\n\t}\n\n\t// needs to be before `ogg` check\n\tif (buf[28] === 0x4F && buf[29] === 0x70 && buf[30] === 0x75 && buf[31] === 0x73 && buf[32] === 0x48 && buf[33] === 0x65 && buf[34] === 0x61 && buf[35] === 0x64) {\n\t\treturn {\n\t\t\text: 'opus',\n\t\t\tmime: 'audio/opus'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x4F && buf[1] === 0x67 && buf[2] === 0x67 && buf[3] === 0x53) {\n\t\treturn {\n\t\t\text: 'ogg',\n\t\t\tmime: 'audio/ogg'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x66 && buf[1] === 0x4C && buf[2] === 0x61 && buf[3] === 0x43) {\n\t\treturn {\n\t\t\text: 'flac',\n\t\t\tmime: 'audio/x-flac'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x52 && buf[1] === 0x49 && buf[2] === 0x46 && buf[3] === 0x46 && buf[8] === 0x57 && buf[9] === 0x41 && buf[10] === 0x56 && buf[11] === 0x45) {\n\t\treturn {\n\t\t\text: 'wav',\n\t\t\tmime: 'audio/x-wav'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x23 && buf[1] === 0x21 && buf[2] === 0x41 && buf[3] === 0x4D && buf[4] === 0x52 && buf[5] === 0x0A) {\n\t\treturn {\n\t\t\text: 'amr',\n\t\t\tmime: 'audio/amr'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x25 && buf[1] === 0x50 && buf[2] === 0x44 && buf[3] === 0x46) {\n\t\treturn {\n\t\t\text: 'pdf',\n\t\t\tmime: 'application/pdf'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x4D && buf[1] === 0x5A) {\n\t\treturn {\n\t\t\text: 'exe',\n\t\t\tmime: 'application/x-msdownload'\n\t\t};\n\t}\n\n\tif ((buf[0] === 0x43 || buf[0] === 0x46) && buf[1] === 0x57 && buf[2] === 0x53) {\n\t\treturn {\n\t\t\text: 'swf',\n\t\t\tmime: 'application/x-shockwave-flash'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x7B && buf[1] === 0x5C && buf[2] === 0x72 && buf[3] === 0x74 && buf[4] === 0x66) {\n\t\treturn {\n\t\t\text: 'rtf',\n\t\t\tmime: 'application/rtf'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[0] === 0x77 && buf[1] === 0x4F && buf[2] === 0x46 && buf[3] === 0x46) &&\n\t\t(\n\t\t\t(buf[4] === 0x00 && buf[5] === 0x01 && buf[6] === 0x00 && buf[7] === 0x00) ||\n\t\t\t(buf[4] === 0x4F && buf[5] === 0x54 && buf[6] === 0x54 && buf[7] === 0x4F)\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff',\n\t\t\tmime: 'application/font-woff'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[0] === 0x77 && buf[1] === 0x4F && buf[2] === 0x46 && buf[3] === 0x32) &&\n\t\t(\n\t\t\t(buf[4] === 0x00 && buf[5] === 0x01 && buf[6] === 0x00 && buf[7] === 0x00) ||\n\t\t\t(buf[4] === 0x4F && buf[5] === 0x54 && buf[6] === 0x54 && buf[7] === 0x4F)\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff2',\n\t\t\tmime: 'application/font-woff'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[34] === 0x4C && buf[35] === 0x50) &&\n\t\t(\n\t\t\t(buf[8] === 0x00 && buf[9] === 0x00 && buf[10] === 0x01) ||\n\t\t\t(buf[8] === 0x01 && buf[9] === 0x00 && buf[10] === 0x02) ||\n\t\t\t(buf[8] === 0x02 && buf[9] === 0x00 && buf[10] === 0x02)\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'eot',\n\t\t\tmime: 'application/octet-stream'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x00 && buf[1] === 0x01 && buf[2] === 0x00 && buf[3] === 0x00 && buf[4] === 0x00) {\n\t\treturn {\n\t\t\text: 'ttf',\n\t\t\tmime: 'application/font-sfnt'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x4F && buf[1] === 0x54 && buf[2] === 0x54 && buf[3] === 0x4F && buf[4] === 0x00) {\n\t\treturn {\n\t\t\text: 'otf',\n\t\t\tmime: 'application/font-sfnt'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x00 && buf[1] === 0x00 && buf[2] === 0x01 && buf[3] === 0x00) {\n\t\treturn {\n\t\t\text: 'ico',\n\t\t\tmime: 'image/x-icon'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x46 && buf[1] === 0x4C && buf[2] === 0x56 && buf[3] === 0x01) {\n\t\treturn {\n\t\t\text: 'flv',\n\t\t\tmime: 'video/x-flv'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x25 && buf[1] === 0x21) {\n\t\treturn {\n\t\t\text: 'ps',\n\t\t\tmime: 'application/postscript'\n\t\t};\n\t}\n\n\tif (buf[0] === 0xFD && buf[1] === 0x37 && buf[2] === 0x7A && buf[3] === 0x58 && buf[4] === 0x5A && buf[5] === 0x00) {\n\t\treturn {\n\t\t\text: 'xz',\n\t\t\tmime: 'application/x-xz'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x53 && buf[1] === 0x51 && buf[2] === 0x4C && buf[3] === 0x69) {\n\t\treturn {\n\t\t\text: 'sqlite',\n\t\t\tmime: 'application/x-sqlite3'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x4E && buf[1] === 0x45 && buf[2] === 0x53 && buf[3] === 0x1A) {\n\t\treturn {\n\t\t\text: 'nes',\n\t\t\tmime: 'application/x-nintendo-nes-rom'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x43 && buf[1] === 0x72 && buf[2] === 0x32 && buf[3] === 0x34) {\n\t\treturn {\n\t\t\text: 'crx',\n\t\t\tmime: 'application/x-google-chrome-extension'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[0] === 0x4D && buf[1] === 0x53 && buf[2] === 0x43 && buf[3] === 0x46) ||\n\t\t(buf[0] === 0x49 && buf[1] === 0x53 && buf[2] === 0x63 && buf[3] === 0x28)\n\t) {\n\t\treturn {\n\t\t\text: 'cab',\n\t\t\tmime: 'application/vnd.ms-cab-compressed'\n\t\t};\n\t}\n\n\t// needs to be before `ar` check\n\tif (buf[0] === 0x21 && buf[1] === 0x3C && buf[2] === 0x61 && buf[3] === 0x72 && buf[4] === 0x63 && buf[5] === 0x68 && buf[6] === 0x3E && buf[7] === 0x0A && buf[8] === 0x64 && buf[9] === 0x65 && buf[10] === 0x62 && buf[11] === 0x69 && buf[12] === 0x61 && buf[13] === 0x6E && buf[14] === 0x2D && buf[15] === 0x62 && buf[16] === 0x69 && buf[17] === 0x6E && buf[18] === 0x61 && buf[19] === 0x72 && buf[20] === 0x79) {\n\t\treturn {\n\t\t\text: 'deb',\n\t\t\tmime: 'application/x-deb'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x21 && buf[1] === 0x3C && buf[2] === 0x61 && buf[3] === 0x72 && buf[4] === 0x63 && buf[5] === 0x68 && buf[6] === 0x3E) {\n\t\treturn {\n\t\t\text: 'ar',\n\t\t\tmime: 'application/x-unix-archive'\n\t\t};\n\t}\n\n\tif (buf[0] === 0xED && buf[1] === 0xAB && buf[2] === 0xEE && buf[3] === 0xDB) {\n\t\treturn {\n\t\t\text: 'rpm',\n\t\t\tmime: 'application/x-rpm'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[0] === 0x1F && buf[1] === 0xA0) ||\n\t\t(buf[0] === 0x1F && buf[1] === 0x9D)\n\t) {\n\t\treturn {\n\t\t\text: 'Z',\n\t\t\tmime: 'application/x-compress'\n\t\t};\n\t}\n\n\tif (buf[0] === 0x4C && buf[1] === 0x5A && buf[2] === 0x49 && buf[3] === 0x50) {\n\t\treturn {\n\t\t\text: 'lz',\n\t\t\tmime: 'application/x-lzip'\n\t\t};\n\t}\n\n\tif (buf[0] === 0xD0 && buf[1] === 0xCF && buf[2] === 0x11 && buf[3] === 0xE0 && buf[4] === 0xA1 && buf[5] === 0xB1 && buf[6] === 0x1A && buf[7] === 0xE1) {\n\t\treturn {\n\t\t\text: 'msi',\n\t\t\tmime: 'application/x-msi'\n\t\t};\n\t}\n\n\treturn null;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/file-type@3.9.0/node_modules/file-type/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/file-type@5.2.0/node_modules/file-type/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@5.2.0/node_modules/file-type/index.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = input => {\n\tconst buf = new Uint8Array(input);\n\n\tif (!(buf && buf.length > 1)) {\n\t\treturn null;\n\t}\n\n\tconst check = (header, opts) => {\n\t\topts = Object.assign({\n\t\t\toffset: 0\n\t\t}, opts);\n\n\t\tfor (let i = 0; i < header.length; i++) {\n\t\t\tif (header[i] !== buf[i + opts.offset]) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\treturn true;\n\t};\n\n\tif (check([0xFF, 0xD8, 0xFF])) {\n\t\treturn {\n\t\t\text: 'jpg',\n\t\t\tmime: 'image/jpeg'\n\t\t};\n\t}\n\n\tif (check([0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\treturn {\n\t\t\text: 'png',\n\t\t\tmime: 'image/png'\n\t\t};\n\t}\n\n\tif (check([0x47, 0x49, 0x46])) {\n\t\treturn {\n\t\t\text: 'gif',\n\t\t\tmime: 'image/gif'\n\t\t};\n\t}\n\n\tif (check([0x57, 0x45, 0x42, 0x50], {offset: 8})) {\n\t\treturn {\n\t\t\text: 'webp',\n\t\t\tmime: 'image/webp'\n\t\t};\n\t}\n\n\tif (check([0x46, 0x4C, 0x49, 0x46])) {\n\t\treturn {\n\t\t\text: 'flif',\n\t\t\tmime: 'image/flif'\n\t\t};\n\t}\n\n\t// Needs to be before `tif` check\n\tif (\n\t\t(check([0x49, 0x49, 0x2A, 0x0]) || check([0x4D, 0x4D, 0x0, 0x2A])) &&\n\t\tcheck([0x43, 0x52], {offset: 8})\n\t) {\n\t\treturn {\n\t\t\text: 'cr2',\n\t\t\tmime: 'image/x-canon-cr2'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x49, 0x49, 0x2A, 0x0]) ||\n\t\tcheck([0x4D, 0x4D, 0x0, 0x2A])\n\t) {\n\t\treturn {\n\t\t\text: 'tif',\n\t\t\tmime: 'image/tiff'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x4D])) {\n\t\treturn {\n\t\t\text: 'bmp',\n\t\t\tmime: 'image/bmp'\n\t\t};\n\t}\n\n\tif (check([0x49, 0x49, 0xBC])) {\n\t\treturn {\n\t\t\text: 'jxr',\n\t\t\tmime: 'image/vnd.ms-photo'\n\t\t};\n\t}\n\n\tif (check([0x38, 0x42, 0x50, 0x53])) {\n\t\treturn {\n\t\t\text: 'psd',\n\t\t\tmime: 'image/vnd.adobe.photoshop'\n\t\t};\n\t}\n\n\t// Needs to be before the `zip` check\n\tif (\n\t\tcheck([0x50, 0x4B, 0x3, 0x4]) &&\n\t\tcheck([0x6D, 0x69, 0x6D, 0x65, 0x74, 0x79, 0x70, 0x65, 0x61, 0x70, 0x70, 0x6C, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6F, 0x6E, 0x2F, 0x65, 0x70, 0x75, 0x62, 0x2B, 0x7A, 0x69, 0x70], {offset: 30})\n\t) {\n\t\treturn {\n\t\t\text: 'epub',\n\t\t\tmime: 'application/epub+zip'\n\t\t};\n\t}\n\n\t// Needs to be before `zip` check\n\t// Assumes signed `.xpi` from addons.mozilla.org\n\tif (\n\t\tcheck([0x50, 0x4B, 0x3, 0x4]) &&\n\t\tcheck([0x4D, 0x45, 0x54, 0x41, 0x2D, 0x49, 0x4E, 0x46, 0x2F, 0x6D, 0x6F, 0x7A, 0x69, 0x6C, 0x6C, 0x61, 0x2E, 0x72, 0x73, 0x61], {offset: 30})\n\t) {\n\t\treturn {\n\t\t\text: 'xpi',\n\t\t\tmime: 'application/x-xpinstall'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x50, 0x4B]) &&\n\t\t(buf[2] === 0x3 || buf[2] === 0x5 || buf[2] === 0x7) &&\n\t\t(buf[3] === 0x4 || buf[3] === 0x6 || buf[3] === 0x8)\n\t) {\n\t\treturn {\n\t\t\text: 'zip',\n\t\t\tmime: 'application/zip'\n\t\t};\n\t}\n\n\tif (check([0x75, 0x73, 0x74, 0x61, 0x72], {offset: 257})) {\n\t\treturn {\n\t\t\text: 'tar',\n\t\t\tmime: 'application/x-tar'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x52, 0x61, 0x72, 0x21, 0x1A, 0x7]) &&\n\t\t(buf[6] === 0x0 || buf[6] === 0x1)\n\t) {\n\t\treturn {\n\t\t\text: 'rar',\n\t\t\tmime: 'application/x-rar-compressed'\n\t\t};\n\t}\n\n\tif (check([0x1F, 0x8B, 0x8])) {\n\t\treturn {\n\t\t\text: 'gz',\n\t\t\tmime: 'application/gzip'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x5A, 0x68])) {\n\t\treturn {\n\t\t\text: 'bz2',\n\t\t\tmime: 'application/x-bzip2'\n\t\t};\n\t}\n\n\tif (check([0x37, 0x7A, 0xBC, 0xAF, 0x27, 0x1C])) {\n\t\treturn {\n\t\t\text: '7z',\n\t\t\tmime: 'application/x-7z-compressed'\n\t\t};\n\t}\n\n\tif (check([0x78, 0x01])) {\n\t\treturn {\n\t\t\text: 'dmg',\n\t\t\tmime: 'application/x-apple-diskimage'\n\t\t};\n\t}\n\n\tif (\n\t\t(\n\t\t\tcheck([0x0, 0x0, 0x0]) &&\n\t\t\t(buf[3] === 0x18 || buf[3] === 0x20) &&\n\t\t\tcheck([0x66, 0x74, 0x79, 0x70], {offset: 4})\n\t\t) ||\n\t\tcheck([0x33, 0x67, 0x70, 0x35]) ||\n\t\t(\n\t\t\tcheck([0x0, 0x0, 0x0, 0x1C, 0x66, 0x74, 0x79, 0x70, 0x6D, 0x70, 0x34, 0x32]) &&\n\t\t\tcheck([0x6D, 0x70, 0x34, 0x31, 0x6D, 0x70, 0x34, 0x32, 0x69, 0x73, 0x6F, 0x6D], {offset: 16})\n\t\t) ||\n\t\tcheck([0x0, 0x0, 0x0, 0x1C, 0x66, 0x74, 0x79, 0x70, 0x69, 0x73, 0x6F, 0x6D]) ||\n\t\tcheck([0x0, 0x0, 0x0, 0x1C, 0x66, 0x74, 0x79, 0x70, 0x6D, 0x70, 0x34, 0x32, 0x0, 0x0, 0x0, 0x0])\n\t) {\n\t\treturn {\n\t\t\text: 'mp4',\n\t\t\tmime: 'video/mp4'\n\t\t};\n\t}\n\n\tif (check([0x0, 0x0, 0x0, 0x1C, 0x66, 0x74, 0x79, 0x70, 0x4D, 0x34, 0x56])) {\n\t\treturn {\n\t\t\text: 'm4v',\n\t\t\tmime: 'video/x-m4v'\n\t\t};\n\t}\n\n\tif (check([0x4D, 0x54, 0x68, 0x64])) {\n\t\treturn {\n\t\t\text: 'mid',\n\t\t\tmime: 'audio/midi'\n\t\t};\n\t}\n\n\t// https://github.com/threatstack/libmagic/blob/master/magic/Magdir/matroska\n\tif (check([0x1A, 0x45, 0xDF, 0xA3])) {\n\t\tconst sliced = buf.subarray(4, 4 + 4096);\n\t\tconst idPos = sliced.findIndex((el, i, arr) => arr[i] === 0x42 && arr[i + 1] === 0x82);\n\n\t\tif (idPos >= 0) {\n\t\t\tconst docTypePos = idPos + 3;\n\t\t\tconst findDocType = type => Array.from(type).every((c, i) => sliced[docTypePos + i] === c.charCodeAt(0));\n\n\t\t\tif (findDocType('matroska')) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mkv',\n\t\t\t\t\tmime: 'video/x-matroska'\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (findDocType('webm')) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'webm',\n\t\t\t\t\tmime: 'video/webm'\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\tif (check([0x0, 0x0, 0x0, 0x14, 0x66, 0x74, 0x79, 0x70, 0x71, 0x74, 0x20, 0x20]) ||\n\t\tcheck([0x66, 0x72, 0x65, 0x65], {offset: 4}) ||\n\t\tcheck([0x66, 0x74, 0x79, 0x70, 0x71, 0x74, 0x20, 0x20], {offset: 4}) ||\n\t\tcheck([0x6D, 0x64, 0x61, 0x74], {offset: 4}) || // MJPEG\n\t\tcheck([0x77, 0x69, 0x64, 0x65], {offset: 4})) {\n\t\treturn {\n\t\t\text: 'mov',\n\t\t\tmime: 'video/quicktime'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x52, 0x49, 0x46, 0x46]) &&\n\t\tcheck([0x41, 0x56, 0x49], {offset: 8})\n\t) {\n\t\treturn {\n\t\t\text: 'avi',\n\t\t\tmime: 'video/x-msvideo'\n\t\t};\n\t}\n\n\tif (check([0x30, 0x26, 0xB2, 0x75, 0x8E, 0x66, 0xCF, 0x11, 0xA6, 0xD9])) {\n\t\treturn {\n\t\t\text: 'wmv',\n\t\t\tmime: 'video/x-ms-wmv'\n\t\t};\n\t}\n\n\tif (check([0x0, 0x0, 0x1, 0xBA])) {\n\t\treturn {\n\t\t\text: 'mpg',\n\t\t\tmime: 'video/mpeg'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x49, 0x44, 0x33]) ||\n\t\tcheck([0xFF, 0xFB])\n\t) {\n\t\treturn {\n\t\t\text: 'mp3',\n\t\t\tmime: 'audio/mpeg'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x66, 0x74, 0x79, 0x70, 0x4D, 0x34, 0x41], {offset: 4}) ||\n\t\tcheck([0x4D, 0x34, 0x41, 0x20])\n\t) {\n\t\treturn {\n\t\t\text: 'm4a',\n\t\t\tmime: 'audio/m4a'\n\t\t};\n\t}\n\n\t// Needs to be before `ogg` check\n\tif (check([0x4F, 0x70, 0x75, 0x73, 0x48, 0x65, 0x61, 0x64], {offset: 28})) {\n\t\treturn {\n\t\t\text: 'opus',\n\t\t\tmime: 'audio/opus'\n\t\t};\n\t}\n\n\tif (check([0x4F, 0x67, 0x67, 0x53])) {\n\t\treturn {\n\t\t\text: 'ogg',\n\t\t\tmime: 'audio/ogg'\n\t\t};\n\t}\n\n\tif (check([0x66, 0x4C, 0x61, 0x43])) {\n\t\treturn {\n\t\t\text: 'flac',\n\t\t\tmime: 'audio/x-flac'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x52, 0x49, 0x46, 0x46]) &&\n\t\tcheck([0x57, 0x41, 0x56, 0x45], {offset: 8})\n\t) {\n\t\treturn {\n\t\t\text: 'wav',\n\t\t\tmime: 'audio/x-wav'\n\t\t};\n\t}\n\n\tif (check([0x23, 0x21, 0x41, 0x4D, 0x52, 0x0A])) {\n\t\treturn {\n\t\t\text: 'amr',\n\t\t\tmime: 'audio/amr'\n\t\t};\n\t}\n\n\tif (check([0x25, 0x50, 0x44, 0x46])) {\n\t\treturn {\n\t\t\text: 'pdf',\n\t\t\tmime: 'application/pdf'\n\t\t};\n\t}\n\n\tif (check([0x4D, 0x5A])) {\n\t\treturn {\n\t\t\text: 'exe',\n\t\t\tmime: 'application/x-msdownload'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[0] === 0x43 || buf[0] === 0x46) &&\n\t\tcheck([0x57, 0x53], {offset: 1})\n\t) {\n\t\treturn {\n\t\t\text: 'swf',\n\t\t\tmime: 'application/x-shockwave-flash'\n\t\t};\n\t}\n\n\tif (check([0x7B, 0x5C, 0x72, 0x74, 0x66])) {\n\t\treturn {\n\t\t\text: 'rtf',\n\t\t\tmime: 'application/rtf'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x61, 0x73, 0x6D])) {\n\t\treturn {\n\t\t\text: 'wasm',\n\t\t\tmime: 'application/wasm'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x77, 0x4F, 0x46, 0x46]) &&\n\t\t(\n\t\t\tcheck([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||\n\t\t\tcheck([0x4F, 0x54, 0x54, 0x4F], {offset: 4})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff',\n\t\t\tmime: 'font/woff'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x77, 0x4F, 0x46, 0x32]) &&\n\t\t(\n\t\t\tcheck([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||\n\t\t\tcheck([0x4F, 0x54, 0x54, 0x4F], {offset: 4})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff2',\n\t\t\tmime: 'font/woff2'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x4C, 0x50], {offset: 34}) &&\n\t\t(\n\t\t\tcheck([0x00, 0x00, 0x01], {offset: 8}) ||\n\t\t\tcheck([0x01, 0x00, 0x02], {offset: 8}) ||\n\t\t\tcheck([0x02, 0x00, 0x02], {offset: 8})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'eot',\n\t\t\tmime: 'application/octet-stream'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x01, 0x00, 0x00, 0x00])) {\n\t\treturn {\n\t\t\text: 'ttf',\n\t\t\tmime: 'font/ttf'\n\t\t};\n\t}\n\n\tif (check([0x4F, 0x54, 0x54, 0x4F, 0x00])) {\n\t\treturn {\n\t\t\text: 'otf',\n\t\t\tmime: 'font/otf'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x00, 0x01, 0x00])) {\n\t\treturn {\n\t\t\text: 'ico',\n\t\t\tmime: 'image/x-icon'\n\t\t};\n\t}\n\n\tif (check([0x46, 0x4C, 0x56, 0x01])) {\n\t\treturn {\n\t\t\text: 'flv',\n\t\t\tmime: 'video/x-flv'\n\t\t};\n\t}\n\n\tif (check([0x25, 0x21])) {\n\t\treturn {\n\t\t\text: 'ps',\n\t\t\tmime: 'application/postscript'\n\t\t};\n\t}\n\n\tif (check([0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00])) {\n\t\treturn {\n\t\t\text: 'xz',\n\t\t\tmime: 'application/x-xz'\n\t\t};\n\t}\n\n\tif (check([0x53, 0x51, 0x4C, 0x69])) {\n\t\treturn {\n\t\t\text: 'sqlite',\n\t\t\tmime: 'application/x-sqlite3'\n\t\t};\n\t}\n\n\tif (check([0x4E, 0x45, 0x53, 0x1A])) {\n\t\treturn {\n\t\t\text: 'nes',\n\t\t\tmime: 'application/x-nintendo-nes-rom'\n\t\t};\n\t}\n\n\tif (check([0x43, 0x72, 0x32, 0x34])) {\n\t\treturn {\n\t\t\text: 'crx',\n\t\t\tmime: 'application/x-google-chrome-extension'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x4D, 0x53, 0x43, 0x46]) ||\n\t\tcheck([0x49, 0x53, 0x63, 0x28])\n\t) {\n\t\treturn {\n\t\t\text: 'cab',\n\t\t\tmime: 'application/vnd.ms-cab-compressed'\n\t\t};\n\t}\n\n\t// Needs to be before `ar` check\n\tif (check([0x21, 0x3C, 0x61, 0x72, 0x63, 0x68, 0x3E, 0x0A, 0x64, 0x65, 0x62, 0x69, 0x61, 0x6E, 0x2D, 0x62, 0x69, 0x6E, 0x61, 0x72, 0x79])) {\n\t\treturn {\n\t\t\text: 'deb',\n\t\t\tmime: 'application/x-deb'\n\t\t};\n\t}\n\n\tif (check([0x21, 0x3C, 0x61, 0x72, 0x63, 0x68, 0x3E])) {\n\t\treturn {\n\t\t\text: 'ar',\n\t\t\tmime: 'application/x-unix-archive'\n\t\t};\n\t}\n\n\tif (check([0xED, 0xAB, 0xEE, 0xDB])) {\n\t\treturn {\n\t\t\text: 'rpm',\n\t\t\tmime: 'application/x-rpm'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x1F, 0xA0]) ||\n\t\tcheck([0x1F, 0x9D])\n\t) {\n\t\treturn {\n\t\t\text: 'Z',\n\t\t\tmime: 'application/x-compress'\n\t\t};\n\t}\n\n\tif (check([0x4C, 0x5A, 0x49, 0x50])) {\n\t\treturn {\n\t\t\text: 'lz',\n\t\t\tmime: 'application/x-lzip'\n\t\t};\n\t}\n\n\tif (check([0xD0, 0xCF, 0x11, 0xE0, 0xA1, 0xB1, 0x1A, 0xE1])) {\n\t\treturn {\n\t\t\text: 'msi',\n\t\t\tmime: 'application/x-msi'\n\t\t};\n\t}\n\n\tif (check([0x06, 0x0E, 0x2B, 0x34, 0x02, 0x05, 0x01, 0x01, 0x0D, 0x01, 0x02, 0x01, 0x01, 0x02])) {\n\t\treturn {\n\t\t\text: 'mxf',\n\t\t\tmime: 'application/mxf'\n\t\t};\n\t}\n\n\tif (check([0x47], {offset: 4}) && (check([0x47], {offset: 192}) || check([0x47], {offset: 196}))) {\n\t\treturn {\n\t\t\text: 'mts',\n\t\t\tmime: 'video/mp2t'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x4C, 0x45, 0x4E, 0x44, 0x45, 0x52])) {\n\t\treturn {\n\t\t\text: 'blend',\n\t\t\tmime: 'application/x-blender'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x50, 0x47, 0xFB])) {\n\t\treturn {\n\t\t\text: 'bpg',\n\t\t\tmime: 'image/bpg'\n\t\t};\n\t}\n\n\treturn null;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/file-type@5.2.0/node_modules/file-type/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/file-type@6.2.0/node_modules/file-type/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@6.2.0/node_modules/file-type/index.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\nconst toBytes = s => Array.from(s).map(c => c.charCodeAt(0));\nconst xpiZipFilename = toBytes('META-INF/mozilla.rsa');\nconst oxmlContentTypes = toBytes('[Content_Types].xml');\nconst oxmlRels = toBytes('_rels/.rels');\n\nmodule.exports = input => {\n\tconst buf = new Uint8Array(input);\n\n\tif (!(buf && buf.length > 1)) {\n\t\treturn null;\n\t}\n\n\tconst check = (header, opts) => {\n\t\topts = Object.assign({\n\t\t\toffset: 0\n\t\t}, opts);\n\n\t\tfor (let i = 0; i < header.length; i++) {\n\t\t\t// If a bitmask is set\n\t\t\tif (opts.mask) {\n\t\t\t\t// If header doesn't equal `buf` with bits masked off\n\t\t\t\tif (header[i] !== (opts.mask[i] & buf[i + opts.offset])) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t} else if (header[i] !== buf[i + opts.offset]) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\treturn true;\n\t};\n\n\tif (check([0xFF, 0xD8, 0xFF])) {\n\t\treturn {\n\t\t\text: 'jpg',\n\t\t\tmime: 'image/jpeg'\n\t\t};\n\t}\n\n\tif (check([0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\treturn {\n\t\t\text: 'png',\n\t\t\tmime: 'image/png'\n\t\t};\n\t}\n\n\tif (check([0x47, 0x49, 0x46])) {\n\t\treturn {\n\t\t\text: 'gif',\n\t\t\tmime: 'image/gif'\n\t\t};\n\t}\n\n\tif (check([0x57, 0x45, 0x42, 0x50], {offset: 8})) {\n\t\treturn {\n\t\t\text: 'webp',\n\t\t\tmime: 'image/webp'\n\t\t};\n\t}\n\n\tif (check([0x46, 0x4C, 0x49, 0x46])) {\n\t\treturn {\n\t\t\text: 'flif',\n\t\t\tmime: 'image/flif'\n\t\t};\n\t}\n\n\t// Needs to be before `tif` check\n\tif (\n\t\t(check([0x49, 0x49, 0x2A, 0x0]) || check([0x4D, 0x4D, 0x0, 0x2A])) &&\n\t\tcheck([0x43, 0x52], {offset: 8})\n\t) {\n\t\treturn {\n\t\t\text: 'cr2',\n\t\t\tmime: 'image/x-canon-cr2'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x49, 0x49, 0x2A, 0x0]) ||\n\t\tcheck([0x4D, 0x4D, 0x0, 0x2A])\n\t) {\n\t\treturn {\n\t\t\text: 'tif',\n\t\t\tmime: 'image/tiff'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x4D])) {\n\t\treturn {\n\t\t\text: 'bmp',\n\t\t\tmime: 'image/bmp'\n\t\t};\n\t}\n\n\tif (check([0x49, 0x49, 0xBC])) {\n\t\treturn {\n\t\t\text: 'jxr',\n\t\t\tmime: 'image/vnd.ms-photo'\n\t\t};\n\t}\n\n\tif (check([0x38, 0x42, 0x50, 0x53])) {\n\t\treturn {\n\t\t\text: 'psd',\n\t\t\tmime: 'image/vnd.adobe.photoshop'\n\t\t};\n\t}\n\n\t// Zip-based file formats\n\t// Need to be before the `zip` check\n\tif (check([0x50, 0x4B, 0x3, 0x4])) {\n\t\tif (\n\t\t\tcheck([0x6D, 0x69, 0x6D, 0x65, 0x74, 0x79, 0x70, 0x65, 0x61, 0x70, 0x70, 0x6C, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6F, 0x6E, 0x2F, 0x65, 0x70, 0x75, 0x62, 0x2B, 0x7A, 0x69, 0x70], {offset: 30})\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'epub',\n\t\t\t\tmime: 'application/epub+zip'\n\t\t\t};\n\t\t}\n\n\t\t// Assumes signed `.xpi` from addons.mozilla.org\n\t\tif (check(xpiZipFilename, {offset: 30})) {\n\t\t\treturn {\n\t\t\t\text: 'xpi',\n\t\t\t\tmime: 'application/x-xpinstall'\n\t\t\t};\n\t\t}\n\n\t\t// https://github.com/file/file/blob/master/magic/Magdir/msooxml\n\t\tif (check(oxmlContentTypes, {offset: 30}) || check(oxmlRels, {offset: 30})) {\n\t\t\tconst sliced = buf.subarray(4, 4 + 2000);\n\t\t\tconst nextZipHeaderIndex = arr => arr.findIndex((el, i, arr) => arr[i] === 0x50 && arr[i + 1] === 0x4B && arr[i + 2] === 0x3 && arr[i + 3] === 0x4);\n\t\t\tconst header2Pos = nextZipHeaderIndex(sliced);\n\n\t\t\tif (header2Pos !== -1) {\n\t\t\t\tconst slicedAgain = buf.subarray(header2Pos + 8, header2Pos + 8 + 1000);\n\t\t\t\tconst header3Pos = nextZipHeaderIndex(slicedAgain);\n\n\t\t\t\tif (header3Pos !== -1) {\n\t\t\t\t\tconst offset = 8 + header2Pos + header3Pos + 30;\n\n\t\t\t\t\tif (check(toBytes('word/'), {offset})) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'docx',\n\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (check(toBytes('ppt/'), {offset})) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'pptx',\n\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.presentationml.presentation'\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (check(toBytes('xl/'), {offset})) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'xlsx',\n\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (\n\t\tcheck([0x50, 0x4B]) &&\n\t\t(buf[2] === 0x3 || buf[2] === 0x5 || buf[2] === 0x7) &&\n\t\t(buf[3] === 0x4 || buf[3] === 0x6 || buf[3] === 0x8)\n\t) {\n\t\treturn {\n\t\t\text: 'zip',\n\t\t\tmime: 'application/zip'\n\t\t};\n\t}\n\n\tif (check([0x75, 0x73, 0x74, 0x61, 0x72], {offset: 257})) {\n\t\treturn {\n\t\t\text: 'tar',\n\t\t\tmime: 'application/x-tar'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x52, 0x61, 0x72, 0x21, 0x1A, 0x7]) &&\n\t\t(buf[6] === 0x0 || buf[6] === 0x1)\n\t) {\n\t\treturn {\n\t\t\text: 'rar',\n\t\t\tmime: 'application/x-rar-compressed'\n\t\t};\n\t}\n\n\tif (check([0x1F, 0x8B, 0x8])) {\n\t\treturn {\n\t\t\text: 'gz',\n\t\t\tmime: 'application/gzip'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x5A, 0x68])) {\n\t\treturn {\n\t\t\text: 'bz2',\n\t\t\tmime: 'application/x-bzip2'\n\t\t};\n\t}\n\n\tif (check([0x37, 0x7A, 0xBC, 0xAF, 0x27, 0x1C])) {\n\t\treturn {\n\t\t\text: '7z',\n\t\t\tmime: 'application/x-7z-compressed'\n\t\t};\n\t}\n\n\tif (check([0x78, 0x01])) {\n\t\treturn {\n\t\t\text: 'dmg',\n\t\t\tmime: 'application/x-apple-diskimage'\n\t\t};\n\t}\n\n\tif (check([0x33, 0x67, 0x70, 0x35]) || // 3gp5\n\t\t(\n\t\t\tcheck([0x0, 0x0, 0x0]) && check([0x66, 0x74, 0x79, 0x70], {offset: 4}) &&\n\t\t\t\t(\n\t\t\t\t\tcheck([0x6D, 0x70, 0x34, 0x31], {offset: 8}) || // MP41\n\t\t\t\t\tcheck([0x6D, 0x70, 0x34, 0x32], {offset: 8}) || // MP42\n\t\t\t\t\tcheck([0x69, 0x73, 0x6F, 0x6D], {offset: 8}) || // ISOM\n\t\t\t\t\tcheck([0x69, 0x73, 0x6F, 0x32], {offset: 8}) || // ISO2\n\t\t\t\t\tcheck([0x6D, 0x6D, 0x70, 0x34], {offset: 8}) || // MMP4\n\t\t\t\t\tcheck([0x4D, 0x34, 0x56], {offset: 8}) || // M4V\n\t\t\t\t\tcheck([0x64, 0x61, 0x73, 0x68], {offset: 8}) // DASH\n\t\t\t\t)\n\t\t)) {\n\t\treturn {\n\t\t\text: 'mp4',\n\t\t\tmime: 'video/mp4'\n\t\t};\n\t}\n\n\tif (check([0x4D, 0x54, 0x68, 0x64])) {\n\t\treturn {\n\t\t\text: 'mid',\n\t\t\tmime: 'audio/midi'\n\t\t};\n\t}\n\n\t// https://github.com/threatstack/libmagic/blob/master/magic/Magdir/matroska\n\tif (check([0x1A, 0x45, 0xDF, 0xA3])) {\n\t\tconst sliced = buf.subarray(4, 4 + 4096);\n\t\tconst idPos = sliced.findIndex((el, i, arr) => arr[i] === 0x42 && arr[i + 1] === 0x82);\n\n\t\tif (idPos !== -1) {\n\t\t\tconst docTypePos = idPos + 3;\n\t\t\tconst findDocType = type => Array.from(type).every((c, i) => sliced[docTypePos + i] === c.charCodeAt(0));\n\n\t\t\tif (findDocType('matroska')) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mkv',\n\t\t\t\t\tmime: 'video/x-matroska'\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (findDocType('webm')) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'webm',\n\t\t\t\t\tmime: 'video/webm'\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\tif (check([0x0, 0x0, 0x0, 0x14, 0x66, 0x74, 0x79, 0x70, 0x71, 0x74, 0x20, 0x20]) ||\n\t\tcheck([0x66, 0x72, 0x65, 0x65], {offset: 4}) ||\n\t\tcheck([0x66, 0x74, 0x79, 0x70, 0x71, 0x74, 0x20, 0x20], {offset: 4}) ||\n\t\tcheck([0x6D, 0x64, 0x61, 0x74], {offset: 4}) || // MJPEG\n\t\tcheck([0x77, 0x69, 0x64, 0x65], {offset: 4})) {\n\t\treturn {\n\t\t\text: 'mov',\n\t\t\tmime: 'video/quicktime'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x52, 0x49, 0x46, 0x46]) &&\n\t\tcheck([0x41, 0x56, 0x49], {offset: 8})\n\t) {\n\t\treturn {\n\t\t\text: 'avi',\n\t\t\tmime: 'video/x-msvideo'\n\t\t};\n\t}\n\n\tif (check([0x30, 0x26, 0xB2, 0x75, 0x8E, 0x66, 0xCF, 0x11, 0xA6, 0xD9])) {\n\t\treturn {\n\t\t\text: 'wmv',\n\t\t\tmime: 'video/x-ms-wmv'\n\t\t};\n\t}\n\n\tif (check([0x0, 0x0, 0x1, 0xBA])) {\n\t\treturn {\n\t\t\text: 'mpg',\n\t\t\tmime: 'video/mpeg'\n\t\t};\n\t}\n\n\t// Check for MP3 header at different starting offsets\n\tfor (let start = 0; start < 2 && start < (buf.length - 16); start++) {\n\t\tif (\n\t\t\tcheck([0x49, 0x44, 0x33], {offset: start}) || // ID3 header\n\t\t\tcheck([0xFF, 0xE2], {offset: start, mask: [0xFF, 0xE2]}) // MPEG 1 or 2 Layer 3 header\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'mp3',\n\t\t\t\tmime: 'audio/mpeg'\n\t\t\t};\n\t\t}\n\t}\n\n\tif (\n\t\tcheck([0x66, 0x74, 0x79, 0x70, 0x4D, 0x34, 0x41], {offset: 4}) ||\n\t\tcheck([0x4D, 0x34, 0x41, 0x20])\n\t) {\n\t\treturn {\n\t\t\text: 'm4a',\n\t\t\tmime: 'audio/m4a'\n\t\t};\n\t}\n\n\t// Needs to be before `ogg` check\n\tif (check([0x4F, 0x70, 0x75, 0x73, 0x48, 0x65, 0x61, 0x64], {offset: 28})) {\n\t\treturn {\n\t\t\text: 'opus',\n\t\t\tmime: 'audio/opus'\n\t\t};\n\t}\n\n\tif (check([0x4F, 0x67, 0x67, 0x53])) {\n\t\treturn {\n\t\t\text: 'ogg',\n\t\t\tmime: 'audio/ogg'\n\t\t};\n\t}\n\n\tif (check([0x66, 0x4C, 0x61, 0x43])) {\n\t\treturn {\n\t\t\text: 'flac',\n\t\t\tmime: 'audio/x-flac'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x52, 0x49, 0x46, 0x46]) &&\n\t\tcheck([0x57, 0x41, 0x56, 0x45], {offset: 8})\n\t) {\n\t\treturn {\n\t\t\text: 'wav',\n\t\t\tmime: 'audio/x-wav'\n\t\t};\n\t}\n\n\tif (check([0x23, 0x21, 0x41, 0x4D, 0x52, 0x0A])) {\n\t\treturn {\n\t\t\text: 'amr',\n\t\t\tmime: 'audio/amr'\n\t\t};\n\t}\n\n\tif (check([0x25, 0x50, 0x44, 0x46])) {\n\t\treturn {\n\t\t\text: 'pdf',\n\t\t\tmime: 'application/pdf'\n\t\t};\n\t}\n\n\tif (check([0x4D, 0x5A])) {\n\t\treturn {\n\t\t\text: 'exe',\n\t\t\tmime: 'application/x-msdownload'\n\t\t};\n\t}\n\n\tif (\n\t\t(buf[0] === 0x43 || buf[0] === 0x46) &&\n\t\tcheck([0x57, 0x53], {offset: 1})\n\t) {\n\t\treturn {\n\t\t\text: 'swf',\n\t\t\tmime: 'application/x-shockwave-flash'\n\t\t};\n\t}\n\n\tif (check([0x7B, 0x5C, 0x72, 0x74, 0x66])) {\n\t\treturn {\n\t\t\text: 'rtf',\n\t\t\tmime: 'application/rtf'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x61, 0x73, 0x6D])) {\n\t\treturn {\n\t\t\text: 'wasm',\n\t\t\tmime: 'application/wasm'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x77, 0x4F, 0x46, 0x46]) &&\n\t\t(\n\t\t\tcheck([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||\n\t\t\tcheck([0x4F, 0x54, 0x54, 0x4F], {offset: 4})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff',\n\t\t\tmime: 'font/woff'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x77, 0x4F, 0x46, 0x32]) &&\n\t\t(\n\t\t\tcheck([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||\n\t\t\tcheck([0x4F, 0x54, 0x54, 0x4F], {offset: 4})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff2',\n\t\t\tmime: 'font/woff2'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x4C, 0x50], {offset: 34}) &&\n\t\t(\n\t\t\tcheck([0x00, 0x00, 0x01], {offset: 8}) ||\n\t\t\tcheck([0x01, 0x00, 0x02], {offset: 8}) ||\n\t\t\tcheck([0x02, 0x00, 0x02], {offset: 8})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'eot',\n\t\t\tmime: 'application/octet-stream'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x01, 0x00, 0x00, 0x00])) {\n\t\treturn {\n\t\t\text: 'ttf',\n\t\t\tmime: 'font/ttf'\n\t\t};\n\t}\n\n\tif (check([0x4F, 0x54, 0x54, 0x4F, 0x00])) {\n\t\treturn {\n\t\t\text: 'otf',\n\t\t\tmime: 'font/otf'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x00, 0x01, 0x00])) {\n\t\treturn {\n\t\t\text: 'ico',\n\t\t\tmime: 'image/x-icon'\n\t\t};\n\t}\n\n\tif (check([0x46, 0x4C, 0x56, 0x01])) {\n\t\treturn {\n\t\t\text: 'flv',\n\t\t\tmime: 'video/x-flv'\n\t\t};\n\t}\n\n\tif (check([0x25, 0x21])) {\n\t\treturn {\n\t\t\text: 'ps',\n\t\t\tmime: 'application/postscript'\n\t\t};\n\t}\n\n\tif (check([0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00])) {\n\t\treturn {\n\t\t\text: 'xz',\n\t\t\tmime: 'application/x-xz'\n\t\t};\n\t}\n\n\tif (check([0x53, 0x51, 0x4C, 0x69])) {\n\t\treturn {\n\t\t\text: 'sqlite',\n\t\t\tmime: 'application/x-sqlite3'\n\t\t};\n\t}\n\n\tif (check([0x4E, 0x45, 0x53, 0x1A])) {\n\t\treturn {\n\t\t\text: 'nes',\n\t\t\tmime: 'application/x-nintendo-nes-rom'\n\t\t};\n\t}\n\n\tif (check([0x43, 0x72, 0x32, 0x34])) {\n\t\treturn {\n\t\t\text: 'crx',\n\t\t\tmime: 'application/x-google-chrome-extension'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x4D, 0x53, 0x43, 0x46]) ||\n\t\tcheck([0x49, 0x53, 0x63, 0x28])\n\t) {\n\t\treturn {\n\t\t\text: 'cab',\n\t\t\tmime: 'application/vnd.ms-cab-compressed'\n\t\t};\n\t}\n\n\t// Needs to be before `ar` check\n\tif (check([0x21, 0x3C, 0x61, 0x72, 0x63, 0x68, 0x3E, 0x0A, 0x64, 0x65, 0x62, 0x69, 0x61, 0x6E, 0x2D, 0x62, 0x69, 0x6E, 0x61, 0x72, 0x79])) {\n\t\treturn {\n\t\t\text: 'deb',\n\t\t\tmime: 'application/x-deb'\n\t\t};\n\t}\n\n\tif (check([0x21, 0x3C, 0x61, 0x72, 0x63, 0x68, 0x3E])) {\n\t\treturn {\n\t\t\text: 'ar',\n\t\t\tmime: 'application/x-unix-archive'\n\t\t};\n\t}\n\n\tif (check([0xED, 0xAB, 0xEE, 0xDB])) {\n\t\treturn {\n\t\t\text: 'rpm',\n\t\t\tmime: 'application/x-rpm'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x1F, 0xA0]) ||\n\t\tcheck([0x1F, 0x9D])\n\t) {\n\t\treturn {\n\t\t\text: 'Z',\n\t\t\tmime: 'application/x-compress'\n\t\t};\n\t}\n\n\tif (check([0x4C, 0x5A, 0x49, 0x50])) {\n\t\treturn {\n\t\t\text: 'lz',\n\t\t\tmime: 'application/x-lzip'\n\t\t};\n\t}\n\n\tif (check([0xD0, 0xCF, 0x11, 0xE0, 0xA1, 0xB1, 0x1A, 0xE1])) {\n\t\treturn {\n\t\t\text: 'msi',\n\t\t\tmime: 'application/x-msi'\n\t\t};\n\t}\n\n\tif (check([0x06, 0x0E, 0x2B, 0x34, 0x02, 0x05, 0x01, 0x01, 0x0D, 0x01, 0x02, 0x01, 0x01, 0x02])) {\n\t\treturn {\n\t\t\text: 'mxf',\n\t\t\tmime: 'application/mxf'\n\t\t};\n\t}\n\n\tif (check([0x47], {offset: 4}) && (check([0x47], {offset: 192}) || check([0x47], {offset: 196}))) {\n\t\treturn {\n\t\t\text: 'mts',\n\t\t\tmime: 'video/mp2t'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x4C, 0x45, 0x4E, 0x44, 0x45, 0x52])) {\n\t\treturn {\n\t\t\text: 'blend',\n\t\t\tmime: 'application/x-blender'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x50, 0x47, 0xFB])) {\n\t\treturn {\n\t\t\text: 'bpg',\n\t\t\tmime: 'image/bpg'\n\t\t};\n\t}\n\n\treturn null;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/file-type@6.2.0/node_modules/file-type/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/fs-constants@1.0.0/node_modules/fs-constants/index.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/.pnpm/fs-constants@1.0.0/node_modules/fs-constants/index.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = (__webpack_require__(/*! fs */ \"fs\").constants) || __webpack_require__(/*! constants */ \"constants\")\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/fs-constants@1.0.0/node_modules/fs-constants/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/buffer-stream.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/buffer-stream.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var PassThrough = (__webpack_require__(/*! stream */ \"stream\").PassThrough);\nvar objectAssign = __webpack_require__(/*! object-assign */ \"./node_modules/.pnpm/object-assign@4.1.1/node_modules/object-assign/index.js\");\n\nmodule.exports = function (opts) {\n\topts = objectAssign({}, opts);\n\n\tvar array = opts.array;\n\tvar encoding = opts.encoding;\n\n\tvar buffer = encoding === 'buffer';\n\tvar objectMode = false;\n\n\tif (array) {\n\t\tobjectMode = !(encoding || buffer);\n\t} else {\n\t\tencoding = encoding || 'utf8';\n\t}\n\n\tif (buffer) {\n\t\tencoding = null;\n\t}\n\n\tvar len = 0;\n\tvar ret = [];\n\n\tvar stream = new PassThrough({objectMode: objectMode});\n\n\tif (encoding) {\n\t\tstream.setEncoding(encoding);\n\t}\n\n\tstream.on('data', function (chunk) {\n\t\tret.push(chunk);\n\n\t\tif (objectMode) {\n\t\t\tlen = ret.length;\n\t\t} else {\n\t\t\tlen += chunk.length;\n\t\t}\n\t});\n\n\tstream.getBufferedValue = function () {\n\t\tif (array) {\n\t\t\treturn ret;\n\t\t}\n\t\treturn buffer ? Buffer.concat(ret, len) : ret.join('');\n\t};\n\n\tstream.getBufferedLength = function () {\n\t\treturn len;\n\t};\n\n\treturn stream;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/buffer-stream.js?");

/***/ }),

/***/ "./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/index.js":
/*!******************************************************************************!*\
  !*** ./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/index.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar Promise = __webpack_require__(/*! pinkie-promise */ \"./node_modules/.pnpm/pinkie-promise@2.0.1/node_modules/pinkie-promise/index.js\");\nvar objectAssign = __webpack_require__(/*! object-assign */ \"./node_modules/.pnpm/object-assign@4.1.1/node_modules/object-assign/index.js\");\nvar bufferStream = __webpack_require__(/*! ./buffer-stream */ \"./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/buffer-stream.js\");\n\nfunction getStream(inputStream, opts) {\n\tif (!inputStream) {\n\t\treturn Promise.reject(new Error('Expected a stream'));\n\t}\n\n\topts = objectAssign({maxBuffer: Infinity}, opts);\n\tvar maxBuffer = opts.maxBuffer;\n\tvar stream;\n\tvar clean;\n\n\tvar p = new Promise(function (resolve, reject) {\n\t\tstream = bufferStream(opts);\n\t\tinputStream.once('error', error);\n\t\tinputStream.pipe(stream);\n\n\t\tstream.on('data', function () {\n\t\t\tif (stream.getBufferedLength() > maxBuffer) {\n\t\t\t\treject(new Error('maxBuffer exceeded'));\n\t\t\t}\n\t\t});\n\t\tstream.once('error', error);\n\t\tstream.on('end', resolve);\n\n\t\tclean = function () {\n\t\t\t// some streams doesn't implement the stream.Readable interface correctly\n\t\t\tif (inputStream.unpipe) {\n\t\t\t\tinputStream.unpipe(stream);\n\t\t\t}\n\t\t};\n\n\t\tfunction error(err) {\n\t\t\tif (err) { // null check\n\t\t\t\terr.bufferedData = stream.getBufferedValue();\n\t\t\t}\n\t\t\treject(err);\n\t\t}\n\t});\n\n\tp.then(clean, clean);\n\n\treturn p.then(function () {\n\t\treturn stream.getBufferedValue();\n\t});\n}\n\nmodule.exports = getStream;\n\nmodule.exports.buffer = function (stream, opts) {\n\treturn getStream(stream, objectAssign({}, opts, {encoding: 'buffer'}));\n};\n\nmodule.exports.array = function (stream, opts) {\n\treturn getStream(stream, objectAssign({}, opts, {array: true}));\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/get-stream@2.3.1/node_modules/get-stream/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/clone.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/clone.js ***!
  \*********************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = clone\n\nvar getPrototypeOf = Object.getPrototypeOf || function (obj) {\n  return obj.__proto__\n}\n\nfunction clone (obj) {\n  if (obj === null || typeof obj !== 'object')\n    return obj\n\n  if (obj instanceof Object)\n    var copy = { __proto__: getPrototypeOf(obj) }\n  else\n    var copy = Object.create(null)\n\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key))\n  })\n\n  return copy\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/clone.js?");

/***/ }),

/***/ "./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/graceful-fs.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/graceful-fs.js ***!
  \***************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var fs = __webpack_require__(/*! fs */ \"fs\")\nvar polyfills = __webpack_require__(/*! ./polyfills.js */ \"./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/polyfills.js\")\nvar legacy = __webpack_require__(/*! ./legacy-streams.js */ \"./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/legacy-streams.js\")\nvar clone = __webpack_require__(/*! ./clone.js */ \"./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/clone.js\")\n\nvar util = __webpack_require__(/*! util */ \"util\")\n\n/* istanbul ignore next - node 0.x polyfill */\nvar gracefulQueue\nvar previousSymbol\n\n/* istanbul ignore else - node 0.x polyfill */\nif (typeof Symbol === 'function' && typeof Symbol.for === 'function') {\n  gracefulQueue = Symbol.for('graceful-fs.queue')\n  // This is used in testing by future versions\n  previousSymbol = Symbol.for('graceful-fs.previous')\n} else {\n  gracefulQueue = '___graceful-fs.queue'\n  previousSymbol = '___graceful-fs.previous'\n}\n\nfunction noop () {}\n\nfunction publishQueue(context, queue) {\n  Object.defineProperty(context, gracefulQueue, {\n    get: function() {\n      return queue\n    }\n  })\n}\n\nvar debug = noop\nif (util.debuglog)\n  debug = util.debuglog('gfs4')\nelse if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ')\n    console.error(m)\n  }\n\n// Once time initialization\nif (!fs[gracefulQueue]) {\n  // This queue can be shared by multiple loaded instances\n  var queue = global[gracefulQueue] || []\n  publishQueue(fs, queue)\n\n  // Patch fs.close/closeSync to shared queue version, because we need\n  // to retry() whenever a close happens *anywhere* in the program.\n  // This is essential when multiple graceful-fs instances are\n  // in play at the same time.\n  fs.close = (function (fs$close) {\n    function close (fd, cb) {\n      return fs$close.call(fs, fd, function (err) {\n        // This function uses the graceful-fs shared queue\n        if (!err) {\n          resetQueue()\n        }\n\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n      })\n    }\n\n    Object.defineProperty(close, previousSymbol, {\n      value: fs$close\n    })\n    return close\n  })(fs.close)\n\n  fs.closeSync = (function (fs$closeSync) {\n    function closeSync (fd) {\n      // This function uses the graceful-fs shared queue\n      fs$closeSync.apply(fs, arguments)\n      resetQueue()\n    }\n\n    Object.defineProperty(closeSync, previousSymbol, {\n      value: fs$closeSync\n    })\n    return closeSync\n  })(fs.closeSync)\n\n  if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n    process.on('exit', function() {\n      debug(fs[gracefulQueue])\n      __webpack_require__(/*! assert */ \"assert\").equal(fs[gracefulQueue].length, 0)\n    })\n  }\n}\n\nif (!global[gracefulQueue]) {\n  publishQueue(global, fs[gracefulQueue]);\n}\n\nmodule.exports = patch(clone(fs))\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {\n    module.exports = patch(fs)\n    fs.__patched = true;\n}\n\nfunction patch (fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs)\n  fs.gracefulify = patch\n\n  fs.createReadStream = createReadStream\n  fs.createWriteStream = createWriteStream\n  var fs$readFile = fs.readFile\n  fs.readFile = readFile\n  function readFile (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readFile(path, options, cb)\n\n    function go$readFile (path, options, cb, startTime) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readFile, [path, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$writeFile = fs.writeFile\n  fs.writeFile = writeFile\n  function writeFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$writeFile(path, data, options, cb)\n\n    function go$writeFile (path, data, options, cb, startTime) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$writeFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$appendFile = fs.appendFile\n  if (fs$appendFile)\n    fs.appendFile = appendFile\n  function appendFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$appendFile(path, data, options, cb)\n\n    function go$appendFile (path, data, options, cb, startTime) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$appendFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$copyFile = fs.copyFile\n  if (fs$copyFile)\n    fs.copyFile = copyFile\n  function copyFile (src, dest, flags, cb) {\n    if (typeof flags === 'function') {\n      cb = flags\n      flags = 0\n    }\n    return go$copyFile(src, dest, flags, cb)\n\n    function go$copyFile (src, dest, flags, cb, startTime) {\n      return fs$copyFile(src, dest, flags, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$copyFile, [src, dest, flags, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$readdir = fs.readdir\n  fs.readdir = readdir\n  var noReaddirOptionVersions = /^v[0-5]\\./\n  function readdir (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    var go$readdir = noReaddirOptionVersions.test(process.version)\n      ? function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n      : function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, options, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n\n    return go$readdir(path, options, cb)\n\n    function fs$readdirCallback (path, options, cb, startTime) {\n      return function (err, files) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([\n            go$readdir,\n            [path, options, cb],\n            err,\n            startTime || Date.now(),\n            Date.now()\n          ])\n        else {\n          if (files && files.sort)\n            files.sort()\n\n          if (typeof cb === 'function')\n            cb.call(this, err, files)\n        }\n      }\n    }\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs)\n    ReadStream = legStreams.ReadStream\n    WriteStream = legStreams.WriteStream\n  }\n\n  var fs$ReadStream = fs.ReadStream\n  if (fs$ReadStream) {\n    ReadStream.prototype = Object.create(fs$ReadStream.prototype)\n    ReadStream.prototype.open = ReadStream$open\n  }\n\n  var fs$WriteStream = fs.WriteStream\n  if (fs$WriteStream) {\n    WriteStream.prototype = Object.create(fs$WriteStream.prototype)\n    WriteStream.prototype.open = WriteStream$open\n  }\n\n  Object.defineProperty(fs, 'ReadStream', {\n    get: function () {\n      return ReadStream\n    },\n    set: function (val) {\n      ReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  Object.defineProperty(fs, 'WriteStream', {\n    get: function () {\n      return WriteStream\n    },\n    set: function (val) {\n      WriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  // legacy names\n  var FileReadStream = ReadStream\n  Object.defineProperty(fs, 'FileReadStream', {\n    get: function () {\n      return FileReadStream\n    },\n    set: function (val) {\n      FileReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  var FileWriteStream = WriteStream\n  Object.defineProperty(fs, 'FileWriteStream', {\n    get: function () {\n      return FileWriteStream\n    },\n    set: function (val) {\n      FileWriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  function ReadStream (path, options) {\n    if (this instanceof ReadStream)\n      return fs$ReadStream.apply(this, arguments), this\n    else\n      return ReadStream.apply(Object.create(ReadStream.prototype), arguments)\n  }\n\n  function ReadStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose)\n          that.destroy()\n\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n        that.read()\n      }\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (this instanceof WriteStream)\n      return fs$WriteStream.apply(this, arguments), this\n    else\n      return WriteStream.apply(Object.create(WriteStream.prototype), arguments)\n  }\n\n  function WriteStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy()\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n      }\n    })\n  }\n\n  function createReadStream (path, options) {\n    return new fs.ReadStream(path, options)\n  }\n\n  function createWriteStream (path, options) {\n    return new fs.WriteStream(path, options)\n  }\n\n  var fs$open = fs.open\n  fs.open = open\n  function open (path, flags, mode, cb) {\n    if (typeof mode === 'function')\n      cb = mode, mode = null\n\n    return go$open(path, flags, mode, cb)\n\n    function go$open (path, flags, mode, cb, startTime) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$open, [path, flags, mode, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  return fs\n}\n\nfunction enqueue (elem) {\n  debug('ENQUEUE', elem[0].name, elem[1])\n  fs[gracefulQueue].push(elem)\n  retry()\n}\n\n// keep track of the timeout between retry() calls\nvar retryTimer\n\n// reset the startTime and lastTime to now\n// this resets the start of the 60 second overall timeout as well as the\n// delay between attempts so that we'll retry these jobs sooner\nfunction resetQueue () {\n  var now = Date.now()\n  for (var i = 0; i < fs[gracefulQueue].length; ++i) {\n    // entries that are only a length of 2 are from an older version, don't\n    // bother modifying those since they'll be retried anyway.\n    if (fs[gracefulQueue][i].length > 2) {\n      fs[gracefulQueue][i][3] = now // startTime\n      fs[gracefulQueue][i][4] = now // lastTime\n    }\n  }\n  // call retry to make sure we're actively processing the queue\n  retry()\n}\n\nfunction retry () {\n  // clear the timer and remove it to help prevent unintended concurrency\n  clearTimeout(retryTimer)\n  retryTimer = undefined\n\n  if (fs[gracefulQueue].length === 0)\n    return\n\n  var elem = fs[gracefulQueue].shift()\n  var fn = elem[0]\n  var args = elem[1]\n  // these items may be unset if they were added by an older graceful-fs\n  var err = elem[2]\n  var startTime = elem[3]\n  var lastTime = elem[4]\n\n  // if we don't have a startTime we have no way of knowing if we've waited\n  // long enough, so go ahead and retry this item now\n  if (startTime === undefined) {\n    debug('RETRY', fn.name, args)\n    fn.apply(null, args)\n  } else if (Date.now() - startTime >= 60000) {\n    // it's been more than 60 seconds total, bail now\n    debug('TIMEOUT', fn.name, args)\n    var cb = args.pop()\n    if (typeof cb === 'function')\n      cb.call(null, err)\n  } else {\n    // the amount of time between the last attempt and right now\n    var sinceAttempt = Date.now() - lastTime\n    // the amount of time between when we first tried, and when we last tried\n    // rounded up to at least 1\n    var sinceStart = Math.max(lastTime - startTime, 1)\n    // backoff. wait longer than the total time we've been retrying, but only\n    // up to a maximum of 100ms\n    var desiredDelay = Math.min(sinceStart * 1.2, 100)\n    // it's been long enough since the last retry, do it again\n    if (sinceAttempt >= desiredDelay) {\n      debug('RETRY', fn.name, args)\n      fn.apply(null, args.concat([startTime]))\n    } else {\n      // if we can't do this job yet, push it to the end of the queue\n      // and let the next iteration check again\n      fs[gracefulQueue].push(elem)\n    }\n  }\n\n  // schedule our next run if one isn't already scheduled\n  if (retryTimer === undefined) {\n    retryTimer = setTimeout(retry, 0)\n  }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/graceful-fs.js?");

/***/ }),

/***/ "./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/legacy-streams.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/legacy-streams.js ***!
  \******************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Stream = (__webpack_require__(/*! stream */ \"stream\").Stream)\n\nmodule.exports = legacy\n\nfunction legacy (fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  }\n\n  function ReadStream (path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n\n    Stream.call(this);\n\n    var self = this;\n\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n\n    this.flags = 'r';\n    this.mode = 438; /*=0666*/\n    this.bufferSize = 64 * 1024;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function() {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n      self._read();\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n\n    Stream.call(this);\n\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438; /*=0666*/\n    this.bytesWritten = 0;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n      this.flush();\n    }\n  }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/legacy-streams.js?");

/***/ }),

/***/ "./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/polyfills.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/polyfills.js ***!
  \*************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var constants = __webpack_require__(/*! constants */ \"constants\")\n\nvar origCwd = process.cwd\nvar cwd = null\n\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform\n\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\ntry {\n  process.cwd()\n} catch (er) {}\n\n// This check is needed until node.js 12 is required\nif (typeof process.chdir === 'function') {\n  var chdir = process.chdir\n  process.chdir = function (d) {\n    cwd = null\n    chdir.call(process, d)\n  }\n  if (Object.setPrototypeOf) Object.setPrototypeOf(process.chdir, chdir)\n}\n\nmodule.exports = patch\n\nfunction patch (fs) {\n  // (re-)implement some things that are known busted or missing.\n\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') &&\n      process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs)\n  }\n\n  // lutimes implementation, or no-op\n  if (!fs.lutimes) {\n    patchLutimes(fs)\n  }\n\n  // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n  fs.chown = chownFix(fs.chown)\n  fs.fchown = chownFix(fs.fchown)\n  fs.lchown = chownFix(fs.lchown)\n\n  fs.chmod = chmodFix(fs.chmod)\n  fs.fchmod = chmodFix(fs.fchmod)\n  fs.lchmod = chmodFix(fs.lchmod)\n\n  fs.chownSync = chownFixSync(fs.chownSync)\n  fs.fchownSync = chownFixSync(fs.fchownSync)\n  fs.lchownSync = chownFixSync(fs.lchownSync)\n\n  fs.chmodSync = chmodFixSync(fs.chmodSync)\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync)\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync)\n\n  fs.stat = statFix(fs.stat)\n  fs.fstat = statFix(fs.fstat)\n  fs.lstat = statFix(fs.lstat)\n\n  fs.statSync = statFixSync(fs.statSync)\n  fs.fstatSync = statFixSync(fs.fstatSync)\n  fs.lstatSync = statFixSync(fs.lstatSync)\n\n  // if lchmod/lchown do not exist, then make them no-ops\n  if (fs.chmod && !fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchmodSync = function () {}\n  }\n  if (fs.chown && !fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchownSync = function () {}\n  }\n\n  // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n  if (platform === \"win32\") {\n    fs.rename = typeof fs.rename !== 'function' ? fs.rename\n    : (function (fs$rename) {\n      function rename (from, to, cb) {\n        var start = Date.now()\n        var backoff = 0;\n        fs$rename(from, to, function CB (er) {\n          if (er\n              && (er.code === \"EACCES\" || er.code === \"EPERM\")\n              && Date.now() - start < 60000) {\n            setTimeout(function() {\n              fs.stat(to, function (stater, st) {\n                if (stater && stater.code === \"ENOENT\")\n                  fs$rename(from, to, CB);\n                else\n                  cb(er)\n              })\n            }, backoff)\n            if (backoff < 100)\n              backoff += 10;\n            return;\n          }\n          if (cb) cb(er)\n        })\n      }\n      if (Object.setPrototypeOf) Object.setPrototypeOf(rename, fs$rename)\n      return rename\n    })(fs.rename)\n  }\n\n  // if read() returns EAGAIN, then just try it again.\n  fs.read = typeof fs.read !== 'function' ? fs.read\n  : (function (fs$read) {\n    function read (fd, buffer, offset, length, position, callback_) {\n      var callback\n      if (callback_ && typeof callback_ === 'function') {\n        var eagCounter = 0\n        callback = function (er, _, __) {\n          if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter ++\n            return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n          }\n          callback_.apply(this, arguments)\n        }\n      }\n      return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n    }\n\n    // This ensures `util.promisify` works as it does for native `fs.read`.\n    if (Object.setPrototypeOf) Object.setPrototypeOf(read, fs$read)\n    return read\n  })(fs.read)\n\n  fs.readSync = typeof fs.readSync !== 'function' ? fs.readSync\n  : (function (fs$readSync) { return function (fd, buffer, offset, length, position) {\n    var eagCounter = 0\n    while (true) {\n      try {\n        return fs$readSync.call(fs, fd, buffer, offset, length, position)\n      } catch (er) {\n        if (er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          continue\n        }\n        throw er\n      }\n    }\n  }})(fs.readSync)\n\n  function patchLchmod (fs) {\n    fs.lchmod = function (path, mode, callback) {\n      fs.open( path\n             , constants.O_WRONLY | constants.O_SYMLINK\n             , mode\n             , function (err, fd) {\n        if (err) {\n          if (callback) callback(err)\n          return\n        }\n        // prefer to return the chmod error, if one occurs,\n        // but still try to close, and report closing errors if they occur.\n        fs.fchmod(fd, mode, function (err) {\n          fs.close(fd, function(err2) {\n            if (callback) callback(err || err2)\n          })\n        })\n      })\n    }\n\n    fs.lchmodSync = function (path, mode) {\n      var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      var threw = true\n      var ret\n      try {\n        ret = fs.fchmodSync(fd, mode)\n        threw = false\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd)\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd)\n        }\n      }\n      return ret\n    }\n  }\n\n  function patchLutimes (fs) {\n    if (constants.hasOwnProperty(\"O_SYMLINK\") && fs.futimes) {\n      fs.lutimes = function (path, at, mt, cb) {\n        fs.open(path, constants.O_SYMLINK, function (er, fd) {\n          if (er) {\n            if (cb) cb(er)\n            return\n          }\n          fs.futimes(fd, at, mt, function (er) {\n            fs.close(fd, function (er2) {\n              if (cb) cb(er || er2)\n            })\n          })\n        })\n      }\n\n      fs.lutimesSync = function (path, at, mt) {\n        var fd = fs.openSync(path, constants.O_SYMLINK)\n        var ret\n        var threw = true\n        try {\n          ret = fs.futimesSync(fd, at, mt)\n          threw = false\n        } finally {\n          if (threw) {\n            try {\n              fs.closeSync(fd)\n            } catch (er) {}\n          } else {\n            fs.closeSync(fd)\n          }\n        }\n        return ret\n      }\n\n    } else if (fs.futimes) {\n      fs.lutimes = function (_a, _b, _c, cb) { if (cb) process.nextTick(cb) }\n      fs.lutimesSync = function () {}\n    }\n  }\n\n  function chmodFix (orig) {\n    if (!orig) return orig\n    return function (target, mode, cb) {\n      return orig.call(fs, target, mode, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chmodFixSync (orig) {\n    if (!orig) return orig\n    return function (target, mode) {\n      try {\n        return orig.call(fs, target, mode)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n\n  function chownFix (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid, cb) {\n      return orig.call(fs, target, uid, gid, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chownFixSync (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid) {\n      try {\n        return orig.call(fs, target, uid, gid)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n  function statFix (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options, cb) {\n      if (typeof options === 'function') {\n        cb = options\n        options = null\n      }\n      function callback (er, stats) {\n        if (stats) {\n          if (stats.uid < 0) stats.uid += 0x100000000\n          if (stats.gid < 0) stats.gid += 0x100000000\n        }\n        if (cb) cb.apply(this, arguments)\n      }\n      return options ? orig.call(fs, target, options, callback)\n        : orig.call(fs, target, callback)\n    }\n  }\n\n  function statFixSync (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options) {\n      var stats = options ? orig.call(fs, target, options)\n        : orig.call(fs, target)\n      if (stats) {\n        if (stats.uid < 0) stats.uid += 0x100000000\n        if (stats.gid < 0) stats.gid += 0x100000000\n      }\n      return stats;\n    }\n  }\n\n  // ENOSYS means that the fs doesn't support the op. Just ignore\n  // that, because it doesn't matter.\n  //\n  // if there's no getuid, or if getuid() is something other\n  // than 0, and the error is EINVAL or EPERM, then just ignore\n  // it.\n  //\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  //\n  // When running as root, or if other types of errors are\n  // encountered, then it's strict.\n  function chownErOk (er) {\n    if (!er)\n      return true\n\n    if (er.code === \"ENOSYS\")\n      return true\n\n    var nonroot = !process.getuid || process.getuid() !== 0\n    if (nonroot) {\n      if (er.code === \"EINVAL\" || er.code === \"EPERM\")\n        return true\n    }\n\n    return false\n  }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/graceful-fs@4.2.10/node_modules/graceful-fs/polyfills.js?");

/***/ }),

/***/ "./node_modules/.pnpm/ieee754@1.2.1/node_modules/ieee754/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/.pnpm/ieee754@1.2.1/node_modules/ieee754/index.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

eval("/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */\nexports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/ieee754@1.2.1/node_modules/ieee754/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("try {\n  var util = __webpack_require__(/*! util */ \"util\");\n  /* istanbul ignore next */\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  /* istanbul ignore next */\n  module.exports = __webpack_require__(/*! ./inherits_browser.js */ \"./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits_browser.js\");\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js?");

/***/ }),

/***/ "./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits_browser.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits_browser.js ***!
  \*************************************************************************************/
/***/ ((module) => {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "./node_modules/.pnpm/is-natural-number@4.0.1/node_modules/is-natural-number/index.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/.pnpm/is-natural-number@4.0.1/node_modules/is-natural-number/index.js ***!
  \********************************************************************************************/
/***/ ((module) => {

"use strict";
eval("/*!\n * is-natural-number.js | MIT (c) Shinnosuke Watanabe\n * https://github.com/shinnn/is-natural-number.js\n*/\n\n\nmodule.exports = function isNaturalNumber(val, option) {\n  if (option) {\n    if (typeof option !== 'object') {\n      throw new TypeError(\n        String(option) +\n        ' is not an object. Expected an object that has boolean `includeZero` property.'\n      );\n    }\n\n    if ('includeZero' in option) {\n      if (typeof option.includeZero !== 'boolean') {\n        throw new TypeError(\n          String(option.includeZero) +\n          ' is neither true nor false. `includeZero` option must be a Boolean value.'\n        );\n      }\n\n      if (option.includeZero && val === 0) {\n        return true;\n      }\n    }\n  }\n\n  return Number.isSafeInteger(val) && val >= 1;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/is-natural-number@4.0.1/node_modules/is-natural-number/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/is-stream@1.1.0/node_modules/is-stream/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/is-stream@1.1.0/node_modules/is-stream/index.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar isStream = module.exports = function (stream) {\n\treturn stream !== null && typeof stream === 'object' && typeof stream.pipe === 'function';\n};\n\nisStream.writable = function (stream) {\n\treturn isStream(stream) && stream.writable !== false && typeof stream._write === 'function' && typeof stream._writableState === 'object';\n};\n\nisStream.readable = function (stream) {\n\treturn isStream(stream) && stream.readable !== false && typeof stream._read === 'function' && typeof stream._readableState === 'object';\n};\n\nisStream.duplex = function (stream) {\n\treturn isStream.writable(stream) && isStream.readable(stream);\n};\n\nisStream.transform = function (stream) {\n\treturn isStream.duplex(stream) && typeof stream._transform === 'function' && typeof stream._transformState === 'object';\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/is-stream@1.1.0/node_modules/is-stream/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/isarray@1.0.0/node_modules/isarray/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/.pnpm/isarray@1.0.0/node_modules/isarray/index.js ***!
  \************************************************************************/
/***/ ((module) => {

eval("var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/isarray@1.0.0/node_modules/isarray/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/make-dir@1.3.0/node_modules/make-dir/index.js":
/*!**************************************************************************!*\
  !*** ./node_modules/.pnpm/make-dir@1.3.0/node_modules/make-dir/index.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst fs = __webpack_require__(/*! fs */ \"fs\");\nconst path = __webpack_require__(/*! path */ \"path\");\nconst pify = __webpack_require__(/*! pify */ \"./node_modules/.pnpm/pify@3.0.0/node_modules/pify/index.js\");\n\nconst defaults = {\n\tmode: 0o777 & (~process.umask()),\n\tfs\n};\n\n// https://github.com/nodejs/node/issues/8987\n// https://github.com/libuv/libuv/pull/1088\nconst checkPath = pth => {\n\tif (process.platform === 'win32') {\n\t\tconst pathHasInvalidWinCharacters = /[<>:\"|?*]/.test(pth.replace(path.parse(pth).root, ''));\n\n\t\tif (pathHasInvalidWinCharacters) {\n\t\t\tconst err = new Error(`Path contains invalid characters: ${pth}`);\n\t\t\terr.code = 'EINVAL';\n\t\t\tthrow err;\n\t\t}\n\t}\n};\n\nmodule.exports = (input, opts) => Promise.resolve().then(() => {\n\tcheckPath(input);\n\topts = Object.assign({}, defaults, opts);\n\n\tconst mkdir = pify(opts.fs.mkdir);\n\tconst stat = pify(opts.fs.stat);\n\n\tconst make = pth => {\n\t\treturn mkdir(pth, opts.mode)\n\t\t\t.then(() => pth)\n\t\t\t.catch(err => {\n\t\t\t\tif (err.code === 'ENOENT') {\n\t\t\t\t\tif (err.message.includes('null bytes') || path.dirname(pth) === pth) {\n\t\t\t\t\t\tthrow err;\n\t\t\t\t\t}\n\n\t\t\t\t\treturn make(path.dirname(pth)).then(() => make(pth));\n\t\t\t\t}\n\n\t\t\t\treturn stat(pth)\n\t\t\t\t\t.then(stats => stats.isDirectory() ? pth : Promise.reject())\n\t\t\t\t\t.catch(() => {\n\t\t\t\t\t\tthrow err;\n\t\t\t\t\t});\n\t\t\t});\n\t};\n\n\treturn make(path.resolve(input));\n});\n\nmodule.exports.sync = (input, opts) => {\n\tcheckPath(input);\n\topts = Object.assign({}, defaults, opts);\n\n\tconst make = pth => {\n\t\ttry {\n\t\t\topts.fs.mkdirSync(pth, opts.mode);\n\t\t} catch (err) {\n\t\t\tif (err.code === 'ENOENT') {\n\t\t\t\tif (err.message.includes('null bytes') || path.dirname(pth) === pth) {\n\t\t\t\t\tthrow err;\n\t\t\t\t}\n\n\t\t\t\tmake(path.dirname(pth));\n\t\t\t\treturn make(pth);\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tif (!opts.fs.statSync(pth).isDirectory()) {\n\t\t\t\t\tthrow new Error('The path is not a directory');\n\t\t\t\t}\n\t\t\t} catch (_) {\n\t\t\t\tthrow err;\n\t\t\t}\n\t\t}\n\n\t\treturn pth;\n\t};\n\n\treturn make(path.resolve(input));\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/make-dir@1.3.0/node_modules/make-dir/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/object-assign@4.1.1/node_modules/object-assign/index.js":
/*!************************************************************************************!*\
  !*** ./node_modules/.pnpm/object-assign@4.1.1/node_modules/object-assign/index.js ***!
  \************************************************************************************/
/***/ ((module) => {

"use strict";
eval("/*\nobject-assign\n(c) Sindre Sorhus\n@license MIT\n*/\n\n\n/* eslint-disable no-unused-vars */\nvar getOwnPropertySymbols = Object.getOwnPropertySymbols;\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\nfunction toObject(val) {\n\tif (val === null || val === undefined) {\n\t\tthrow new TypeError('Object.assign cannot be called with null or undefined');\n\t}\n\n\treturn Object(val);\n}\n\nfunction shouldUseNative() {\n\ttry {\n\t\tif (!Object.assign) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Detect buggy property enumeration order in older V8 versions.\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=4118\n\t\tvar test1 = new String('abc');  // eslint-disable-line no-new-wrappers\n\t\ttest1[5] = 'de';\n\t\tif (Object.getOwnPropertyNames(test1)[0] === '5') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test2 = {};\n\t\tfor (var i = 0; i < 10; i++) {\n\t\t\ttest2['_' + String.fromCharCode(i)] = i;\n\t\t}\n\t\tvar order2 = Object.getOwnPropertyNames(test2).map(function (n) {\n\t\t\treturn test2[n];\n\t\t});\n\t\tif (order2.join('') !== '0123456789') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test3 = {};\n\t\t'abcdefghijklmnopqrst'.split('').forEach(function (letter) {\n\t\t\ttest3[letter] = letter;\n\t\t});\n\t\tif (Object.keys(Object.assign({}, test3)).join('') !==\n\t\t\t\t'abcdefghijklmnopqrst') {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t} catch (err) {\n\t\t// We don't expect any of the above to throw, but better to be safe.\n\t\treturn false;\n\t}\n}\n\nmodule.exports = shouldUseNative() ? Object.assign : function (target, source) {\n\tvar from;\n\tvar to = toObject(target);\n\tvar symbols;\n\n\tfor (var s = 1; s < arguments.length; s++) {\n\t\tfrom = Object(arguments[s]);\n\n\t\tfor (var key in from) {\n\t\t\tif (hasOwnProperty.call(from, key)) {\n\t\t\t\tto[key] = from[key];\n\t\t\t}\n\t\t}\n\n\t\tif (getOwnPropertySymbols) {\n\t\t\tsymbols = getOwnPropertySymbols(from);\n\t\t\tfor (var i = 0; i < symbols.length; i++) {\n\t\t\t\tif (propIsEnumerable.call(from, symbols[i])) {\n\t\t\t\t\tto[symbols[i]] = from[symbols[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn to;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/object-assign@4.1.1/node_modules/object-assign/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/once@1.4.0/node_modules/once/once.js":
/*!*****************************************************************!*\
  !*** ./node_modules/.pnpm/once@1.4.0/node_modules/once/once.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var wrappy = __webpack_require__(/*! wrappy */ \"./node_modules/.pnpm/wrappy@1.0.2/node_modules/wrappy/wrappy.js\")\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/once@1.4.0/node_modules/once/once.js?");

/***/ }),

/***/ "./node_modules/.pnpm/pend@1.2.0/node_modules/pend/index.js":
/*!******************************************************************!*\
  !*** ./node_modules/.pnpm/pend@1.2.0/node_modules/pend/index.js ***!
  \******************************************************************/
/***/ ((module) => {

eval("module.exports = Pend;\n\nfunction Pend() {\n  this.pending = 0;\n  this.max = Infinity;\n  this.listeners = [];\n  this.waiting = [];\n  this.error = null;\n}\n\nPend.prototype.go = function(fn) {\n  if (this.pending < this.max) {\n    pendGo(this, fn);\n  } else {\n    this.waiting.push(fn);\n  }\n};\n\nPend.prototype.wait = function(cb) {\n  if (this.pending === 0) {\n    cb(this.error);\n  } else {\n    this.listeners.push(cb);\n  }\n};\n\nPend.prototype.hold = function() {\n  return pendHold(this);\n};\n\nfunction pendHold(self) {\n  self.pending += 1;\n  var called = false;\n  return onCb;\n  function onCb(err) {\n    if (called) throw new Error(\"callback called twice\");\n    called = true;\n    self.error = self.error || err;\n    self.pending -= 1;\n    if (self.waiting.length > 0 && self.pending < self.max) {\n      pendGo(self, self.waiting.shift());\n    } else if (self.pending === 0) {\n      var listeners = self.listeners;\n      self.listeners = [];\n      listeners.forEach(cbListener);\n    }\n  }\n  function cbListener(listener) {\n    listener(self.error);\n  }\n}\n\nfunction pendGo(self, fn) {\n  fn(pendHold(self));\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/pend@1.2.0/node_modules/pend/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/pify@2.3.0/node_modules/pify/index.js":
/*!******************************************************************!*\
  !*** ./node_modules/.pnpm/pify@2.3.0/node_modules/pify/index.js ***!
  \******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar processFn = function (fn, P, opts) {\n\treturn function () {\n\t\tvar that = this;\n\t\tvar args = new Array(arguments.length);\n\n\t\tfor (var i = 0; i < arguments.length; i++) {\n\t\t\targs[i] = arguments[i];\n\t\t}\n\n\t\treturn new P(function (resolve, reject) {\n\t\t\targs.push(function (err, result) {\n\t\t\t\tif (err) {\n\t\t\t\t\treject(err);\n\t\t\t\t} else if (opts.multiArgs) {\n\t\t\t\t\tvar results = new Array(arguments.length - 1);\n\n\t\t\t\t\tfor (var i = 1; i < arguments.length; i++) {\n\t\t\t\t\t\tresults[i - 1] = arguments[i];\n\t\t\t\t\t}\n\n\t\t\t\t\tresolve(results);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(result);\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tfn.apply(that, args);\n\t\t});\n\t};\n};\n\nvar pify = module.exports = function (obj, P, opts) {\n\tif (typeof P !== 'function') {\n\t\topts = P;\n\t\tP = Promise;\n\t}\n\n\topts = opts || {};\n\topts.exclude = opts.exclude || [/.+Sync$/];\n\n\tvar filter = function (key) {\n\t\tvar match = function (pattern) {\n\t\t\treturn typeof pattern === 'string' ? key === pattern : pattern.test(key);\n\t\t};\n\n\t\treturn opts.include ? opts.include.some(match) : !opts.exclude.some(match);\n\t};\n\n\tvar ret = typeof obj === 'function' ? function () {\n\t\tif (opts.excludeMain) {\n\t\t\treturn obj.apply(this, arguments);\n\t\t}\n\n\t\treturn processFn(obj, P, opts).apply(this, arguments);\n\t} : {};\n\n\treturn Object.keys(obj).reduce(function (ret, key) {\n\t\tvar x = obj[key];\n\n\t\tret[key] = typeof x === 'function' && filter(key) ? processFn(x, P, opts) : x;\n\n\t\treturn ret;\n\t}, ret);\n};\n\npify.all = pify;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/pify@2.3.0/node_modules/pify/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/pify@3.0.0/node_modules/pify/index.js":
/*!******************************************************************!*\
  !*** ./node_modules/.pnpm/pify@3.0.0/node_modules/pify/index.js ***!
  \******************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst processFn = (fn, opts) => function () {\n\tconst P = opts.promiseModule;\n\tconst args = new Array(arguments.length);\n\n\tfor (let i = 0; i < arguments.length; i++) {\n\t\targs[i] = arguments[i];\n\t}\n\n\treturn new P((resolve, reject) => {\n\t\tif (opts.errorFirst) {\n\t\t\targs.push(function (err, result) {\n\t\t\t\tif (opts.multiArgs) {\n\t\t\t\t\tconst results = new Array(arguments.length - 1);\n\n\t\t\t\t\tfor (let i = 1; i < arguments.length; i++) {\n\t\t\t\t\t\tresults[i - 1] = arguments[i];\n\t\t\t\t\t}\n\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\tresults.unshift(err);\n\t\t\t\t\t\treject(results);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresolve(results);\n\t\t\t\t\t}\n\t\t\t\t} else if (err) {\n\t\t\t\t\treject(err);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(result);\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\targs.push(function (result) {\n\t\t\t\tif (opts.multiArgs) {\n\t\t\t\t\tconst results = new Array(arguments.length - 1);\n\n\t\t\t\t\tfor (let i = 0; i < arguments.length; i++) {\n\t\t\t\t\t\tresults[i] = arguments[i];\n\t\t\t\t\t}\n\n\t\t\t\t\tresolve(results);\n\t\t\t\t} else {\n\t\t\t\t\tresolve(result);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\n\t\tfn.apply(this, args);\n\t});\n};\n\nmodule.exports = (obj, opts) => {\n\topts = Object.assign({\n\t\texclude: [/.+(Sync|Stream)$/],\n\t\terrorFirst: true,\n\t\tpromiseModule: Promise\n\t}, opts);\n\n\tconst filter = key => {\n\t\tconst match = pattern => typeof pattern === 'string' ? key === pattern : pattern.test(key);\n\t\treturn opts.include ? opts.include.some(match) : !opts.exclude.some(match);\n\t};\n\n\tlet ret;\n\tif (typeof obj === 'function') {\n\t\tret = function () {\n\t\t\tif (opts.excludeMain) {\n\t\t\t\treturn obj.apply(this, arguments);\n\t\t\t}\n\n\t\t\treturn processFn(obj, opts).apply(this, arguments);\n\t\t};\n\t} else {\n\t\tret = Object.create(Object.getPrototypeOf(obj));\n\t}\n\n\tfor (const key in obj) { // eslint-disable-line guard-for-in\n\t\tconst x = obj[key];\n\t\tret[key] = typeof x === 'function' && filter(key) ? processFn(x, opts) : x;\n\t}\n\n\treturn ret;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/pify@3.0.0/node_modules/pify/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/pinkie-promise@2.0.1/node_modules/pinkie-promise/index.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/.pnpm/pinkie-promise@2.0.1/node_modules/pinkie-promise/index.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = typeof Promise === 'function' ? Promise : __webpack_require__(/*! pinkie */ \"./node_modules/.pnpm/pinkie@2.0.4/node_modules/pinkie/index.js\");\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/pinkie-promise@2.0.1/node_modules/pinkie-promise/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/pinkie@2.0.4/node_modules/pinkie/index.js":
/*!**********************************************************************!*\
  !*** ./node_modules/.pnpm/pinkie@2.0.4/node_modules/pinkie/index.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar PENDING = 'pending';\nvar SETTLED = 'settled';\nvar FULFILLED = 'fulfilled';\nvar REJECTED = 'rejected';\nvar NOOP = function () {};\nvar isNode = typeof global !== 'undefined' && typeof global.process !== 'undefined' && typeof global.process.emit === 'function';\n\nvar asyncSetTimer = typeof setImmediate === 'undefined' ? setTimeout : setImmediate;\nvar asyncQueue = [];\nvar asyncTimer;\n\nfunction asyncFlush() {\n\t// run promise callbacks\n\tfor (var i = 0; i < asyncQueue.length; i++) {\n\t\tasyncQueue[i][0](asyncQueue[i][1]);\n\t}\n\n\t// reset async asyncQueue\n\tasyncQueue = [];\n\tasyncTimer = false;\n}\n\nfunction asyncCall(callback, arg) {\n\tasyncQueue.push([callback, arg]);\n\n\tif (!asyncTimer) {\n\t\tasyncTimer = true;\n\t\tasyncSetTimer(asyncFlush, 0);\n\t}\n}\n\nfunction invokeResolver(resolver, promise) {\n\tfunction resolvePromise(value) {\n\t\tresolve(promise, value);\n\t}\n\n\tfunction rejectPromise(reason) {\n\t\treject(promise, reason);\n\t}\n\n\ttry {\n\t\tresolver(resolvePromise, rejectPromise);\n\t} catch (e) {\n\t\trejectPromise(e);\n\t}\n}\n\nfunction invokeCallback(subscriber) {\n\tvar owner = subscriber.owner;\n\tvar settled = owner._state;\n\tvar value = owner._data;\n\tvar callback = subscriber[settled];\n\tvar promise = subscriber.then;\n\n\tif (typeof callback === 'function') {\n\t\tsettled = FULFILLED;\n\t\ttry {\n\t\t\tvalue = callback(value);\n\t\t} catch (e) {\n\t\t\treject(promise, e);\n\t\t}\n\t}\n\n\tif (!handleThenable(promise, value)) {\n\t\tif (settled === FULFILLED) {\n\t\t\tresolve(promise, value);\n\t\t}\n\n\t\tif (settled === REJECTED) {\n\t\t\treject(promise, value);\n\t\t}\n\t}\n}\n\nfunction handleThenable(promise, value) {\n\tvar resolved;\n\n\ttry {\n\t\tif (promise === value) {\n\t\t\tthrow new TypeError('A promises callback cannot return that same promise.');\n\t\t}\n\n\t\tif (value && (typeof value === 'function' || typeof value === 'object')) {\n\t\t\t// then should be retrieved only once\n\t\t\tvar then = value.then;\n\n\t\t\tif (typeof then === 'function') {\n\t\t\t\tthen.call(value, function (val) {\n\t\t\t\t\tif (!resolved) {\n\t\t\t\t\t\tresolved = true;\n\n\t\t\t\t\t\tif (value === val) {\n\t\t\t\t\t\t\tfulfill(promise, val);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tresolve(promise, val);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}, function (reason) {\n\t\t\t\t\tif (!resolved) {\n\t\t\t\t\t\tresolved = true;\n\n\t\t\t\t\t\treject(promise, reason);\n\t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t} catch (e) {\n\t\tif (!resolved) {\n\t\t\treject(promise, e);\n\t\t}\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nfunction resolve(promise, value) {\n\tif (promise === value || !handleThenable(promise, value)) {\n\t\tfulfill(promise, value);\n\t}\n}\n\nfunction fulfill(promise, value) {\n\tif (promise._state === PENDING) {\n\t\tpromise._state = SETTLED;\n\t\tpromise._data = value;\n\n\t\tasyncCall(publishFulfillment, promise);\n\t}\n}\n\nfunction reject(promise, reason) {\n\tif (promise._state === PENDING) {\n\t\tpromise._state = SETTLED;\n\t\tpromise._data = reason;\n\n\t\tasyncCall(publishRejection, promise);\n\t}\n}\n\nfunction publish(promise) {\n\tpromise._then = promise._then.forEach(invokeCallback);\n}\n\nfunction publishFulfillment(promise) {\n\tpromise._state = FULFILLED;\n\tpublish(promise);\n}\n\nfunction publishRejection(promise) {\n\tpromise._state = REJECTED;\n\tpublish(promise);\n\tif (!promise._handled && isNode) {\n\t\tglobal.process.emit('unhandledRejection', promise._data, promise);\n\t}\n}\n\nfunction notifyRejectionHandled(promise) {\n\tglobal.process.emit('rejectionHandled', promise);\n}\n\n/**\n * @class\n */\nfunction Promise(resolver) {\n\tif (typeof resolver !== 'function') {\n\t\tthrow new TypeError('Promise resolver ' + resolver + ' is not a function');\n\t}\n\n\tif (this instanceof Promise === false) {\n\t\tthrow new TypeError('Failed to construct \\'Promise\\': Please use the \\'new\\' operator, this object constructor cannot be called as a function.');\n\t}\n\n\tthis._then = [];\n\n\tinvokeResolver(resolver, this);\n}\n\nPromise.prototype = {\n\tconstructor: Promise,\n\n\t_state: PENDING,\n\t_then: null,\n\t_data: undefined,\n\t_handled: false,\n\n\tthen: function (onFulfillment, onRejection) {\n\t\tvar subscriber = {\n\t\t\towner: this,\n\t\t\tthen: new this.constructor(NOOP),\n\t\t\tfulfilled: onFulfillment,\n\t\t\trejected: onRejection\n\t\t};\n\n\t\tif ((onRejection || onFulfillment) && !this._handled) {\n\t\t\tthis._handled = true;\n\t\t\tif (this._state === REJECTED && isNode) {\n\t\t\t\tasyncCall(notifyRejectionHandled, this);\n\t\t\t}\n\t\t}\n\n\t\tif (this._state === FULFILLED || this._state === REJECTED) {\n\t\t\t// already resolved, call callback async\n\t\t\tasyncCall(invokeCallback, subscriber);\n\t\t} else {\n\t\t\t// subscribe\n\t\t\tthis._then.push(subscriber);\n\t\t}\n\n\t\treturn subscriber.then;\n\t},\n\n\tcatch: function (onRejection) {\n\t\treturn this.then(null, onRejection);\n\t}\n};\n\nPromise.all = function (promises) {\n\tif (!Array.isArray(promises)) {\n\t\tthrow new TypeError('You must pass an array to Promise.all().');\n\t}\n\n\treturn new Promise(function (resolve, reject) {\n\t\tvar results = [];\n\t\tvar remaining = 0;\n\n\t\tfunction resolver(index) {\n\t\t\tremaining++;\n\t\t\treturn function (value) {\n\t\t\t\tresults[index] = value;\n\t\t\t\tif (!--remaining) {\n\t\t\t\t\tresolve(results);\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\n\t\tfor (var i = 0, promise; i < promises.length; i++) {\n\t\t\tpromise = promises[i];\n\n\t\t\tif (promise && typeof promise.then === 'function') {\n\t\t\t\tpromise.then(resolver(i), reject);\n\t\t\t} else {\n\t\t\t\tresults[i] = promise;\n\t\t\t}\n\t\t}\n\n\t\tif (!remaining) {\n\t\t\tresolve(results);\n\t\t}\n\t});\n};\n\nPromise.race = function (promises) {\n\tif (!Array.isArray(promises)) {\n\t\tthrow new TypeError('You must pass an array to Promise.race().');\n\t}\n\n\treturn new Promise(function (resolve, reject) {\n\t\tfor (var i = 0, promise; i < promises.length; i++) {\n\t\t\tpromise = promises[i];\n\n\t\t\tif (promise && typeof promise.then === 'function') {\n\t\t\t\tpromise.then(resolve, reject);\n\t\t\t} else {\n\t\t\t\tresolve(promise);\n\t\t\t}\n\t\t}\n\t});\n};\n\nPromise.resolve = function (value) {\n\tif (value && typeof value === 'object' && value.constructor === Promise) {\n\t\treturn value;\n\t}\n\n\treturn new Promise(function (resolve) {\n\t\tresolve(value);\n\t});\n};\n\nPromise.reject = function (reason) {\n\treturn new Promise(function (resolve, reject) {\n\t\treject(reason);\n\t});\n};\n\nmodule.exports = Promise;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/pinkie@2.0.4/node_modules/pinkie/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/process-nextick-args@2.0.1/node_modules/process-nextick-args/index.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/.pnpm/process-nextick-args@2.0.1/node_modules/process-nextick-args/index.js ***!
  \**************************************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nif (typeof process === 'undefined' ||\n    !process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/process-nextick-args@2.0.1/node_modules/process-nextick-args/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/duplex.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/duplex.js ***!
  \*****************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! ./readable */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js\").Duplex\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/duplex.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js ***!
  \*****************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/.pnpm/process-nextick-args@2.0.1/node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_readable.js\");\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_writable.js\");\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_passthrough.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \**********************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_transform.js\");\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_readable.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_readable.js ***!
  \*******************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/.pnpm/process-nextick-args@2.0.1/node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = __webpack_require__(/*! isarray */ \"./node_modules/.pnpm/isarray@1.0.0/node_modules/isarray/index.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = (__webpack_require__(/*! events */ \"events\").EventEmitter);\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/stream.js\");\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"./node_modules/.pnpm/safe-buffer@5.1.2/node_modules/safe-buffer/index.js\").Buffer);\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(/*! util */ \"util\");\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/BufferList */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/BufferList.js\");\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/destroy.js\");\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/.pnpm/string_decoder@1.1.1/node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/.pnpm/string_decoder@1.1.1/node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_transform.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_transform.js ***!
  \********************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\n\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js\");\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_writable.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_writable.js ***!
  \*******************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/.pnpm/process-nextick-args@2.0.1/node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/.pnpm/core-util-is@1.0.3/node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/.pnpm/inherits@2.0.4/node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"./node_modules/.pnpm/util-deprecate@1.0.2/node_modules/util-deprecate/node.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/stream.js\");\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"./node_modules/.pnpm/safe-buffer@5.1.2/node_modules/safe-buffer/index.js\").Buffer);\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/BufferList.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/BufferList.js ***!
  \******************************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"./node_modules/.pnpm/safe-buffer@5.1.2/node_modules/safe-buffer/index.js\").Buffer);\nvar util = __webpack_require__(/*! util */ \"util\");\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/BufferList.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \***************************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/.pnpm/process-nextick-args@2.0.1/node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/stream.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/stream.js ***!
  \**************************************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! stream */ \"stream\");\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/internal/streams/stream.js?");

/***/ }),

/***/ "./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js ***!
  \*******************************************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("var Stream = __webpack_require__(/*! stream */ \"stream\");\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_readable.js\");\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_writable.js\");\n  exports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_duplex.js\");\n  exports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_transform.js\");\n  exports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/lib/_stream_passthrough.js\");\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js?");

/***/ }),

/***/ "./node_modules/.pnpm/safe-buffer@5.1.2/node_modules/safe-buffer/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/safe-buffer@5.1.2/node_modules/safe-buffer/index.js ***!
  \********************************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(/*! buffer */ \"buffer\")\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/safe-buffer@5.1.2/node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/safe-buffer@5.2.1/node_modules/safe-buffer/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/safe-buffer@5.2.1/node_modules/safe-buffer/index.js ***!
  \********************************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(/*! buffer */ \"buffer\")\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/safe-buffer@5.2.1/node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/bitreader.js":
/*!************************************************************************************!*\
  !*** ./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/bitreader.js ***!
  \************************************************************************************/
/***/ ((module) => {

eval("/*\nnode-bzip - a pure-javascript Node.JS module for decoding bzip2 data\n\nCopyright (C) 2012 Eli Skeggs\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nAdapted from bzip2.js, copyright 2011 antimatter15 (antimatter15@gmail.com).\n\nBased on micro-bunzip by Rob Landley (rob@landley.net).\n\nBased on bzip2 decompression code by Julian R Seward (jseward@acm.org),\nwhich also acknowledges contributions by Mike Burrows, David Wheeler,\nPeter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,\nRobert Sedgewick, and Jon L. Bentley.\n*/\n\nvar BITMASK = [0x00, 0x01, 0x03, 0x07, 0x0F, 0x1F, 0x3F, 0x7F, 0xFF];\n\n// offset in bytes\nvar BitReader = function(stream) {\n  this.stream = stream;\n  this.bitOffset = 0;\n  this.curByte = 0;\n  this.hasByte = false;\n};\n\nBitReader.prototype._ensureByte = function() {\n  if (!this.hasByte) {\n    this.curByte = this.stream.readByte();\n    this.hasByte = true;\n  }\n};\n\n// reads bits from the buffer\nBitReader.prototype.read = function(bits) {\n  var result = 0;\n  while (bits > 0) {\n    this._ensureByte();\n    var remaining = 8 - this.bitOffset;\n    // if we're in a byte\n    if (bits >= remaining) {\n      result <<= remaining;\n      result |= BITMASK[remaining] & this.curByte;\n      this.hasByte = false;\n      this.bitOffset = 0;\n      bits -= remaining;\n    } else {\n      result <<= bits;\n      var shift = remaining - bits;\n      result |= (this.curByte & (BITMASK[bits] << shift)) >> shift;\n      this.bitOffset += bits;\n      bits = 0;\n    }\n  }\n  return result;\n};\n\n// seek to an arbitrary point in the buffer (expressed in bits)\nBitReader.prototype.seek = function(pos) {\n  var n_bit = pos % 8;\n  var n_byte = (pos - n_bit) / 8;\n  this.bitOffset = n_bit;\n  this.stream.seek(n_byte);\n  this.hasByte = false;\n};\n\n// reads 6 bytes worth of data using the read method\nBitReader.prototype.pi = function() {\n  var buf = new Buffer(6), i;\n  for (i = 0; i < buf.length; i++) {\n    buf[i] = this.read(8);\n  }\n  return buf.toString('hex');\n};\n\nmodule.exports = BitReader;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/bitreader.js?");

/***/ }),

/***/ "./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/crc32.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/crc32.js ***!
  \********************************************************************************/
/***/ ((module) => {

eval("/* CRC32, used in Bzip2 implementation.\n * This is a port of CRC32.java from the jbzip2 implementation at\n *   https://code.google.com/p/jbzip2\n * which is:\n *   Copyright (c) 2011 Matthew Francis\n *\n *   Permission is hereby granted, free of charge, to any person\n *   obtaining a copy of this software and associated documentation\n *   files (the \"Software\"), to deal in the Software without\n *   restriction, including without limitation the rights to use,\n *   copy, modify, merge, publish, distribute, sublicense, and/or sell\n *   copies of the Software, and to permit persons to whom the\n *   Software is furnished to do so, subject to the following\n *   conditions:\n *\n *   The above copyright notice and this permission notice shall be\n *   included in all copies or substantial portions of the Software.\n *\n *   THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n *   EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n *   OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n *   NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT\n *   HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n *   WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n *   FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\n *   OTHER DEALINGS IN THE SOFTWARE.\n * This JavaScript implementation is:\n *   Copyright (c) 2013 C. Scott Ananian\n * with the same licensing terms as Matthew Francis' original implementation.\n */\nmodule.exports = (function() {\n\n  /**\n   * A static CRC lookup table\n   */\n  var crc32Lookup = new Uint32Array([\n    0x00000000, 0x04c11db7, 0x09823b6e, 0x0d4326d9, 0x130476dc, 0x17c56b6b, 0x1a864db2, 0x1e475005,\n    0x2608edb8, 0x22c9f00f, 0x2f8ad6d6, 0x2b4bcb61, 0x350c9b64, 0x31cd86d3, 0x3c8ea00a, 0x384fbdbd,\n    0x4c11db70, 0x48d0c6c7, 0x4593e01e, 0x4152fda9, 0x5f15adac, 0x5bd4b01b, 0x569796c2, 0x52568b75,\n    0x6a1936c8, 0x6ed82b7f, 0x639b0da6, 0x675a1011, 0x791d4014, 0x7ddc5da3, 0x709f7b7a, 0x745e66cd,\n    0x9823b6e0, 0x9ce2ab57, 0x91a18d8e, 0x95609039, 0x8b27c03c, 0x8fe6dd8b, 0x82a5fb52, 0x8664e6e5,\n    0xbe2b5b58, 0xbaea46ef, 0xb7a96036, 0xb3687d81, 0xad2f2d84, 0xa9ee3033, 0xa4ad16ea, 0xa06c0b5d,\n    0xd4326d90, 0xd0f37027, 0xddb056fe, 0xd9714b49, 0xc7361b4c, 0xc3f706fb, 0xceb42022, 0xca753d95,\n    0xf23a8028, 0xf6fb9d9f, 0xfbb8bb46, 0xff79a6f1, 0xe13ef6f4, 0xe5ffeb43, 0xe8bccd9a, 0xec7dd02d,\n    0x34867077, 0x30476dc0, 0x3d044b19, 0x39c556ae, 0x278206ab, 0x23431b1c, 0x2e003dc5, 0x2ac12072,\n    0x128e9dcf, 0x164f8078, 0x1b0ca6a1, 0x1fcdbb16, 0x018aeb13, 0x054bf6a4, 0x0808d07d, 0x0cc9cdca,\n    0x7897ab07, 0x7c56b6b0, 0x71159069, 0x75d48dde, 0x6b93dddb, 0x6f52c06c, 0x6211e6b5, 0x66d0fb02,\n    0x5e9f46bf, 0x5a5e5b08, 0x571d7dd1, 0x53dc6066, 0x4d9b3063, 0x495a2dd4, 0x44190b0d, 0x40d816ba,\n    0xaca5c697, 0xa864db20, 0xa527fdf9, 0xa1e6e04e, 0xbfa1b04b, 0xbb60adfc, 0xb6238b25, 0xb2e29692,\n    0x8aad2b2f, 0x8e6c3698, 0x832f1041, 0x87ee0df6, 0x99a95df3, 0x9d684044, 0x902b669d, 0x94ea7b2a,\n    0xe0b41de7, 0xe4750050, 0xe9362689, 0xedf73b3e, 0xf3b06b3b, 0xf771768c, 0xfa325055, 0xfef34de2,\n    0xc6bcf05f, 0xc27dede8, 0xcf3ecb31, 0xcbffd686, 0xd5b88683, 0xd1799b34, 0xdc3abded, 0xd8fba05a,\n    0x690ce0ee, 0x6dcdfd59, 0x608edb80, 0x644fc637, 0x7a089632, 0x7ec98b85, 0x738aad5c, 0x774bb0eb,\n    0x4f040d56, 0x4bc510e1, 0x46863638, 0x42472b8f, 0x5c007b8a, 0x58c1663d, 0x558240e4, 0x51435d53,\n    0x251d3b9e, 0x21dc2629, 0x2c9f00f0, 0x285e1d47, 0x36194d42, 0x32d850f5, 0x3f9b762c, 0x3b5a6b9b,\n    0x0315d626, 0x07d4cb91, 0x0a97ed48, 0x0e56f0ff, 0x1011a0fa, 0x14d0bd4d, 0x19939b94, 0x1d528623,\n    0xf12f560e, 0xf5ee4bb9, 0xf8ad6d60, 0xfc6c70d7, 0xe22b20d2, 0xe6ea3d65, 0xeba91bbc, 0xef68060b,\n    0xd727bbb6, 0xd3e6a601, 0xdea580d8, 0xda649d6f, 0xc423cd6a, 0xc0e2d0dd, 0xcda1f604, 0xc960ebb3,\n    0xbd3e8d7e, 0xb9ff90c9, 0xb4bcb610, 0xb07daba7, 0xae3afba2, 0xaafbe615, 0xa7b8c0cc, 0xa379dd7b,\n    0x9b3660c6, 0x9ff77d71, 0x92b45ba8, 0x9675461f, 0x8832161a, 0x8cf30bad, 0x81b02d74, 0x857130c3,\n    0x5d8a9099, 0x594b8d2e, 0x5408abf7, 0x50c9b640, 0x4e8ee645, 0x4a4ffbf2, 0x470cdd2b, 0x43cdc09c,\n    0x7b827d21, 0x7f436096, 0x7200464f, 0x76c15bf8, 0x68860bfd, 0x6c47164a, 0x61043093, 0x65c52d24,\n    0x119b4be9, 0x155a565e, 0x18197087, 0x1cd86d30, 0x029f3d35, 0x065e2082, 0x0b1d065b, 0x0fdc1bec,\n    0x3793a651, 0x3352bbe6, 0x3e119d3f, 0x3ad08088, 0x2497d08d, 0x2056cd3a, 0x2d15ebe3, 0x29d4f654,\n    0xc5a92679, 0xc1683bce, 0xcc2b1d17, 0xc8ea00a0, 0xd6ad50a5, 0xd26c4d12, 0xdf2f6bcb, 0xdbee767c,\n    0xe3a1cbc1, 0xe760d676, 0xea23f0af, 0xeee2ed18, 0xf0a5bd1d, 0xf464a0aa, 0xf9278673, 0xfde69bc4,\n    0x89b8fd09, 0x8d79e0be, 0x803ac667, 0x84fbdbd0, 0x9abc8bd5, 0x9e7d9662, 0x933eb0bb, 0x97ffad0c,\n    0xafb010b1, 0xab710d06, 0xa6322bdf, 0xa2f33668, 0xbcb4666d, 0xb8757bda, 0xb5365d03, 0xb1f740b4\n  ]);\n\n  var CRC32 = function() {\n    /**\n     * The current CRC\n     */\n    var crc = 0xffffffff;\n\n    /**\n     * @return The current CRC\n     */\n    this.getCRC = function() {\n      return (~crc) >>> 0; // return an unsigned value\n    };\n\n    /**\n     * Update the CRC with a single byte\n     * @param value The value to update the CRC with\n     */\n    this.updateCRC = function(value) {\n      crc = (crc << 8) ^ crc32Lookup[((crc >>> 24) ^ value) & 0xff];\n    };\n\n    /**\n     * Update the CRC with a sequence of identical bytes\n     * @param value The value to update the CRC with\n     * @param count The number of bytes\n     */\n    this.updateCRCRun = function(value, count) {\n      while (count-- > 0) {\n        crc = (crc << 8) ^ crc32Lookup[((crc >>> 24) ^ value) & 0xff];\n      }\n    };\n  };\n  return CRC32;\n})();\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/crc32.js?");

/***/ }),

/***/ "./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/index.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/*\nseek-bzip - a pure-javascript module for seeking within bzip2 data\n\nCopyright (C) 2013 C. Scott Ananian\nCopyright (C) 2012 Eli Skeggs\nCopyright (C) 2011 Kevin Kwok\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nAdapted from node-bzip, copyright 2012 Eli Skeggs.\nAdapted from bzip2.js, copyright 2011 Kevin Kwok (antimatter15@gmail.com).\n\nBased on micro-bunzip by Rob Landley (rob@landley.net).\n\nBased on bzip2 decompression code by Julian R Seward (jseward@acm.org),\nwhich also acknowledges contributions by Mike Burrows, David Wheeler,\nPeter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,\nRobert Sedgewick, and Jon L. Bentley.\n*/\n\nvar BitReader = __webpack_require__(/*! ./bitreader */ \"./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/bitreader.js\");\nvar Stream = __webpack_require__(/*! ./stream */ \"./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/stream.js\");\nvar CRC32 = __webpack_require__(/*! ./crc32 */ \"./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/crc32.js\");\nvar pjson = __webpack_require__(/*! ../package.json */ \"./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/package.json\");\n\nvar MAX_HUFCODE_BITS = 20;\nvar MAX_SYMBOLS = 258;\nvar SYMBOL_RUNA = 0;\nvar SYMBOL_RUNB = 1;\nvar MIN_GROUPS = 2;\nvar MAX_GROUPS = 6;\nvar GROUP_SIZE = 50;\n\nvar WHOLEPI = \"314159265359\";\nvar SQRTPI = \"177245385090\";\n\nvar mtf = function(array, index) {\n  var src = array[index], i;\n  for (i = index; i > 0; i--) {\n    array[i] = array[i-1];\n  }\n  array[0] = src;\n  return src;\n};\n\nvar Err = {\n  OK: 0,\n  LAST_BLOCK: -1,\n  NOT_BZIP_DATA: -2,\n  UNEXPECTED_INPUT_EOF: -3,\n  UNEXPECTED_OUTPUT_EOF: -4,\n  DATA_ERROR: -5,\n  OUT_OF_MEMORY: -6,\n  OBSOLETE_INPUT: -7,\n  END_OF_BLOCK: -8\n};\nvar ErrorMessages = {};\nErrorMessages[Err.LAST_BLOCK] =            \"Bad file checksum\";\nErrorMessages[Err.NOT_BZIP_DATA] =         \"Not bzip data\";\nErrorMessages[Err.UNEXPECTED_INPUT_EOF] =  \"Unexpected input EOF\";\nErrorMessages[Err.UNEXPECTED_OUTPUT_EOF] = \"Unexpected output EOF\";\nErrorMessages[Err.DATA_ERROR] =            \"Data error\";\nErrorMessages[Err.OUT_OF_MEMORY] =         \"Out of memory\";\nErrorMessages[Err.OBSOLETE_INPUT] = \"Obsolete (pre 0.9.5) bzip format not supported.\";\n\nvar _throw = function(status, optDetail) {\n  var msg = ErrorMessages[status] || 'unknown error';\n  if (optDetail) { msg += ': '+optDetail; }\n  var e = new TypeError(msg);\n  e.errorCode = status;\n  throw e;\n};\n\nvar Bunzip = function(inputStream, outputStream) {\n  this.writePos = this.writeCurrent = this.writeCount = 0;\n\n  this._start_bunzip(inputStream, outputStream);\n};\nBunzip.prototype._init_block = function() {\n  var moreBlocks = this._get_next_block();\n  if ( !moreBlocks ) {\n    this.writeCount = -1;\n    return false; /* no more blocks */\n  }\n  this.blockCRC = new CRC32();\n  return true;\n};\n/* XXX micro-bunzip uses (inputStream, inputBuffer, len) as arguments */\nBunzip.prototype._start_bunzip = function(inputStream, outputStream) {\n  /* Ensure that file starts with \"BZh['1'-'9'].\" */\n  var buf = new Buffer(4);\n  if (inputStream.read(buf, 0, 4) !== 4 ||\n      String.fromCharCode(buf[0], buf[1], buf[2]) !== 'BZh')\n    _throw(Err.NOT_BZIP_DATA, 'bad magic');\n\n  var level = buf[3] - 0x30;\n  if (level < 1 || level > 9)\n    _throw(Err.NOT_BZIP_DATA, 'level out of range');\n\n  this.reader = new BitReader(inputStream);\n\n  /* Fourth byte (ascii '1'-'9'), indicates block size in units of 100k of\n     uncompressed data.  Allocate intermediate buffer for block. */\n  this.dbufSize = 100000 * level;\n  this.nextoutput = 0;\n  this.outputStream = outputStream;\n  this.streamCRC = 0;\n};\nBunzip.prototype._get_next_block = function() {\n  var i, j, k;\n  var reader = this.reader;\n  // this is get_next_block() function from micro-bunzip:\n  /* Read in header signature and CRC, then validate signature.\n     (last block signature means CRC is for whole file, return now) */\n  var h = reader.pi();\n  if (h === SQRTPI) { // last block\n    return false; /* no more blocks */\n  }\n  if (h !== WHOLEPI)\n    _throw(Err.NOT_BZIP_DATA);\n  this.targetBlockCRC = reader.read(32) >>> 0; // (convert to unsigned)\n  this.streamCRC = (this.targetBlockCRC ^\n                    ((this.streamCRC << 1) | (this.streamCRC>>>31))) >>> 0;\n  /* We can add support for blockRandomised if anybody complains.  There was\n     some code for this in busybox 1.0.0-pre3, but nobody ever noticed that\n     it didn't actually work. */\n  if (reader.read(1))\n    _throw(Err.OBSOLETE_INPUT);\n  var origPointer = reader.read(24);\n  if (origPointer > this.dbufSize)\n    _throw(Err.DATA_ERROR, 'initial position out of bounds');\n  /* mapping table: if some byte values are never used (encoding things\n     like ascii text), the compression code removes the gaps to have fewer\n     symbols to deal with, and writes a sparse bitfield indicating which\n     values were present.  We make a translation table to convert the symbols\n     back to the corresponding bytes. */\n  var t = reader.read(16);\n  var symToByte = new Buffer(256), symTotal = 0;\n  for (i = 0; i < 16; i++) {\n    if (t & (1 << (0xF - i))) {\n      var o = i * 16;\n      k = reader.read(16);\n      for (j = 0; j < 16; j++)\n        if (k & (1 << (0xF - j)))\n          symToByte[symTotal++] = o + j;\n    }\n  }\n\n  /* How many different huffman coding groups does this block use? */\n  var groupCount = reader.read(3);\n  if (groupCount < MIN_GROUPS || groupCount > MAX_GROUPS)\n    _throw(Err.DATA_ERROR);\n  /* nSelectors: Every GROUP_SIZE many symbols we select a new huffman coding\n     group.  Read in the group selector list, which is stored as MTF encoded\n     bit runs.  (MTF=Move To Front, as each value is used it's moved to the\n     start of the list.) */\n  var nSelectors = reader.read(15);\n  if (nSelectors === 0)\n    _throw(Err.DATA_ERROR);\n\n  var mtfSymbol = new Buffer(256);\n  for (i = 0; i < groupCount; i++)\n    mtfSymbol[i] = i;\n\n  var selectors = new Buffer(nSelectors); // was 32768...\n\n  for (i = 0; i < nSelectors; i++) {\n    /* Get next value */\n    for (j = 0; reader.read(1); j++)\n      if (j >= groupCount) _throw(Err.DATA_ERROR);\n    /* Decode MTF to get the next selector */\n    selectors[i] = mtf(mtfSymbol, j);\n  }\n\n  /* Read the huffman coding tables for each group, which code for symTotal\n     literal symbols, plus two run symbols (RUNA, RUNB) */\n  var symCount = symTotal + 2;\n  var groups = [], hufGroup;\n  for (j = 0; j < groupCount; j++) {\n    var length = new Buffer(symCount), temp = new Uint16Array(MAX_HUFCODE_BITS + 1);\n    /* Read huffman code lengths for each symbol.  They're stored in\n       a way similar to mtf; record a starting value for the first symbol,\n       and an offset from the previous value for everys symbol after that. */\n    t = reader.read(5); // lengths\n    for (i = 0; i < symCount; i++) {\n      for (;;) {\n        if (t < 1 || t > MAX_HUFCODE_BITS) _throw(Err.DATA_ERROR);\n        /* If first bit is 0, stop.  Else second bit indicates whether\n           to increment or decrement the value. */\n        if(!reader.read(1))\n          break;\n        if(!reader.read(1))\n          t++;\n        else\n          t--;\n      }\n      length[i] = t;\n    }\n\n    /* Find largest and smallest lengths in this group */\n    var minLen,  maxLen;\n    minLen = maxLen = length[0];\n    for (i = 1; i < symCount; i++) {\n      if (length[i] > maxLen)\n        maxLen = length[i];\n      else if (length[i] < minLen)\n        minLen = length[i];\n    }\n\n    /* Calculate permute[], base[], and limit[] tables from length[].\n     *\n     * permute[] is the lookup table for converting huffman coded symbols\n     * into decoded symbols.  base[] is the amount to subtract from the\n     * value of a huffman symbol of a given length when using permute[].\n     *\n     * limit[] indicates the largest numerical value a symbol with a given\n     * number of bits can have.  This is how the huffman codes can vary in\n     * length: each code with a value>limit[length] needs another bit.\n     */\n    hufGroup = {};\n    groups.push(hufGroup);\n    hufGroup.permute = new Uint16Array(MAX_SYMBOLS);\n    hufGroup.limit = new Uint32Array(MAX_HUFCODE_BITS + 2);\n    hufGroup.base = new Uint32Array(MAX_HUFCODE_BITS + 1);\n    hufGroup.minLen = minLen;\n    hufGroup.maxLen = maxLen;\n    /* Calculate permute[].  Concurently, initialize temp[] and limit[]. */\n    var pp = 0;\n    for (i = minLen; i <= maxLen; i++) {\n      temp[i] = hufGroup.limit[i] = 0;\n      for (t = 0; t < symCount; t++)\n        if (length[t] === i)\n          hufGroup.permute[pp++] = t;\n    }\n    /* Count symbols coded for at each bit length */\n    for (i = 0; i < symCount; i++)\n      temp[length[i]]++;\n    /* Calculate limit[] (the largest symbol-coding value at each bit\n     * length, which is (previous limit<<1)+symbols at this level), and\n     * base[] (number of symbols to ignore at each bit length, which is\n     * limit minus the cumulative count of symbols coded for already). */\n    pp = t = 0;\n    for (i = minLen; i < maxLen; i++) {\n      pp += temp[i];\n      /* We read the largest possible symbol size and then unget bits\n         after determining how many we need, and those extra bits could\n         be set to anything.  (They're noise from future symbols.)  At\n         each level we're really only interested in the first few bits,\n         so here we set all the trailing to-be-ignored bits to 1 so they\n         don't affect the value>limit[length] comparison. */\n      hufGroup.limit[i] = pp - 1;\n      pp <<= 1;\n      t += temp[i];\n      hufGroup.base[i + 1] = pp - t;\n    }\n    hufGroup.limit[maxLen + 1] = Number.MAX_VALUE; /* Sentinal value for reading next sym. */\n    hufGroup.limit[maxLen] = pp + temp[maxLen] - 1;\n    hufGroup.base[minLen] = 0;\n  }\n  /* We've finished reading and digesting the block header.  Now read this\n     block's huffman coded symbols from the file and undo the huffman coding\n     and run length encoding, saving the result into dbuf[dbufCount++]=uc */\n\n  /* Initialize symbol occurrence counters and symbol Move To Front table */\n  var byteCount = new Uint32Array(256);\n  for (i = 0; i < 256; i++)\n    mtfSymbol[i] = i;\n  /* Loop through compressed symbols. */\n  var runPos = 0, dbufCount = 0, selector = 0, uc;\n  var dbuf = this.dbuf = new Uint32Array(this.dbufSize);\n  symCount = 0;\n  for (;;) {\n    /* Determine which huffman coding group to use. */\n    if (!(symCount--)) {\n      symCount = GROUP_SIZE - 1;\n      if (selector >= nSelectors) { _throw(Err.DATA_ERROR); }\n      hufGroup = groups[selectors[selector++]];\n    }\n    /* Read next huffman-coded symbol. */\n    i = hufGroup.minLen;\n    j = reader.read(i);\n    for (;;i++) {\n      if (i > hufGroup.maxLen) { _throw(Err.DATA_ERROR); }\n      if (j <= hufGroup.limit[i])\n        break;\n      j = (j << 1) | reader.read(1);\n    }\n    /* Huffman decode value to get nextSym (with bounds checking) */\n    j -= hufGroup.base[i];\n    if (j < 0 || j >= MAX_SYMBOLS) { _throw(Err.DATA_ERROR); }\n    var nextSym = hufGroup.permute[j];\n    /* We have now decoded the symbol, which indicates either a new literal\n       byte, or a repeated run of the most recent literal byte.  First,\n       check if nextSym indicates a repeated run, and if so loop collecting\n       how many times to repeat the last literal. */\n    if (nextSym === SYMBOL_RUNA || nextSym === SYMBOL_RUNB) {\n      /* If this is the start of a new run, zero out counter */\n      if (!runPos){\n        runPos = 1;\n        t = 0;\n      }\n      /* Neat trick that saves 1 symbol: instead of or-ing 0 or 1 at\n         each bit position, add 1 or 2 instead.  For example,\n         1011 is 1<<0 + 1<<1 + 2<<2.  1010 is 2<<0 + 2<<1 + 1<<2.\n         You can make any bit pattern that way using 1 less symbol than\n         the basic or 0/1 method (except all bits 0, which would use no\n         symbols, but a run of length 0 doesn't mean anything in this\n         context).  Thus space is saved. */\n      if (nextSym === SYMBOL_RUNA)\n        t += runPos;\n      else\n        t += 2 * runPos;\n      runPos <<= 1;\n      continue;\n    }\n    /* When we hit the first non-run symbol after a run, we now know\n       how many times to repeat the last literal, so append that many\n       copies to our buffer of decoded symbols (dbuf) now.  (The last\n       literal used is the one at the head of the mtfSymbol array.) */\n    if (runPos){\n      runPos = 0;\n      if (dbufCount + t > this.dbufSize) { _throw(Err.DATA_ERROR); }\n      uc = symToByte[mtfSymbol[0]];\n      byteCount[uc] += t;\n      while (t--)\n        dbuf[dbufCount++] = uc;\n    }\n    /* Is this the terminating symbol? */\n    if (nextSym > symTotal)\n      break;\n    /* At this point, nextSym indicates a new literal character.  Subtract\n       one to get the position in the MTF array at which this literal is\n       currently to be found.  (Note that the result can't be -1 or 0,\n       because 0 and 1 are RUNA and RUNB.  But another instance of the\n       first symbol in the mtf array, position 0, would have been handled\n       as part of a run above.  Therefore 1 unused mtf position minus\n       2 non-literal nextSym values equals -1.) */\n    if (dbufCount >= this.dbufSize) { _throw(Err.DATA_ERROR); }\n    i = nextSym - 1;\n    uc = mtf(mtfSymbol, i);\n    uc = symToByte[uc];\n    /* We have our literal byte.  Save it into dbuf. */\n    byteCount[uc]++;\n    dbuf[dbufCount++] = uc;\n  }\n  /* At this point, we've read all the huffman-coded symbols (and repeated\n     runs) for this block from the input stream, and decoded them into the\n     intermediate buffer.  There are dbufCount many decoded bytes in dbuf[].\n     Now undo the Burrows-Wheeler transform on dbuf.\n     See http://dogma.net/markn/articles/bwt/bwt.htm\n  */\n  if (origPointer < 0 || origPointer >= dbufCount) { _throw(Err.DATA_ERROR); }\n  /* Turn byteCount into cumulative occurrence counts of 0 to n-1. */\n  j = 0;\n  for (i = 0; i < 256; i++) {\n    k = j + byteCount[i];\n    byteCount[i] = j;\n    j = k;\n  }\n  /* Figure out what order dbuf would be in if we sorted it. */\n  for (i = 0; i < dbufCount; i++) {\n    uc = dbuf[i] & 0xff;\n    dbuf[byteCount[uc]] |= (i << 8);\n    byteCount[uc]++;\n  }\n  /* Decode first byte by hand to initialize \"previous\" byte.  Note that it\n     doesn't get output, and if the first three characters are identical\n     it doesn't qualify as a run (hence writeRunCountdown=5). */\n  var pos = 0, current = 0, run = 0;\n  if (dbufCount) {\n    pos = dbuf[origPointer];\n    current = (pos & 0xff);\n    pos >>= 8;\n    run = -1;\n  }\n  this.writePos = pos;\n  this.writeCurrent = current;\n  this.writeCount = dbufCount;\n  this.writeRun = run;\n\n  return true; /* more blocks to come */\n};\n/* Undo burrows-wheeler transform on intermediate buffer to produce output.\n   If start_bunzip was initialized with out_fd=-1, then up to len bytes of\n   data are written to outbuf.  Return value is number of bytes written or\n   error (all errors are negative numbers).  If out_fd!=-1, outbuf and len\n   are ignored, data is written to out_fd and return is RETVAL_OK or error.\n*/\nBunzip.prototype._read_bunzip = function(outputBuffer, len) {\n    var copies, previous, outbyte;\n    /* james@jamestaylor.org: writeCount goes to -1 when the buffer is fully\n       decoded, which results in this returning RETVAL_LAST_BLOCK, also\n       equal to -1... Confusing, I'm returning 0 here to indicate no\n       bytes written into the buffer */\n  if (this.writeCount < 0) { return 0; }\n\n  var gotcount = 0;\n  var dbuf = this.dbuf, pos = this.writePos, current = this.writeCurrent;\n  var dbufCount = this.writeCount, outputsize = this.outputsize;\n  var run = this.writeRun;\n\n  while (dbufCount) {\n    dbufCount--;\n    previous = current;\n    pos = dbuf[pos];\n    current = pos & 0xff;\n    pos >>= 8;\n    if (run++ === 3){\n      copies = current;\n      outbyte = previous;\n      current = -1;\n    } else {\n      copies = 1;\n      outbyte = current;\n    }\n    this.blockCRC.updateCRCRun(outbyte, copies);\n    while (copies--) {\n      this.outputStream.writeByte(outbyte);\n      this.nextoutput++;\n    }\n    if (current != previous)\n      run = 0;\n  }\n  this.writeCount = dbufCount;\n  // check CRC\n  if (this.blockCRC.getCRC() !== this.targetBlockCRC) {\n    _throw(Err.DATA_ERROR, \"Bad block CRC \"+\n           \"(got \"+this.blockCRC.getCRC().toString(16)+\n           \" expected \"+this.targetBlockCRC.toString(16)+\")\");\n  }\n  return this.nextoutput;\n};\n\nvar coerceInputStream = function(input) {\n  if ('readByte' in input) { return input; }\n  var inputStream = new Stream();\n  inputStream.pos = 0;\n  inputStream.readByte = function() { return input[this.pos++]; };\n  inputStream.seek = function(pos) { this.pos = pos; };\n  inputStream.eof = function() { return this.pos >= input.length; };\n  return inputStream;\n};\nvar coerceOutputStream = function(output) {\n  var outputStream = new Stream();\n  var resizeOk = true;\n  if (output) {\n    if (typeof(output)==='number') {\n      outputStream.buffer = new Buffer(output);\n      resizeOk = false;\n    } else if ('writeByte' in output) {\n      return output;\n    } else {\n      outputStream.buffer = output;\n      resizeOk = false;\n    }\n  } else {\n    outputStream.buffer = new Buffer(16384);\n  }\n  outputStream.pos = 0;\n  outputStream.writeByte = function(_byte) {\n    if (resizeOk && this.pos >= this.buffer.length) {\n      var newBuffer = new Buffer(this.buffer.length*2);\n      this.buffer.copy(newBuffer);\n      this.buffer = newBuffer;\n    }\n    this.buffer[this.pos++] = _byte;\n  };\n  outputStream.getBuffer = function() {\n    // trim buffer\n    if (this.pos !== this.buffer.length) {\n      if (!resizeOk)\n        throw new TypeError('outputsize does not match decoded input');\n      var newBuffer = new Buffer(this.pos);\n      this.buffer.copy(newBuffer, 0, 0, this.pos);\n      this.buffer = newBuffer;\n    }\n    return this.buffer;\n  };\n  outputStream._coerced = true;\n  return outputStream;\n};\n\n/* Static helper functions */\nBunzip.Err = Err;\n// 'input' can be a stream or a buffer\n// 'output' can be a stream or a buffer or a number (buffer size)\nBunzip.decode = function(input, output, multistream) {\n  // make a stream from a buffer, if necessary\n  var inputStream = coerceInputStream(input);\n  var outputStream = coerceOutputStream(output);\n\n  var bz = new Bunzip(inputStream, outputStream);\n  while (true) {\n    if ('eof' in inputStream && inputStream.eof()) break;\n    if (bz._init_block()) {\n      bz._read_bunzip();\n    } else {\n      var targetStreamCRC = bz.reader.read(32) >>> 0; // (convert to unsigned)\n      if (targetStreamCRC !== bz.streamCRC) {\n        _throw(Err.DATA_ERROR, \"Bad stream CRC \"+\n               \"(got \"+bz.streamCRC.toString(16)+\n               \" expected \"+targetStreamCRC.toString(16)+\")\");\n      }\n      if (multistream &&\n          'eof' in inputStream &&\n          !inputStream.eof()) {\n        // note that start_bunzip will also resync the bit reader to next byte\n        bz._start_bunzip(inputStream, outputStream);\n      } else break;\n    }\n  }\n  if ('getBuffer' in outputStream)\n    return outputStream.getBuffer();\n};\nBunzip.decodeBlock = function(input, pos, output) {\n  // make a stream from a buffer, if necessary\n  var inputStream = coerceInputStream(input);\n  var outputStream = coerceOutputStream(output);\n  var bz = new Bunzip(inputStream, outputStream);\n  bz.reader.seek(pos);\n  /* Fill the decode buffer for the block */\n  var moreBlocks = bz._get_next_block();\n  if (moreBlocks) {\n    /* Init the CRC for writing */\n    bz.blockCRC = new CRC32();\n\n    /* Zero this so the current byte from before the seek is not written */\n    bz.writeCopies = 0;\n\n    /* Decompress the block and write to stdout */\n    bz._read_bunzip();\n    // XXX keep writing?\n  }\n  if ('getBuffer' in outputStream)\n    return outputStream.getBuffer();\n};\n/* Reads bzip2 file from stream or buffer `input`, and invoke\n * `callback(position, size)` once for each bzip2 block,\n * where position gives the starting position (in *bits*)\n * and size gives uncompressed size of the block (in *bytes*). */\nBunzip.table = function(input, callback, multistream) {\n  // make a stream from a buffer, if necessary\n  var inputStream = new Stream();\n  inputStream.delegate = coerceInputStream(input);\n  inputStream.pos = 0;\n  inputStream.readByte = function() {\n    this.pos++;\n    return this.delegate.readByte();\n  };\n  if (inputStream.delegate.eof) {\n    inputStream.eof = inputStream.delegate.eof.bind(inputStream.delegate);\n  }\n  var outputStream = new Stream();\n  outputStream.pos = 0;\n  outputStream.writeByte = function() { this.pos++; };\n\n  var bz = new Bunzip(inputStream, outputStream);\n  var blockSize = bz.dbufSize;\n  while (true) {\n    if ('eof' in inputStream && inputStream.eof()) break;\n\n    var position = inputStream.pos*8 + bz.reader.bitOffset;\n    if (bz.reader.hasByte) { position -= 8; }\n\n    if (bz._init_block()) {\n      var start = outputStream.pos;\n      bz._read_bunzip();\n      callback(position, outputStream.pos - start);\n    } else {\n      var crc = bz.reader.read(32); // (but we ignore the crc)\n      if (multistream &&\n          'eof' in inputStream &&\n          !inputStream.eof()) {\n        // note that start_bunzip will also resync the bit reader to next byte\n        bz._start_bunzip(inputStream, outputStream);\n        console.assert(bz.dbufSize === blockSize,\n                       \"shouldn't change block size within multistream file\");\n      } else break;\n    }\n  }\n};\n\nBunzip.Stream = Stream;\n\nBunzip.version = pjson.version;\nBunzip.license = pjson.license;\n\nmodule.exports = Bunzip;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/stream.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/stream.js ***!
  \*********************************************************************************/
/***/ ((module) => {

eval("/* very simple input/output stream interface */\nvar Stream = function() {\n};\n\n// input streams //////////////\n/** Returns the next byte, or -1 for EOF. */\nStream.prototype.readByte = function() {\n  throw new Error(\"abstract method readByte() not implemented\");\n};\n/** Attempts to fill the buffer; returns number of bytes read, or\n *  -1 for EOF. */\nStream.prototype.read = function(buffer, bufOffset, length) {\n  var bytesRead = 0;\n  while (bytesRead < length) {\n    var c = this.readByte();\n    if (c < 0) { // EOF\n      return (bytesRead===0) ? -1 : bytesRead;\n    }\n    buffer[bufOffset++] = c;\n    bytesRead++;\n  }\n  return bytesRead;\n};\nStream.prototype.seek = function(new_pos) {\n  throw new Error(\"abstract method seek() not implemented\");\n};\n\n// output streams ///////////\nStream.prototype.writeByte = function(_byte) {\n  throw new Error(\"abstract method readByte() not implemented\");\n};\nStream.prototype.write = function(buffer, bufOffset, length) {\n  var i;\n  for (i=0; i<length; i++) {\n    this.writeByte(buffer[bufOffset++]);\n  }\n  return length;\n};\nStream.prototype.flush = function() {\n};\n\nmodule.exports = Stream;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/lib/stream.js?");

/***/ }),

/***/ "./node_modules/.pnpm/string_decoder@1.1.1/node_modules/string_decoder/lib/string_decoder.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/string_decoder@1.1.1/node_modules/string_decoder/lib/string_decoder.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"./node_modules/.pnpm/safe-buffer@5.1.2/node_modules/safe-buffer/index.js\").Buffer);\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/string_decoder@1.1.1/node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strip-dirs@2.1.0/node_modules/strip-dirs/index.js":
/*!******************************************************************************!*\
  !*** ./node_modules/.pnpm/strip-dirs@2.1.0/node_modules/strip-dirs/index.js ***!
  \******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * strip-dirs | MIT (c) Shinnosuke Watanabe\n * https://github.com/shinnn/node-strip-dirs\n*/\n\n\nconst path = __webpack_require__(/*! path */ \"path\");\nconst util = __webpack_require__(/*! util */ \"util\");\n\nconst isNaturalNumber = __webpack_require__(/*! is-natural-number */ \"./node_modules/.pnpm/is-natural-number@4.0.1/node_modules/is-natural-number/index.js\");\n\nmodule.exports = function stripDirs(pathStr, count, option) {\n  if (typeof pathStr !== 'string') {\n    throw new TypeError(\n      util.inspect(pathStr) +\n      ' is not a string. First argument to strip-dirs must be a path string.'\n    );\n  }\n\n  if (path.posix.isAbsolute(pathStr) || path.win32.isAbsolute(pathStr)) {\n    throw new Error(`${pathStr} is an absolute path. strip-dirs requires a relative path.`);\n  }\n\n  if (!isNaturalNumber(count, {includeZero: true})) {\n    throw new Error(\n      'The Second argument of strip-dirs must be a natural number or 0, but received ' +\n      util.inspect(count) +\n      '.'\n    );\n  }\n\n  if (option) {\n    if (typeof option !== 'object') {\n      throw new TypeError(\n        util.inspect(option) +\n        ' is not an object. Expected an object with a boolean `disallowOverflow` property.'\n      );\n    }\n\n    if (Array.isArray(option)) {\n      throw new TypeError(\n        util.inspect(option) +\n        ' is an array. Expected an object with a boolean `disallowOverflow` property.'\n      );\n    }\n\n    if ('disallowOverflow' in option && typeof option.disallowOverflow !== 'boolean') {\n      throw new TypeError(\n        util.inspect(option.disallowOverflow) +\n        ' is neither true nor false. `disallowOverflow` option must be a Boolean value.'\n      );\n    }\n  } else {\n    option = {disallowOverflow: false};\n  }\n\n  const pathComponents = path.normalize(pathStr).split(path.sep);\n\n  if (pathComponents.length > 1 && pathComponents[0] === '.') {\n    pathComponents.shift();\n  }\n\n  if (count > pathComponents.length - 1) {\n    if (option.disallowOverflow) {\n      throw new RangeError('Cannot strip more directories than there are.');\n    }\n\n    count = pathComponents.length - 1;\n  }\n\n  return path.join.apply(null, pathComponents.slice(count));\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strip-dirs@2.1.0/node_modules/strip-dirs/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/extract.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/extract.js ***!
  \********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var util = __webpack_require__(/*! util */ \"util\")\nvar bl = __webpack_require__(/*! bl */ \"./node_modules/.pnpm/bl@1.2.3/node_modules/bl/bl.js\")\nvar xtend = __webpack_require__(/*! xtend */ \"./node_modules/.pnpm/xtend@4.0.2/node_modules/xtend/immutable.js\")\nvar headers = __webpack_require__(/*! ./headers */ \"./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/headers.js\")\n\nvar Writable = (__webpack_require__(/*! readable-stream */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js\").Writable)\nvar PassThrough = (__webpack_require__(/*! readable-stream */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js\").PassThrough)\n\nvar noop = function () {}\n\nvar overflow = function (size) {\n  size &= 511\n  return size && 512 - size\n}\n\nvar emptyStream = function (self, offset) {\n  var s = new Source(self, offset)\n  s.end()\n  return s\n}\n\nvar mixinPax = function (header, pax) {\n  if (pax.path) header.name = pax.path\n  if (pax.linkpath) header.linkname = pax.linkpath\n  if (pax.size) header.size = parseInt(pax.size, 10)\n  header.pax = pax\n  return header\n}\n\nvar Source = function (self, offset) {\n  this._parent = self\n  this.offset = offset\n  PassThrough.call(this)\n}\n\nutil.inherits(Source, PassThrough)\n\nSource.prototype.destroy = function (err) {\n  this._parent.destroy(err)\n}\n\nvar Extract = function (opts) {\n  if (!(this instanceof Extract)) return new Extract(opts)\n  Writable.call(this, opts)\n\n  opts = opts || {}\n\n  this._offset = 0\n  this._buffer = bl()\n  this._missing = 0\n  this._partial = false\n  this._onparse = noop\n  this._header = null\n  this._stream = null\n  this._overflow = null\n  this._cb = null\n  this._locked = false\n  this._destroyed = false\n  this._pax = null\n  this._paxGlobal = null\n  this._gnuLongPath = null\n  this._gnuLongLinkPath = null\n\n  var self = this\n  var b = self._buffer\n\n  var oncontinue = function () {\n    self._continue()\n  }\n\n  var onunlock = function (err) {\n    self._locked = false\n    if (err) return self.destroy(err)\n    if (!self._stream) oncontinue()\n  }\n\n  var onstreamend = function () {\n    self._stream = null\n    var drain = overflow(self._header.size)\n    if (drain) self._parse(drain, ondrain)\n    else self._parse(512, onheader)\n    if (!self._locked) oncontinue()\n  }\n\n  var ondrain = function () {\n    self._buffer.consume(overflow(self._header.size))\n    self._parse(512, onheader)\n    oncontinue()\n  }\n\n  var onpaxglobalheader = function () {\n    var size = self._header.size\n    self._paxGlobal = headers.decodePax(b.slice(0, size))\n    b.consume(size)\n    onstreamend()\n  }\n\n  var onpaxheader = function () {\n    var size = self._header.size\n    self._pax = headers.decodePax(b.slice(0, size))\n    if (self._paxGlobal) self._pax = xtend(self._paxGlobal, self._pax)\n    b.consume(size)\n    onstreamend()\n  }\n\n  var ongnulongpath = function () {\n    var size = self._header.size\n    this._gnuLongPath = headers.decodeLongPath(b.slice(0, size), opts.filenameEncoding)\n    b.consume(size)\n    onstreamend()\n  }\n\n  var ongnulonglinkpath = function () {\n    var size = self._header.size\n    this._gnuLongLinkPath = headers.decodeLongPath(b.slice(0, size), opts.filenameEncoding)\n    b.consume(size)\n    onstreamend()\n  }\n\n  var onheader = function () {\n    var offset = self._offset\n    var header\n    try {\n      header = self._header = headers.decode(b.slice(0, 512), opts.filenameEncoding)\n    } catch (err) {\n      self.emit('error', err)\n    }\n    b.consume(512)\n\n    if (!header) {\n      self._parse(512, onheader)\n      oncontinue()\n      return\n    }\n    if (header.type === 'gnu-long-path') {\n      self._parse(header.size, ongnulongpath)\n      oncontinue()\n      return\n    }\n    if (header.type === 'gnu-long-link-path') {\n      self._parse(header.size, ongnulonglinkpath)\n      oncontinue()\n      return\n    }\n    if (header.type === 'pax-global-header') {\n      self._parse(header.size, onpaxglobalheader)\n      oncontinue()\n      return\n    }\n    if (header.type === 'pax-header') {\n      self._parse(header.size, onpaxheader)\n      oncontinue()\n      return\n    }\n\n    if (self._gnuLongPath) {\n      header.name = self._gnuLongPath\n      self._gnuLongPath = null\n    }\n\n    if (self._gnuLongLinkPath) {\n      header.linkname = self._gnuLongLinkPath\n      self._gnuLongLinkPath = null\n    }\n\n    if (self._pax) {\n      self._header = header = mixinPax(header, self._pax)\n      self._pax = null\n    }\n\n    self._locked = true\n\n    if (!header.size || header.type === 'directory') {\n      self._parse(512, onheader)\n      self.emit('entry', header, emptyStream(self, offset), onunlock)\n      return\n    }\n\n    self._stream = new Source(self, offset)\n\n    self.emit('entry', header, self._stream, onunlock)\n    self._parse(header.size, onstreamend)\n    oncontinue()\n  }\n\n  this._onheader = onheader\n  this._parse(512, onheader)\n}\n\nutil.inherits(Extract, Writable)\n\nExtract.prototype.destroy = function (err) {\n  if (this._destroyed) return\n  this._destroyed = true\n\n  if (err) this.emit('error', err)\n  this.emit('close')\n  if (this._stream) this._stream.emit('close')\n}\n\nExtract.prototype._parse = function (size, onparse) {\n  if (this._destroyed) return\n  this._offset += size\n  this._missing = size\n  if (onparse === this._onheader) this._partial = false\n  this._onparse = onparse\n}\n\nExtract.prototype._continue = function () {\n  if (this._destroyed) return\n  var cb = this._cb\n  this._cb = noop\n  if (this._overflow) this._write(this._overflow, undefined, cb)\n  else cb()\n}\n\nExtract.prototype._write = function (data, enc, cb) {\n  if (this._destroyed) return\n\n  var s = this._stream\n  var b = this._buffer\n  var missing = this._missing\n  if (data.length) this._partial = true\n\n  // we do not reach end-of-chunk now. just forward it\n\n  if (data.length < missing) {\n    this._missing -= data.length\n    this._overflow = null\n    if (s) return s.write(data, cb)\n    b.append(data)\n    return cb()\n  }\n\n  // end-of-chunk. the parser should call cb.\n\n  this._cb = cb\n  this._missing = 0\n\n  var overflow = null\n  if (data.length > missing) {\n    overflow = data.slice(missing)\n    data = data.slice(0, missing)\n  }\n\n  if (s) s.end(data)\n  else b.append(data)\n\n  this._overflow = overflow\n  this._onparse()\n}\n\nExtract.prototype._final = function (cb) {\n  if (this._partial) return this.destroy(new Error('Unexpected end of data'))\n  cb()\n}\n\nmodule.exports = Extract\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/extract.js?");

/***/ }),

/***/ "./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/headers.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/headers.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("var toBuffer = __webpack_require__(/*! to-buffer */ \"./node_modules/.pnpm/to-buffer@1.1.1/node_modules/to-buffer/index.js\")\nvar alloc = __webpack_require__(/*! buffer-alloc */ \"./node_modules/.pnpm/buffer-alloc@1.2.0/node_modules/buffer-alloc/index.js\")\n\nvar ZEROS = '0000000000000000000'\nvar SEVENS = '7777777777777777777'\nvar ZERO_OFFSET = '0'.charCodeAt(0)\nvar USTAR = 'ustar\\x0000'\nvar MASK = parseInt('7777', 8)\n\nvar clamp = function (index, len, defaultValue) {\n  if (typeof index !== 'number') return defaultValue\n  index = ~~index // Coerce to integer.\n  if (index >= len) return len\n  if (index >= 0) return index\n  index += len\n  if (index >= 0) return index\n  return 0\n}\n\nvar toType = function (flag) {\n  switch (flag) {\n    case 0:\n      return 'file'\n    case 1:\n      return 'link'\n    case 2:\n      return 'symlink'\n    case 3:\n      return 'character-device'\n    case 4:\n      return 'block-device'\n    case 5:\n      return 'directory'\n    case 6:\n      return 'fifo'\n    case 7:\n      return 'contiguous-file'\n    case 72:\n      return 'pax-header'\n    case 55:\n      return 'pax-global-header'\n    case 27:\n      return 'gnu-long-link-path'\n    case 28:\n    case 30:\n      return 'gnu-long-path'\n  }\n\n  return null\n}\n\nvar toTypeflag = function (flag) {\n  switch (flag) {\n    case 'file':\n      return 0\n    case 'link':\n      return 1\n    case 'symlink':\n      return 2\n    case 'character-device':\n      return 3\n    case 'block-device':\n      return 4\n    case 'directory':\n      return 5\n    case 'fifo':\n      return 6\n    case 'contiguous-file':\n      return 7\n    case 'pax-header':\n      return 72\n  }\n\n  return 0\n}\n\nvar indexOf = function (block, num, offset, end) {\n  for (; offset < end; offset++) {\n    if (block[offset] === num) return offset\n  }\n  return end\n}\n\nvar cksum = function (block) {\n  var sum = 8 * 32\n  for (var i = 0; i < 148; i++) sum += block[i]\n  for (var j = 156; j < 512; j++) sum += block[j]\n  return sum\n}\n\nvar encodeOct = function (val, n) {\n  val = val.toString(8)\n  if (val.length > n) return SEVENS.slice(0, n) + ' '\n  else return ZEROS.slice(0, n - val.length) + val + ' '\n}\n\n/* Copied from the node-tar repo and modified to meet\n * tar-stream coding standard.\n *\n * Source: https://github.com/npm/node-tar/blob/51b6627a1f357d2eb433e7378e5f05e83b7aa6cd/lib/header.js#L349\n */\nfunction parse256 (buf) {\n  // first byte MUST be either 80 or FF\n  // 80 for positive, FF for 2's comp\n  var positive\n  if (buf[0] === 0x80) positive = true\n  else if (buf[0] === 0xFF) positive = false\n  else return null\n\n  // build up a base-256 tuple from the least sig to the highest\n  var zero = false\n  var tuple = []\n  for (var i = buf.length - 1; i > 0; i--) {\n    var byte = buf[i]\n    if (positive) tuple.push(byte)\n    else if (zero && byte === 0) tuple.push(0)\n    else if (zero) {\n      zero = false\n      tuple.push(0x100 - byte)\n    } else tuple.push(0xFF - byte)\n  }\n\n  var sum = 0\n  var l = tuple.length\n  for (i = 0; i < l; i++) {\n    sum += tuple[i] * Math.pow(256, i)\n  }\n\n  return positive ? sum : -1 * sum\n}\n\nvar decodeOct = function (val, offset, length) {\n  val = val.slice(offset, offset + length)\n  offset = 0\n\n  // If prefixed with 0x80 then parse as a base-256 integer\n  if (val[offset] & 0x80) {\n    return parse256(val)\n  } else {\n    // Older versions of tar can prefix with spaces\n    while (offset < val.length && val[offset] === 32) offset++\n    var end = clamp(indexOf(val, 32, offset, val.length), val.length, val.length)\n    while (offset < end && val[offset] === 0) offset++\n    if (end === offset) return 0\n    return parseInt(val.slice(offset, end).toString(), 8)\n  }\n}\n\nvar decodeStr = function (val, offset, length, encoding) {\n  return val.slice(offset, indexOf(val, 0, offset, offset + length)).toString(encoding)\n}\n\nvar addLength = function (str) {\n  var len = Buffer.byteLength(str)\n  var digits = Math.floor(Math.log(len) / Math.log(10)) + 1\n  if (len + digits >= Math.pow(10, digits)) digits++\n\n  return (len + digits) + str\n}\n\nexports.decodeLongPath = function (buf, encoding) {\n  return decodeStr(buf, 0, buf.length, encoding)\n}\n\nexports.encodePax = function (opts) { // TODO: encode more stuff in pax\n  var result = ''\n  if (opts.name) result += addLength(' path=' + opts.name + '\\n')\n  if (opts.linkname) result += addLength(' linkpath=' + opts.linkname + '\\n')\n  var pax = opts.pax\n  if (pax) {\n    for (var key in pax) {\n      result += addLength(' ' + key + '=' + pax[key] + '\\n')\n    }\n  }\n  return toBuffer(result)\n}\n\nexports.decodePax = function (buf) {\n  var result = {}\n\n  while (buf.length) {\n    var i = 0\n    while (i < buf.length && buf[i] !== 32) i++\n    var len = parseInt(buf.slice(0, i).toString(), 10)\n    if (!len) return result\n\n    var b = buf.slice(i + 1, len - 1).toString()\n    var keyIndex = b.indexOf('=')\n    if (keyIndex === -1) return result\n    result[b.slice(0, keyIndex)] = b.slice(keyIndex + 1)\n\n    buf = buf.slice(len)\n  }\n\n  return result\n}\n\nexports.encode = function (opts) {\n  var buf = alloc(512)\n  var name = opts.name\n  var prefix = ''\n\n  if (opts.typeflag === 5 && name[name.length - 1] !== '/') name += '/'\n  if (Buffer.byteLength(name) !== name.length) return null // utf-8\n\n  while (Buffer.byteLength(name) > 100) {\n    var i = name.indexOf('/')\n    if (i === -1) return null\n    prefix += prefix ? '/' + name.slice(0, i) : name.slice(0, i)\n    name = name.slice(i + 1)\n  }\n\n  if (Buffer.byteLength(name) > 100 || Buffer.byteLength(prefix) > 155) return null\n  if (opts.linkname && Buffer.byteLength(opts.linkname) > 100) return null\n\n  buf.write(name)\n  buf.write(encodeOct(opts.mode & MASK, 6), 100)\n  buf.write(encodeOct(opts.uid, 6), 108)\n  buf.write(encodeOct(opts.gid, 6), 116)\n  buf.write(encodeOct(opts.size, 11), 124)\n  buf.write(encodeOct((opts.mtime.getTime() / 1000) | 0, 11), 136)\n\n  buf[156] = ZERO_OFFSET + toTypeflag(opts.type)\n\n  if (opts.linkname) buf.write(opts.linkname, 157)\n\n  buf.write(USTAR, 257)\n  if (opts.uname) buf.write(opts.uname, 265)\n  if (opts.gname) buf.write(opts.gname, 297)\n  buf.write(encodeOct(opts.devmajor || 0, 6), 329)\n  buf.write(encodeOct(opts.devminor || 0, 6), 337)\n\n  if (prefix) buf.write(prefix, 345)\n\n  buf.write(encodeOct(cksum(buf), 6), 148)\n\n  return buf\n}\n\nexports.decode = function (buf, filenameEncoding) {\n  var typeflag = buf[156] === 0 ? 0 : buf[156] - ZERO_OFFSET\n\n  var name = decodeStr(buf, 0, 100, filenameEncoding)\n  var mode = decodeOct(buf, 100, 8)\n  var uid = decodeOct(buf, 108, 8)\n  var gid = decodeOct(buf, 116, 8)\n  var size = decodeOct(buf, 124, 12)\n  var mtime = decodeOct(buf, 136, 12)\n  var type = toType(typeflag)\n  var linkname = buf[157] === 0 ? null : decodeStr(buf, 157, 100, filenameEncoding)\n  var uname = decodeStr(buf, 265, 32)\n  var gname = decodeStr(buf, 297, 32)\n  var devmajor = decodeOct(buf, 329, 8)\n  var devminor = decodeOct(buf, 337, 8)\n\n  if (buf[345]) name = decodeStr(buf, 345, 155, filenameEncoding) + '/' + name\n\n  // to support old tar versions that use trailing / to indicate dirs\n  if (typeflag === 0 && name && name[name.length - 1] === '/') typeflag = 5\n\n  var c = cksum(buf)\n\n  // checksum is still initial value if header was null.\n  if (c === 8 * 32) return null\n\n  // valid checksum\n  if (c !== decodeOct(buf, 148, 8)) throw new Error('Invalid tar header. Maybe the tar is corrupted or it needs to be gunzipped?')\n\n  return {\n    name: name,\n    mode: mode,\n    uid: uid,\n    gid: gid,\n    size: size,\n    mtime: new Date(1000 * mtime),\n    type: type,\n    linkname: linkname,\n    uname: uname,\n    gname: gname,\n    devmajor: devmajor,\n    devminor: devminor\n  }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/headers.js?");

/***/ }),

/***/ "./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/index.js":
/*!******************************************************************************!*\
  !*** ./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/index.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("exports.extract = __webpack_require__(/*! ./extract */ \"./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/extract.js\")\nexports.pack = __webpack_require__(/*! ./pack */ \"./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/pack.js\")\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/pack.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/pack.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var constants = __webpack_require__(/*! fs-constants */ \"./node_modules/.pnpm/fs-constants@1.0.0/node_modules/fs-constants/index.js\")\nvar eos = __webpack_require__(/*! end-of-stream */ \"./node_modules/.pnpm/end-of-stream@1.4.4/node_modules/end-of-stream/index.js\")\nvar util = __webpack_require__(/*! util */ \"util\")\nvar alloc = __webpack_require__(/*! buffer-alloc */ \"./node_modules/.pnpm/buffer-alloc@1.2.0/node_modules/buffer-alloc/index.js\")\nvar toBuffer = __webpack_require__(/*! to-buffer */ \"./node_modules/.pnpm/to-buffer@1.1.1/node_modules/to-buffer/index.js\")\n\nvar Readable = (__webpack_require__(/*! readable-stream */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js\").Readable)\nvar Writable = (__webpack_require__(/*! readable-stream */ \"./node_modules/.pnpm/readable-stream@2.3.7/node_modules/readable-stream/readable.js\").Writable)\nvar StringDecoder = (__webpack_require__(/*! string_decoder */ \"string_decoder\").StringDecoder)\n\nvar headers = __webpack_require__(/*! ./headers */ \"./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/headers.js\")\n\nvar DMODE = parseInt('755', 8)\nvar FMODE = parseInt('644', 8)\n\nvar END_OF_TAR = alloc(1024)\n\nvar noop = function () {}\n\nvar overflow = function (self, size) {\n  size &= 511\n  if (size) self.push(END_OF_TAR.slice(0, 512 - size))\n}\n\nfunction modeToType (mode) {\n  switch (mode & constants.S_IFMT) {\n    case constants.S_IFBLK: return 'block-device'\n    case constants.S_IFCHR: return 'character-device'\n    case constants.S_IFDIR: return 'directory'\n    case constants.S_IFIFO: return 'fifo'\n    case constants.S_IFLNK: return 'symlink'\n  }\n\n  return 'file'\n}\n\nvar Sink = function (to) {\n  Writable.call(this)\n  this.written = 0\n  this._to = to\n  this._destroyed = false\n}\n\nutil.inherits(Sink, Writable)\n\nSink.prototype._write = function (data, enc, cb) {\n  this.written += data.length\n  if (this._to.push(data)) return cb()\n  this._to._drain = cb\n}\n\nSink.prototype.destroy = function () {\n  if (this._destroyed) return\n  this._destroyed = true\n  this.emit('close')\n}\n\nvar LinkSink = function () {\n  Writable.call(this)\n  this.linkname = ''\n  this._decoder = new StringDecoder('utf-8')\n  this._destroyed = false\n}\n\nutil.inherits(LinkSink, Writable)\n\nLinkSink.prototype._write = function (data, enc, cb) {\n  this.linkname += this._decoder.write(data)\n  cb()\n}\n\nLinkSink.prototype.destroy = function () {\n  if (this._destroyed) return\n  this._destroyed = true\n  this.emit('close')\n}\n\nvar Void = function () {\n  Writable.call(this)\n  this._destroyed = false\n}\n\nutil.inherits(Void, Writable)\n\nVoid.prototype._write = function (data, enc, cb) {\n  cb(new Error('No body allowed for this entry'))\n}\n\nVoid.prototype.destroy = function () {\n  if (this._destroyed) return\n  this._destroyed = true\n  this.emit('close')\n}\n\nvar Pack = function (opts) {\n  if (!(this instanceof Pack)) return new Pack(opts)\n  Readable.call(this, opts)\n\n  this._drain = noop\n  this._finalized = false\n  this._finalizing = false\n  this._destroyed = false\n  this._stream = null\n}\n\nutil.inherits(Pack, Readable)\n\nPack.prototype.entry = function (header, buffer, callback) {\n  if (this._stream) throw new Error('already piping an entry')\n  if (this._finalized || this._destroyed) return\n\n  if (typeof buffer === 'function') {\n    callback = buffer\n    buffer = null\n  }\n\n  if (!callback) callback = noop\n\n  var self = this\n\n  if (!header.size || header.type === 'symlink') header.size = 0\n  if (!header.type) header.type = modeToType(header.mode)\n  if (!header.mode) header.mode = header.type === 'directory' ? DMODE : FMODE\n  if (!header.uid) header.uid = 0\n  if (!header.gid) header.gid = 0\n  if (!header.mtime) header.mtime = new Date()\n\n  if (typeof buffer === 'string') buffer = toBuffer(buffer)\n  if (Buffer.isBuffer(buffer)) {\n    header.size = buffer.length\n    this._encode(header)\n    this.push(buffer)\n    overflow(self, header.size)\n    process.nextTick(callback)\n    return new Void()\n  }\n\n  if (header.type === 'symlink' && !header.linkname) {\n    var linkSink = new LinkSink()\n    eos(linkSink, function (err) {\n      if (err) { // stream was closed\n        self.destroy()\n        return callback(err)\n      }\n\n      header.linkname = linkSink.linkname\n      self._encode(header)\n      callback()\n    })\n\n    return linkSink\n  }\n\n  this._encode(header)\n\n  if (header.type !== 'file' && header.type !== 'contiguous-file') {\n    process.nextTick(callback)\n    return new Void()\n  }\n\n  var sink = new Sink(this)\n\n  this._stream = sink\n\n  eos(sink, function (err) {\n    self._stream = null\n\n    if (err) { // stream was closed\n      self.destroy()\n      return callback(err)\n    }\n\n    if (sink.written !== header.size) { // corrupting tar\n      self.destroy()\n      return callback(new Error('size mismatch'))\n    }\n\n    overflow(self, header.size)\n    if (self._finalizing) self.finalize()\n    callback()\n  })\n\n  return sink\n}\n\nPack.prototype.finalize = function () {\n  if (this._stream) {\n    this._finalizing = true\n    return\n  }\n\n  if (this._finalized) return\n  this._finalized = true\n  this.push(END_OF_TAR)\n  this.push(null)\n}\n\nPack.prototype.destroy = function (err) {\n  if (this._destroyed) return\n  this._destroyed = true\n\n  if (err) this.emit('error', err)\n  this.emit('close')\n  if (this._stream && this._stream.destroy) this._stream.destroy()\n}\n\nPack.prototype._encode = function (header) {\n  if (!header.pax) {\n    var buf = headers.encode(header)\n    if (buf) {\n      this.push(buf)\n      return\n    }\n  }\n  this._encodePax(header)\n}\n\nPack.prototype._encodePax = function (header) {\n  var paxHeader = headers.encodePax({\n    name: header.name,\n    linkname: header.linkname,\n    pax: header.pax\n  })\n\n  var newHeader = {\n    name: 'PaxHeader',\n    mode: header.mode,\n    uid: header.uid,\n    gid: header.gid,\n    size: paxHeader.length,\n    mtime: header.mtime,\n    type: 'pax-header',\n    linkname: header.linkname && 'PaxHeader',\n    uname: header.uname,\n    gname: header.gname,\n    devmajor: header.devmajor,\n    devminor: header.devminor\n  }\n\n  this.push(headers.encode(newHeader))\n  this.push(paxHeader)\n  overflow(this, paxHeader.length)\n\n  newHeader.size = header.size\n  newHeader.type = header.type\n  this.push(headers.encode(newHeader))\n}\n\nPack.prototype._read = function (n) {\n  var drain = this._drain\n  this._drain = noop\n  drain()\n}\n\nmodule.exports = Pack\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/tar-stream@1.6.2/node_modules/tar-stream/pack.js?");

/***/ }),

/***/ "./node_modules/.pnpm/through@2.3.8/node_modules/through/index.js":
/*!************************************************************************!*\
  !*** ./node_modules/.pnpm/through@2.3.8/node_modules/through/index.js ***!
  \************************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("var Stream = __webpack_require__(/*! stream */ \"stream\")\n\n// through\n//\n// a stream that does nothing but re-emit the input.\n// useful for aggregating a series of changing but not ending streams into one stream)\n\nexports = module.exports = through\nthrough.through = through\n\n//create a readable writable stream.\n\nfunction through (write, end, opts) {\n  write = write || function (data) { this.queue(data) }\n  end = end || function () { this.queue(null) }\n\n  var ended = false, destroyed = false, buffer = [], _ended = false\n  var stream = new Stream()\n  stream.readable = stream.writable = true\n  stream.paused = false\n\n//  stream.autoPause   = !(opts && opts.autoPause   === false)\n  stream.autoDestroy = !(opts && opts.autoDestroy === false)\n\n  stream.write = function (data) {\n    write.call(this, data)\n    return !stream.paused\n  }\n\n  function drain() {\n    while(buffer.length && !stream.paused) {\n      var data = buffer.shift()\n      if(null === data)\n        return stream.emit('end')\n      else\n        stream.emit('data', data)\n    }\n  }\n\n  stream.queue = stream.push = function (data) {\n//    console.error(ended)\n    if(_ended) return stream\n    if(data === null) _ended = true\n    buffer.push(data)\n    drain()\n    return stream\n  }\n\n  //this will be registered as the first 'end' listener\n  //must call destroy next tick, to make sure we're after any\n  //stream piped from here.\n  //this is only a problem if end is not emitted synchronously.\n  //a nicer way to do this is to make sure this is the last listener for 'end'\n\n  stream.on('end', function () {\n    stream.readable = false\n    if(!stream.writable && stream.autoDestroy)\n      process.nextTick(function () {\n        stream.destroy()\n      })\n  })\n\n  function _end () {\n    stream.writable = false\n    end.call(stream)\n    if(!stream.readable && stream.autoDestroy)\n      stream.destroy()\n  }\n\n  stream.end = function (data) {\n    if(ended) return\n    ended = true\n    if(arguments.length) stream.write(data)\n    _end() // will emit or queue\n    return stream\n  }\n\n  stream.destroy = function () {\n    if(destroyed) return\n    destroyed = true\n    ended = true\n    buffer.length = 0\n    stream.writable = stream.readable = false\n    stream.emit('close')\n    return stream\n  }\n\n  stream.pause = function () {\n    if(stream.paused) return\n    stream.paused = true\n    return stream\n  }\n\n  stream.resume = function () {\n    if(stream.paused) {\n      stream.paused = false\n      stream.emit('resume')\n    }\n    drain()\n    //may have become paused again,\n    //as drain emits 'data'.\n    if(!stream.paused)\n      stream.emit('drain')\n    return stream\n  }\n  return stream\n}\n\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/through@2.3.8/node_modules/through/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/to-buffer@1.1.1/node_modules/to-buffer/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/to-buffer@1.1.1/node_modules/to-buffer/index.js ***!
  \****************************************************************************/
/***/ ((module) => {

eval("module.exports = toBuffer\n\nvar makeBuffer = Buffer.from && Buffer.from !== Uint8Array.from ? Buffer.from : bufferFrom\n\nfunction bufferFrom (buf, enc) {\n  return new Buffer(buf, enc)\n}\n\nfunction toBuffer (buf, enc) {\n  if (Buffer.isBuffer(buf)) return buf\n  if (typeof buf === 'string') return makeBuffer(buf, enc)\n  if (Array.isArray(buf)) return makeBuffer(buf)\n  throw new Error('Input should be a buffer or a string')\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/to-buffer@1.1.1/node_modules/to-buffer/index.js?");

/***/ }),

/***/ "./index.ts":
/*!******************!*\
  !*** ./index.ts ***!
  \******************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("//#! /usr/bin/env node\r\n\r\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\r\nconst lib_1 = __webpack_require__(/*! ./lib/lib */ \"./lib/lib.ts\");\r\n(0, lib_1.checkArgs)()\r\n    .then((target) => {\r\n    return (0, lib_1.extractToDirectory)(target);\r\n})\r\n    .then((directory) => {\r\n    console.log('\\x1b[32m%s\\x1b[0m', ` Images have been extracted to folder ${directory} !`);\r\n})\r\n    .catch((err) => {\r\n    console.error(`\\x1b[31m${err}\\x1b[0m`);\r\n    process.exit(1);\r\n});\r\n\n\n//# sourceURL=webpack://extract-xd/./index.ts?");

/***/ }),

/***/ "./lib/lib.ts":
/*!********************!*\
  !*** ./lib/lib.ts ***!
  \********************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\r\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n};\r\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\r\nexports.isDirectory = exports.findFilesInFolder = exports.extractToDirectory = exports.checkArgs = void 0;\r\nconst process_1 = __webpack_require__(/*! process */ \"process\");\r\nconst fs_1 = __webpack_require__(/*! fs */ \"fs\");\r\nconst path_1 = __webpack_require__(/*! path */ \"path\");\r\nconst crypto_1 = __webpack_require__(/*! crypto */ \"crypto\");\r\nconst decompress = __webpack_require__(/*! decompress */ \"./node_modules/.pnpm/decompress@4.2.1/node_modules/decompress/index.js\");\r\nconst file_type_1 = __webpack_require__(/*! file-type */ \"./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/index.js\");\r\n/**\r\n * Check if path passed as argument is set\r\n * @returns Promise<string> Path\r\n */\r\nconst checkArgs = () => {\r\n    return new Promise((resolve, reject) => {\r\n        const target = process_1.argv[2];\r\n        if (!target)\r\n            reject('Please specify which XD file you want to extract.');\r\n        const file = (0, path_1.join)((0, process_1.cwd)(), target);\r\n        if ((0, path_1.extname)(file) !== '.xd')\r\n            reject('Please specify a valid XD file.');\r\n        resolve(target);\r\n    });\r\n};\r\nexports.checkArgs = checkArgs;\r\nconst extractToDirectory = (target) => {\r\n    return new Promise((resolve, reject) => {\r\n        const randomFolderName = (0, crypto_1.randomUUID)();\r\n        const destinationFolder = (0, crypto_1.randomUUID)();\r\n        (0, fs_1.mkdirSync)((0, path_1.join)((0, process_1.cwd)(), destinationFolder));\r\n        decompress(target, randomFolderName)\r\n            .then(() => {\r\n            return (0, exports.findFilesInFolder)((0, path_1.join)(randomFolderName, 'resources'));\r\n        })\r\n            .then((files) => __awaiter(void 0, void 0, void 0, function* () {\r\n            for (let file of files) {\r\n                const mime = yield (0, file_type_1.fileTypeFromFile)(file);\r\n                (0, fs_1.copyFileSync)(file, (0, path_1.join)((0, process_1.cwd)(), destinationFolder, `${(0, path_1.basename)(file)}.${mime.ext}`));\r\n            }\r\n            (0, fs_1.rmSync)((0, path_1.join)((0, process_1.cwd)(), randomFolderName), { recursive: true, force: true });\r\n            resolve(destinationFolder);\r\n        }));\r\n    });\r\n};\r\nexports.extractToDirectory = extractToDirectory;\r\nconst findFilesInFolder = (folder) => {\r\n    return new Promise((resolve) => {\r\n        const path = (0, path_1.join)((0, process_1.cwd)(), folder);\r\n        const files = (0, fs_1.readdirSync)(path)\r\n            .filter((file) => !(0, exports.isDirectory)((0, path_1.join)(path, file)))\r\n            .map((file) => (0, path_1.join)((0, process_1.cwd)(), folder, file));\r\n        resolve(files);\r\n    });\r\n};\r\nexports.findFilesInFolder = findFilesInFolder;\r\n/**\r\n * Check if a path is a directory\r\n * @param target Path to check\r\n * @returns boolean True if path is a directory\r\n */\r\nconst isDirectory = (target) => {\r\n    return (0, fs_1.statSync)(target).isDirectory();\r\n};\r\nexports.isDirectory = isDirectory;\r\n\n\n//# sourceURL=webpack://extract-xd/./lib/lib.ts?");

/***/ }),

/***/ "./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/index.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/index.js ***!
  \**************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var through = __webpack_require__(/*! through */ \"./node_modules/.pnpm/through@2.3.8/node_modules/through/index.js\");\nvar bz2 = __webpack_require__(/*! ./lib/bzip2 */ \"./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bzip2.js\");\nvar bitIterator = __webpack_require__(/*! ./lib/bit_iterator */ \"./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bit_iterator.js\");\n\nmodule.exports = unbzip2Stream;\n\nfunction unbzip2Stream() {\n    var bufferQueue = [];\n    var hasBytes = 0;\n    var blockSize = 0;\n    var broken = false;\n    var done = false;\n    var bitReader = null;\n    var streamCRC = null;\n\n    function decompressBlock(push){\n        if(!blockSize){\n            blockSize = bz2.header(bitReader);\n            //console.error(\"got header of\", blockSize);\n            streamCRC = 0;\n            return true;\n        }else{\n            var bufsize = 100000 * blockSize;\n            var buf = new Int32Array(bufsize);\n            \n            var chunk = [];\n            var f = function(b) {\n                chunk.push(b);\n            };\n\n            streamCRC = bz2.decompress(bitReader, f, buf, bufsize, streamCRC);\n            if (streamCRC === null) {\n                // reset for next bzip2 header\n                blockSize = 0;\n                return false;\n            }else{\n                //console.error('decompressed', chunk.length,'bytes');\n                push(Buffer.from(chunk));\n                return true;\n            }\n        }\n    }\n\n    var outlength = 0;\n    function decompressAndQueue(stream) {\n        if (broken) return;\n        try {\n            return decompressBlock(function(d) {\n                stream.queue(d);\n                if (d !== null) {\n                    //console.error('write at', outlength.toString(16));\n                    outlength += d.length;\n                } else {\n                    //console.error('written EOS');\n                }\n            });\n        } catch(e) {\n            //console.error(e);\n            stream.emit('error', e);\n            broken = true;\n            return false;\n        }\n    }\n\n    return through(\n        function write(data) {\n            //console.error('received', data.length,'bytes in', typeof data);\n            bufferQueue.push(data);\n            hasBytes += data.length;\n            if (bitReader === null) {\n                bitReader = bitIterator(function() {\n                    return bufferQueue.shift();\n                });\n            }\n            while (!broken && hasBytes - bitReader.bytesRead + 1 >= ((25000 + 100000 * blockSize) || 4)){\n                //console.error('decompressing with', hasBytes - bitReader.bytesRead + 1, 'bytes in buffer');\n                decompressAndQueue(this);\n            }\n        },\n        function end(x) {\n            //console.error(x,'last compressing with', hasBytes, 'bytes in buffer');\n            while (!broken && bitReader && hasBytes > bitReader.bytesRead){\n                decompressAndQueue(this);\n            }\n            if (!broken) {\n                if (streamCRC !== null)\n                    this.emit('error', new Error(\"input stream ended prematurely\"));\n                this.queue(null);\n            }\n        }\n    );\n}\n\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bit_iterator.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bit_iterator.js ***!
  \*************************************************************************************************/
/***/ ((module) => {

eval("var BITMASK = [0, 0x01, 0x03, 0x07, 0x0F, 0x1F, 0x3F, 0x7F, 0xFF];\n\n// returns a function that reads bits.\n// takes a buffer iterator as input\nmodule.exports = function bitIterator(nextBuffer) {\n    var bit = 0, byte = 0;\n    var bytes = nextBuffer();\n    var f = function(n) {\n        if (n === null && bit != 0) {  // align to byte boundary\n            bit = 0\n            byte++;\n            return;\n        }\n        var result = 0;\n        while(n > 0) {\n            if (byte >= bytes.length) {\n                byte = 0;\n                bytes = nextBuffer();\n            }\n            var left = 8 - bit;\n            if (bit === 0 && n > 0)\n                f.bytesRead++;\n            if (n >= left) {\n                result <<= left;\n                result |= (BITMASK[left] & bytes[byte++]);\n                bit = 0;\n                n -= left;\n            } else {\n                result <<= n;\n                result |= ((bytes[byte] & (BITMASK[n] << (8 - n - bit))) >> (8 - n - bit));\n                bit += n;\n                n = 0;\n            }\n        }\n        return result;\n    };\n    f.bytesRead = 0;\n    return f;\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bit_iterator.js?");

/***/ }),

/***/ "./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bzip2.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bzip2.js ***!
  \******************************************************************************************/
/***/ ((module) => {

eval("/* \n  bzip2.js - a small bzip2 decompression implementation\n  \n  Copyright 2011 by antimatter15 (antimatter15@gmail.com)\n  \n  Based on micro-bunzip by Rob Landley (rob@landley.net).\n\n  Copyright (c) 2011 by antimatter15 (antimatter15@gmail.com).\n\n  Permission is hereby granted, free of charge, to any person obtaining a\n  copy of this software and associated documentation files (the \"Software\"),\n  to deal in the Software without restriction, including without limitation\n  the rights to use, copy, modify, merge, publish, distribute, sublicense,\n  and/or sell copies of the Software, and to permit persons to whom the\n  Software is furnished to do so, subject to the following conditions:\n  \n  The above copyright notice and this permission notice shall be included\n  in all copies or substantial portions of the Software.\n  \n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n  DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n  TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH\n  THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n*/\nfunction Bzip2Error(message) {\n    this.name = 'Bzip2Error';\n    this.message = message;\n    this.stack = (new Error()).stack;\n}\nBzip2Error.prototype = new Error;\n \nvar message = {\n    Error: function(message) {throw new Bzip2Error(message);}\n};\n\nvar bzip2 = {};\nbzip2.Bzip2Error = Bzip2Error;\n\nbzip2.crcTable =\n[\n   0x00000000, 0x04c11db7, 0x09823b6e, 0x0d4326d9,\n   0x130476dc, 0x17c56b6b, 0x1a864db2, 0x1e475005,\n   0x2608edb8, 0x22c9f00f, 0x2f8ad6d6, 0x2b4bcb61,\n   0x350c9b64, 0x31cd86d3, 0x3c8ea00a, 0x384fbdbd,\n   0x4c11db70, 0x48d0c6c7, 0x4593e01e, 0x4152fda9,\n   0x5f15adac, 0x5bd4b01b, 0x569796c2, 0x52568b75,\n   0x6a1936c8, 0x6ed82b7f, 0x639b0da6, 0x675a1011,\n   0x791d4014, 0x7ddc5da3, 0x709f7b7a, 0x745e66cd,\n   0x9823b6e0, 0x9ce2ab57, 0x91a18d8e, 0x95609039,\n   0x8b27c03c, 0x8fe6dd8b, 0x82a5fb52, 0x8664e6e5,\n   0xbe2b5b58, 0xbaea46ef, 0xb7a96036, 0xb3687d81,\n   0xad2f2d84, 0xa9ee3033, 0xa4ad16ea, 0xa06c0b5d,\n   0xd4326d90, 0xd0f37027, 0xddb056fe, 0xd9714b49,\n   0xc7361b4c, 0xc3f706fb, 0xceb42022, 0xca753d95,\n   0xf23a8028, 0xf6fb9d9f, 0xfbb8bb46, 0xff79a6f1,\n   0xe13ef6f4, 0xe5ffeb43, 0xe8bccd9a, 0xec7dd02d,\n   0x34867077, 0x30476dc0, 0x3d044b19, 0x39c556ae,\n   0x278206ab, 0x23431b1c, 0x2e003dc5, 0x2ac12072,\n   0x128e9dcf, 0x164f8078, 0x1b0ca6a1, 0x1fcdbb16,\n   0x018aeb13, 0x054bf6a4, 0x0808d07d, 0x0cc9cdca,\n   0x7897ab07, 0x7c56b6b0, 0x71159069, 0x75d48dde,\n   0x6b93dddb, 0x6f52c06c, 0x6211e6b5, 0x66d0fb02,\n   0x5e9f46bf, 0x5a5e5b08, 0x571d7dd1, 0x53dc6066,\n   0x4d9b3063, 0x495a2dd4, 0x44190b0d, 0x40d816ba,\n   0xaca5c697, 0xa864db20, 0xa527fdf9, 0xa1e6e04e,\n   0xbfa1b04b, 0xbb60adfc, 0xb6238b25, 0xb2e29692,\n   0x8aad2b2f, 0x8e6c3698, 0x832f1041, 0x87ee0df6,\n   0x99a95df3, 0x9d684044, 0x902b669d, 0x94ea7b2a,\n   0xe0b41de7, 0xe4750050, 0xe9362689, 0xedf73b3e,\n   0xf3b06b3b, 0xf771768c, 0xfa325055, 0xfef34de2,\n   0xc6bcf05f, 0xc27dede8, 0xcf3ecb31, 0xcbffd686,\n   0xd5b88683, 0xd1799b34, 0xdc3abded, 0xd8fba05a,\n   0x690ce0ee, 0x6dcdfd59, 0x608edb80, 0x644fc637,\n   0x7a089632, 0x7ec98b85, 0x738aad5c, 0x774bb0eb,\n   0x4f040d56, 0x4bc510e1, 0x46863638, 0x42472b8f,\n   0x5c007b8a, 0x58c1663d, 0x558240e4, 0x51435d53,\n   0x251d3b9e, 0x21dc2629, 0x2c9f00f0, 0x285e1d47,\n   0x36194d42, 0x32d850f5, 0x3f9b762c, 0x3b5a6b9b,\n   0x0315d626, 0x07d4cb91, 0x0a97ed48, 0x0e56f0ff,\n   0x1011a0fa, 0x14d0bd4d, 0x19939b94, 0x1d528623,\n   0xf12f560e, 0xf5ee4bb9, 0xf8ad6d60, 0xfc6c70d7,\n   0xe22b20d2, 0xe6ea3d65, 0xeba91bbc, 0xef68060b,\n   0xd727bbb6, 0xd3e6a601, 0xdea580d8, 0xda649d6f,\n   0xc423cd6a, 0xc0e2d0dd, 0xcda1f604, 0xc960ebb3,\n   0xbd3e8d7e, 0xb9ff90c9, 0xb4bcb610, 0xb07daba7,\n   0xae3afba2, 0xaafbe615, 0xa7b8c0cc, 0xa379dd7b,\n   0x9b3660c6, 0x9ff77d71, 0x92b45ba8, 0x9675461f,\n   0x8832161a, 0x8cf30bad, 0x81b02d74, 0x857130c3,\n   0x5d8a9099, 0x594b8d2e, 0x5408abf7, 0x50c9b640,\n   0x4e8ee645, 0x4a4ffbf2, 0x470cdd2b, 0x43cdc09c,\n   0x7b827d21, 0x7f436096, 0x7200464f, 0x76c15bf8,\n   0x68860bfd, 0x6c47164a, 0x61043093, 0x65c52d24,\n   0x119b4be9, 0x155a565e, 0x18197087, 0x1cd86d30,\n   0x029f3d35, 0x065e2082, 0x0b1d065b, 0x0fdc1bec,\n   0x3793a651, 0x3352bbe6, 0x3e119d3f, 0x3ad08088,\n   0x2497d08d, 0x2056cd3a, 0x2d15ebe3, 0x29d4f654,\n   0xc5a92679, 0xc1683bce, 0xcc2b1d17, 0xc8ea00a0,\n   0xd6ad50a5, 0xd26c4d12, 0xdf2f6bcb, 0xdbee767c,\n   0xe3a1cbc1, 0xe760d676, 0xea23f0af, 0xeee2ed18,\n   0xf0a5bd1d, 0xf464a0aa, 0xf9278673, 0xfde69bc4,\n   0x89b8fd09, 0x8d79e0be, 0x803ac667, 0x84fbdbd0,\n   0x9abc8bd5, 0x9e7d9662, 0x933eb0bb, 0x97ffad0c,\n   0xafb010b1, 0xab710d06, 0xa6322bdf, 0xa2f33668,\n   0xbcb4666d, 0xb8757bda, 0xb5365d03, 0xb1f740b4\n];\n\nbzip2.array = function(bytes) {\n    var bit = 0, byte = 0;\n    var BITMASK = [0, 0x01, 0x03, 0x07, 0x0F, 0x1F, 0x3F, 0x7F, 0xFF ];\n    return function(n) {\n        var result = 0;\n        while(n > 0) {\n            var left = 8 - bit;\n            if (n >= left) {\n                result <<= left;\n                result |= (BITMASK[left] & bytes[byte++]);\n                bit = 0;\n                n -= left;\n            } else {\n                result <<= n;\n                result |= ((bytes[byte] & (BITMASK[n] << (8 - n - bit))) >> (8 - n - bit));\n                bit += n;\n                n = 0;\n            }\n        }\n        return result;\n    }\n}\n\n    \nbzip2.simple = function(srcbuffer, stream) {\n    var bits = bzip2.array(srcbuffer);\n    var size = bzip2.header(bits);\n    var ret = false;\n    var bufsize = 100000 * size;\n    var buf = new Int32Array(bufsize);\n    \n    do {\n        ret = bzip2.decompress(bits, stream, buf, bufsize);        \n    } while(!ret);\n}\n\nbzip2.header = function(bits) {\n    this.byteCount = new Int32Array(256);\n    this.symToByte = new Uint8Array(256);\n    this.mtfSymbol = new Int32Array(256);\n    this.selectors = new Uint8Array(0x8000);\n\n    if (bits(8*3) != 4348520) message.Error(\"No magic number found\");\n\n    var i = bits(8) - 48;\n    if (i < 1 || i > 9) message.Error(\"Not a BZIP archive\");\n    return i;\n};\n\n\n//takes a function for reading the block data (starting with 0x314159265359)\n//a block size (0-9) (optional, defaults to 9)\n//a length at which to stop decompressing and return the output\nbzip2.decompress = function(bits, stream, buf, bufsize, streamCRC) {\n    var MAX_HUFCODE_BITS = 20;\n    var MAX_SYMBOLS = 258;\n    var SYMBOL_RUNA = 0;\n    var SYMBOL_RUNB = 1;\n    var GROUP_SIZE = 50;\n    var crc = 0 ^ (-1);\n    \n    for(var h = '', i = 0; i < 6; i++) h += bits(8).toString(16);\n    if (h == \"177245385090\") {\n      var finalCRC = bits(32)|0;\n      if (finalCRC !== streamCRC) message.Error(\"Error in bzip2: crc32 do not match\");\n      // align stream to byte\n      bits(null);\n      return null; // reset streamCRC for next call\n    }\n    if (h != \"314159265359\") message.Error(\"eek not valid bzip data\");\n    var crcblock = bits(32)|0; // CRC code\n    if (bits(1)) message.Error(\"unsupported obsolete version\");\n    var origPtr = bits(24);\n    if (origPtr > bufsize) message.Error(\"Initial position larger than buffer size\");\n    var t = bits(16);\n    var symTotal = 0;\n    for (i = 0; i < 16; i++) {\n        if (t & (1 << (15 - i))) {\n            var k = bits(16);\n            for(j = 0; j < 16; j++) {\n                if (k & (1 << (15 - j))) {\n                    this.symToByte[symTotal++] = (16 * i) + j;\n                }\n            }\n        }\n    }\n\n    var groupCount = bits(3);\n    if (groupCount < 2 || groupCount > 6) message.Error(\"another error\");\n    var nSelectors = bits(15);\n    if (nSelectors == 0) message.Error(\"meh\");\n    for(var i = 0; i < groupCount; i++) this.mtfSymbol[i] = i;\n\n    for(var i = 0; i < nSelectors; i++) {\n        for(var j = 0; bits(1); j++) if (j >= groupCount) message.Error(\"whoops another error\");\n        var uc = this.mtfSymbol[j];\n        for(var k = j-1; k>=0; k--) {\n            this.mtfSymbol[k+1] = this.mtfSymbol[k];\n        }\n        this.mtfSymbol[0] = uc;\n        this.selectors[i] = uc;\n    }\n\n    var symCount = symTotal + 2;\n    var groups = [];\n    var length = new Uint8Array(MAX_SYMBOLS),\n    temp = new Uint16Array(MAX_HUFCODE_BITS+1);\n\n    var hufGroup;\n\n    for(var j = 0; j < groupCount; j++) {\n        t = bits(5); //lengths\n        for(var i = 0; i < symCount; i++) {\n            while(true){\n                if (t < 1 || t > MAX_HUFCODE_BITS) message.Error(\"I gave up a while ago on writing error messages\");\n                if (!bits(1)) break;\n                if (!bits(1)) t++;\n                else t--;\n            }\n            length[i] = t;\n        }\n        var  minLen,  maxLen;\n        minLen = maxLen = length[0];\n        for(var i = 1; i < symCount; i++) {\n            if (length[i] > maxLen) maxLen = length[i];\n            else if (length[i] < minLen) minLen = length[i];\n        }\n        hufGroup = groups[j] = {};\n        hufGroup.permute = new Int32Array(MAX_SYMBOLS);\n        hufGroup.limit = new Int32Array(MAX_HUFCODE_BITS + 1);\n        hufGroup.base = new Int32Array(MAX_HUFCODE_BITS + 1);\n\n        hufGroup.minLen = minLen;\n        hufGroup.maxLen = maxLen;\n        var base = hufGroup.base;\n        var limit = hufGroup.limit;\n        var pp = 0;\n        for(var i = minLen; i <= maxLen; i++)\n        for(var t = 0; t < symCount; t++)\n        if (length[t] == i) hufGroup.permute[pp++] = t;\n        for(i = minLen; i <= maxLen; i++) temp[i] = limit[i] = 0;\n        for(i = 0; i < symCount; i++) temp[length[i]]++;\n        pp = t = 0;\n        for(i = minLen; i < maxLen; i++) {\n            pp += temp[i];\n            limit[i] = pp - 1;\n            pp <<= 1;\n            base[i+1] = pp - (t += temp[i]);\n        }\n        limit[maxLen] = pp + temp[maxLen] - 1;\n        base[minLen] = 0;\n    }\n\n    for(var i = 0; i < 256; i++) { \n        this.mtfSymbol[i] = i;\n        this.byteCount[i] = 0;\n    }\n    var runPos, count, symCount, selector;\n    runPos = count = symCount = selector = 0;    \n    while(true) {\n        if (!(symCount--)) {\n            symCount = GROUP_SIZE - 1;\n            if (selector >= nSelectors) message.Error(\"meow i'm a kitty, that's an error\");\n            hufGroup = groups[this.selectors[selector++]];\n            base = hufGroup.base;\n            limit = hufGroup.limit;\n        }\n        i = hufGroup.minLen;\n        j = bits(i);\n        while(true) {\n            if (i > hufGroup.maxLen) message.Error(\"rawr i'm a dinosaur\");\n            if (j <= limit[i]) break;\n            i++;\n            j = (j << 1) | bits(1);\n        }\n        j -= base[i];\n        if (j < 0 || j >= MAX_SYMBOLS) message.Error(\"moo i'm a cow\");\n        var nextSym = hufGroup.permute[j];\n        if (nextSym == SYMBOL_RUNA || nextSym == SYMBOL_RUNB) {\n            if (!runPos){\n                runPos = 1;\n                t = 0;\n            }\n            if (nextSym == SYMBOL_RUNA) t += runPos;\n            else t += 2 * runPos;\n            runPos <<= 1;\n            continue;\n        }\n        if (runPos) {\n            runPos = 0;\n            if (count + t > bufsize) message.Error(\"Boom.\");\n            uc = this.symToByte[this.mtfSymbol[0]];\n            this.byteCount[uc] += t;\n            while(t--) buf[count++] = uc;\n        }\n        if (nextSym > symTotal) break;\n        if (count >= bufsize) message.Error(\"I can't think of anything. Error\");\n        i = nextSym - 1;\n        uc = this.mtfSymbol[i];\n        for(var k = i-1; k>=0; k--) {\n            this.mtfSymbol[k+1] = this.mtfSymbol[k];\n        }\n        this.mtfSymbol[0] = uc\n        uc = this.symToByte[uc];\n        this.byteCount[uc]++;\n        buf[count++] = uc;\n    }\n    if (origPtr < 0 || origPtr >= count) message.Error(\"I'm a monkey and I'm throwing something at someone, namely you\");\n    var j = 0;\n    for(var i = 0; i < 256; i++) {\n        k = j + this.byteCount[i];\n        this.byteCount[i] = j;\n        j = k;\n    }\n    for(var i = 0; i < count; i++) {\n        uc = buf[i] & 0xff;\n        buf[this.byteCount[uc]] |= (i << 8);\n        this.byteCount[uc]++;\n    }\n    var pos = 0, current = 0, run = 0;\n    if (count) {\n        pos = buf[origPtr];\n        current = (pos & 0xff);\n        pos >>= 8;\n        run = -1;\n    }\n    count = count;\n    var copies, previous, outbyte;\n    while(count) {\n        count--;\n        previous = current;\n        pos = buf[pos];\n        current = pos & 0xff;\n        pos >>= 8;\n        if (run++ == 3) {\n            copies = current;\n            outbyte = previous;\n            current = -1;\n        } else {\n            copies = 1;\n            outbyte = current;\n        }\n        while(copies--) {\n            crc = ((crc << 8) ^ this.crcTable[((crc>>24) ^ outbyte) & 0xFF])&0xFFFFFFFF; // crc32\n            stream(outbyte);\n        }\n        if (current != previous) run = 0;\n    }\n\n    crc = (crc ^ (-1)) >>> 0;\n    if ((crc|0) != (crcblock|0)) message.Error(\"Error in bzip2: crc32 do not match\");\n    streamCRC = (crc ^ ((streamCRC << 1) | (streamCRC >>> 31))) & 0xFFFFFFFF;\n    return streamCRC;\n}\n\nmodule.exports = bzip2;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/unbzip2-stream@1.4.3/node_modules/unbzip2-stream/lib/bzip2.js?");

/***/ }),

/***/ "./node_modules/.pnpm/util-deprecate@1.0.2/node_modules/util-deprecate/node.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/.pnpm/util-deprecate@1.0.2/node_modules/util-deprecate/node.js ***!
  \*************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = __webpack_require__(/*! util */ \"util\").deprecate;\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/util-deprecate@1.0.2/node_modules/util-deprecate/node.js?");

/***/ }),

/***/ "./node_modules/.pnpm/wrappy@1.0.2/node_modules/wrappy/wrappy.js":
/*!***********************************************************************!*\
  !*** ./node_modules/.pnpm/wrappy@1.0.2/node_modules/wrappy/wrappy.js ***!
  \***********************************************************************/
/***/ ((module) => {

eval("// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/wrappy@1.0.2/node_modules/wrappy/wrappy.js?");

/***/ }),

/***/ "./node_modules/.pnpm/xtend@4.0.2/node_modules/xtend/immutable.js":
/*!************************************************************************!*\
  !*** ./node_modules/.pnpm/xtend@4.0.2/node_modules/xtend/immutable.js ***!
  \************************************************************************/
/***/ ((module) => {

eval("module.exports = extend\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction extend() {\n    var target = {}\n\n    for (var i = 0; i < arguments.length; i++) {\n        var source = arguments[i]\n\n        for (var key in source) {\n            if (hasOwnProperty.call(source, key)) {\n                target[key] = source[key]\n            }\n        }\n    }\n\n    return target\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/xtend@4.0.2/node_modules/xtend/immutable.js?");

/***/ }),

/***/ "./node_modules/.pnpm/yauzl@2.10.0/node_modules/yauzl/index.js":
/*!*********************************************************************!*\
  !*** ./node_modules/.pnpm/yauzl@2.10.0/node_modules/yauzl/index.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("var fs = __webpack_require__(/*! fs */ \"fs\");\nvar zlib = __webpack_require__(/*! zlib */ \"zlib\");\nvar fd_slicer = __webpack_require__(/*! fd-slicer */ \"./node_modules/.pnpm/fd-slicer@1.1.0/node_modules/fd-slicer/index.js\");\nvar crc32 = __webpack_require__(/*! buffer-crc32 */ \"./node_modules/.pnpm/buffer-crc32@0.2.13/node_modules/buffer-crc32/index.js\");\nvar util = __webpack_require__(/*! util */ \"util\");\nvar EventEmitter = (__webpack_require__(/*! events */ \"events\").EventEmitter);\nvar Transform = (__webpack_require__(/*! stream */ \"stream\").Transform);\nvar PassThrough = (__webpack_require__(/*! stream */ \"stream\").PassThrough);\nvar Writable = (__webpack_require__(/*! stream */ \"stream\").Writable);\n\nexports.open = open;\nexports.fromFd = fromFd;\nexports.fromBuffer = fromBuffer;\nexports.fromRandomAccessReader = fromRandomAccessReader;\nexports.dosDateTimeToDate = dosDateTimeToDate;\nexports.validateFileName = validateFileName;\nexports.ZipFile = ZipFile;\nexports.Entry = Entry;\nexports.RandomAccessReader = RandomAccessReader;\n\nfunction open(path, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  fs.open(path, \"r\", function(err, fd) {\n    if (err) return callback(err);\n    fromFd(fd, options, function(err, zipfile) {\n      if (err) fs.close(fd, defaultCallback);\n      callback(err, zipfile);\n    });\n  });\n}\n\nfunction fromFd(fd, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  fs.fstat(fd, function(err, stats) {\n    if (err) return callback(err);\n    var reader = fd_slicer.createFromFd(fd, {autoClose: true});\n    fromRandomAccessReader(reader, stats.size, options, callback);\n  });\n}\n\nfunction fromBuffer(buffer, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  // limit the max chunk size. see https://github.com/thejoshwolfe/yauzl/issues/87\n  var reader = fd_slicer.createFromBuffer(buffer, {maxChunkSize: 0x10000});\n  fromRandomAccessReader(reader, buffer.length, options, callback);\n}\n\nfunction fromRandomAccessReader(reader, totalSize, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  var decodeStrings = !!options.decodeStrings;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  if (typeof totalSize !== \"number\") throw new Error(\"expected totalSize parameter to be a number\");\n  if (totalSize > Number.MAX_SAFE_INTEGER) {\n    throw new Error(\"zip file too large. only file sizes up to 2^52 are supported due to JavaScript's Number type being an IEEE 754 double.\");\n  }\n\n  // the matching unref() call is in zipfile.close()\n  reader.ref();\n\n  // eocdr means End of Central Directory Record.\n  // search backwards for the eocdr signature.\n  // the last field of the eocdr is a variable-length comment.\n  // the comment size is encoded in a 2-byte field in the eocdr, which we can't find without trudging backwards through the comment to find it.\n  // as a consequence of this design decision, it's possible to have ambiguous zip file metadata if a coherent eocdr was in the comment.\n  // we search backwards for a eocdr signature, and hope that whoever made the zip file was smart enough to forbid the eocdr signature in the comment.\n  var eocdrWithoutCommentSize = 22;\n  var maxCommentSize = 0xffff; // 2-byte size\n  var bufferSize = Math.min(eocdrWithoutCommentSize + maxCommentSize, totalSize);\n  var buffer = newBuffer(bufferSize);\n  var bufferReadStart = totalSize - buffer.length;\n  readAndAssertNoEof(reader, buffer, 0, bufferSize, bufferReadStart, function(err) {\n    if (err) return callback(err);\n    for (var i = bufferSize - eocdrWithoutCommentSize; i >= 0; i -= 1) {\n      if (buffer.readUInt32LE(i) !== 0x06054b50) continue;\n      // found eocdr\n      var eocdrBuffer = buffer.slice(i);\n\n      // 0 - End of central directory signature = 0x06054b50\n      // 4 - Number of this disk\n      var diskNumber = eocdrBuffer.readUInt16LE(4);\n      if (diskNumber !== 0) {\n        return callback(new Error(\"multi-disk zip files are not supported: found disk number: \" + diskNumber));\n      }\n      // 6 - Disk where central directory starts\n      // 8 - Number of central directory records on this disk\n      // 10 - Total number of central directory records\n      var entryCount = eocdrBuffer.readUInt16LE(10);\n      // 12 - Size of central directory (bytes)\n      // 16 - Offset of start of central directory, relative to start of archive\n      var centralDirectoryOffset = eocdrBuffer.readUInt32LE(16);\n      // 20 - Comment length\n      var commentLength = eocdrBuffer.readUInt16LE(20);\n      var expectedCommentLength = eocdrBuffer.length - eocdrWithoutCommentSize;\n      if (commentLength !== expectedCommentLength) {\n        return callback(new Error(\"invalid comment length. expected: \" + expectedCommentLength + \". found: \" + commentLength));\n      }\n      // 22 - Comment\n      // the encoding is always cp437.\n      var comment = decodeStrings ? decodeBuffer(eocdrBuffer, 22, eocdrBuffer.length, false)\n                                  : eocdrBuffer.slice(22);\n\n      if (!(entryCount === 0xffff || centralDirectoryOffset === 0xffffffff)) {\n        return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n      }\n\n      // ZIP64 format\n\n      // ZIP64 Zip64 end of central directory locator\n      var zip64EocdlBuffer = newBuffer(20);\n      var zip64EocdlOffset = bufferReadStart + i - zip64EocdlBuffer.length;\n      readAndAssertNoEof(reader, zip64EocdlBuffer, 0, zip64EocdlBuffer.length, zip64EocdlOffset, function(err) {\n        if (err) return callback(err);\n\n        // 0 - zip64 end of central dir locator signature = 0x07064b50\n        if (zip64EocdlBuffer.readUInt32LE(0) !== 0x07064b50) {\n          return callback(new Error(\"invalid zip64 end of central directory locator signature\"));\n        }\n        // 4 - number of the disk with the start of the zip64 end of central directory\n        // 8 - relative offset of the zip64 end of central directory record\n        var zip64EocdrOffset = readUInt64LE(zip64EocdlBuffer, 8);\n        // 16 - total number of disks\n\n        // ZIP64 end of central directory record\n        var zip64EocdrBuffer = newBuffer(56);\n        readAndAssertNoEof(reader, zip64EocdrBuffer, 0, zip64EocdrBuffer.length, zip64EocdrOffset, function(err) {\n          if (err) return callback(err);\n\n          // 0 - zip64 end of central dir signature                           4 bytes  (0x06064b50)\n          if (zip64EocdrBuffer.readUInt32LE(0) !== 0x06064b50) {\n            return callback(new Error(\"invalid zip64 end of central directory record signature\"));\n          }\n          // 4 - size of zip64 end of central directory record                8 bytes\n          // 12 - version made by                                             2 bytes\n          // 14 - version needed to extract                                   2 bytes\n          // 16 - number of this disk                                         4 bytes\n          // 20 - number of the disk with the start of the central directory  4 bytes\n          // 24 - total number of entries in the central directory on this disk         8 bytes\n          // 32 - total number of entries in the central directory            8 bytes\n          entryCount = readUInt64LE(zip64EocdrBuffer, 32);\n          // 40 - size of the central directory                               8 bytes\n          // 48 - offset of start of central directory with respect to the starting disk number     8 bytes\n          centralDirectoryOffset = readUInt64LE(zip64EocdrBuffer, 48);\n          // 56 - zip64 extensible data sector                                (variable size)\n          return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n        });\n      });\n      return;\n    }\n    callback(new Error(\"end of central directory record signature not found\"));\n  });\n}\n\nutil.inherits(ZipFile, EventEmitter);\nfunction ZipFile(reader, centralDirectoryOffset, fileSize, entryCount, comment, autoClose, lazyEntries, decodeStrings, validateEntrySizes, strictFileNames) {\n  var self = this;\n  EventEmitter.call(self);\n  self.reader = reader;\n  // forward close events\n  self.reader.on(\"error\", function(err) {\n    // error closing the fd\n    emitError(self, err);\n  });\n  self.reader.once(\"close\", function() {\n    self.emit(\"close\");\n  });\n  self.readEntryCursor = centralDirectoryOffset;\n  self.fileSize = fileSize;\n  self.entryCount = entryCount;\n  self.comment = comment;\n  self.entriesRead = 0;\n  self.autoClose = !!autoClose;\n  self.lazyEntries = !!lazyEntries;\n  self.decodeStrings = !!decodeStrings;\n  self.validateEntrySizes = !!validateEntrySizes;\n  self.strictFileNames = !!strictFileNames;\n  self.isOpen = true;\n  self.emittedError = false;\n\n  if (!self.lazyEntries) self._readEntry();\n}\nZipFile.prototype.close = function() {\n  if (!this.isOpen) return;\n  this.isOpen = false;\n  this.reader.unref();\n};\n\nfunction emitErrorAndAutoClose(self, err) {\n  if (self.autoClose) self.close();\n  emitError(self, err);\n}\nfunction emitError(self, err) {\n  if (self.emittedError) return;\n  self.emittedError = true;\n  self.emit(\"error\", err);\n}\n\nZipFile.prototype.readEntry = function() {\n  if (!this.lazyEntries) throw new Error(\"readEntry() called without lazyEntries:true\");\n  this._readEntry();\n};\nZipFile.prototype._readEntry = function() {\n  var self = this;\n  if (self.entryCount === self.entriesRead) {\n    // done with metadata\n    setImmediate(function() {\n      if (self.autoClose) self.close();\n      if (self.emittedError) return;\n      self.emit(\"end\");\n    });\n    return;\n  }\n  if (self.emittedError) return;\n  var buffer = newBuffer(46);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function(err) {\n    if (err) return emitErrorAndAutoClose(self, err);\n    if (self.emittedError) return;\n    var entry = new Entry();\n    // 0 - Central directory file header signature\n    var signature = buffer.readUInt32LE(0);\n    if (signature !== 0x02014b50) return emitErrorAndAutoClose(self, new Error(\"invalid central directory file header signature: 0x\" + signature.toString(16)));\n    // 4 - Version made by\n    entry.versionMadeBy = buffer.readUInt16LE(4);\n    // 6 - Version needed to extract (minimum)\n    entry.versionNeededToExtract = buffer.readUInt16LE(6);\n    // 8 - General purpose bit flag\n    entry.generalPurposeBitFlag = buffer.readUInt16LE(8);\n    // 10 - Compression method\n    entry.compressionMethod = buffer.readUInt16LE(10);\n    // 12 - File last modification time\n    entry.lastModFileTime = buffer.readUInt16LE(12);\n    // 14 - File last modification date\n    entry.lastModFileDate = buffer.readUInt16LE(14);\n    // 16 - CRC-32\n    entry.crc32 = buffer.readUInt32LE(16);\n    // 20 - Compressed size\n    entry.compressedSize = buffer.readUInt32LE(20);\n    // 24 - Uncompressed size\n    entry.uncompressedSize = buffer.readUInt32LE(24);\n    // 28 - File name length (n)\n    entry.fileNameLength = buffer.readUInt16LE(28);\n    // 30 - Extra field length (m)\n    entry.extraFieldLength = buffer.readUInt16LE(30);\n    // 32 - File comment length (k)\n    entry.fileCommentLength = buffer.readUInt16LE(32);\n    // 34 - Disk number where file starts\n    // 36 - Internal file attributes\n    entry.internalFileAttributes = buffer.readUInt16LE(36);\n    // 38 - External file attributes\n    entry.externalFileAttributes = buffer.readUInt32LE(38);\n    // 42 - Relative offset of local file header\n    entry.relativeOffsetOfLocalHeader = buffer.readUInt32LE(42);\n\n    if (entry.generalPurposeBitFlag & 0x40) return emitErrorAndAutoClose(self, new Error(\"strong encryption is not supported\"));\n\n    self.readEntryCursor += 46;\n\n    buffer = newBuffer(entry.fileNameLength + entry.extraFieldLength + entry.fileCommentLength);\n    readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function(err) {\n      if (err) return emitErrorAndAutoClose(self, err);\n      if (self.emittedError) return;\n      // 46 - File name\n      var isUtf8 = (entry.generalPurposeBitFlag & 0x800) !== 0;\n      entry.fileName = self.decodeStrings ? decodeBuffer(buffer, 0, entry.fileNameLength, isUtf8)\n                                          : buffer.slice(0, entry.fileNameLength);\n\n      // 46+n - Extra field\n      var fileCommentStart = entry.fileNameLength + entry.extraFieldLength;\n      var extraFieldBuffer = buffer.slice(entry.fileNameLength, fileCommentStart);\n      entry.extraFields = [];\n      var i = 0;\n      while (i < extraFieldBuffer.length - 3) {\n        var headerId = extraFieldBuffer.readUInt16LE(i + 0);\n        var dataSize = extraFieldBuffer.readUInt16LE(i + 2);\n        var dataStart = i + 4;\n        var dataEnd = dataStart + dataSize;\n        if (dataEnd > extraFieldBuffer.length) return emitErrorAndAutoClose(self, new Error(\"extra field length exceeds extra field buffer size\"));\n        var dataBuffer = newBuffer(dataSize);\n        extraFieldBuffer.copy(dataBuffer, 0, dataStart, dataEnd);\n        entry.extraFields.push({\n          id: headerId,\n          data: dataBuffer,\n        });\n        i = dataEnd;\n      }\n\n      // 46+n+m - File comment\n      entry.fileComment = self.decodeStrings ? decodeBuffer(buffer, fileCommentStart, fileCommentStart + entry.fileCommentLength, isUtf8)\n                                             : buffer.slice(fileCommentStart, fileCommentStart + entry.fileCommentLength);\n      // compatibility hack for https://github.com/thejoshwolfe/yauzl/issues/47\n      entry.comment = entry.fileComment;\n\n      self.readEntryCursor += buffer.length;\n      self.entriesRead += 1;\n\n      if (entry.uncompressedSize            === 0xffffffff ||\n          entry.compressedSize              === 0xffffffff ||\n          entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n        // ZIP64 format\n        // find the Zip64 Extended Information Extra Field\n        var zip64EiefBuffer = null;\n        for (var i = 0; i < entry.extraFields.length; i++) {\n          var extraField = entry.extraFields[i];\n          if (extraField.id === 0x0001) {\n            zip64EiefBuffer = extraField.data;\n            break;\n          }\n        }\n        if (zip64EiefBuffer == null) {\n          return emitErrorAndAutoClose(self, new Error(\"expected zip64 extended information extra field\"));\n        }\n        var index = 0;\n        // 0 - Original Size          8 bytes\n        if (entry.uncompressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include uncompressed size\"));\n          }\n          entry.uncompressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 8 - Compressed Size        8 bytes\n        if (entry.compressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include compressed size\"));\n          }\n          entry.compressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 16 - Relative Header Offset 8 bytes\n        if (entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include relative header offset\"));\n          }\n          entry.relativeOffsetOfLocalHeader = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 24 - Disk Start Number      4 bytes\n      }\n\n      // check for Info-ZIP Unicode Path Extra Field (0x7075)\n      // see https://github.com/thejoshwolfe/yauzl/issues/33\n      if (self.decodeStrings) {\n        for (var i = 0; i < entry.extraFields.length; i++) {\n          var extraField = entry.extraFields[i];\n          if (extraField.id === 0x7075) {\n            if (extraField.data.length < 6) {\n              // too short to be meaningful\n              continue;\n            }\n            // Version       1 byte      version of this extra field, currently 1\n            if (extraField.data.readUInt8(0) !== 1) {\n              // > Changes may not be backward compatible so this extra\n              // > field should not be used if the version is not recognized.\n              continue;\n            }\n            // NameCRC32     4 bytes     File Name Field CRC32 Checksum\n            var oldNameCrc32 = extraField.data.readUInt32LE(1);\n            if (crc32.unsigned(buffer.slice(0, entry.fileNameLength)) !== oldNameCrc32) {\n              // > If the CRC check fails, this UTF-8 Path Extra Field should be\n              // > ignored and the File Name field in the header should be used instead.\n              continue;\n            }\n            // UnicodeName   Variable    UTF-8 version of the entry File Name\n            entry.fileName = decodeBuffer(extraField.data, 5, extraField.data.length, true);\n            break;\n          }\n        }\n      }\n\n      // validate file size\n      if (self.validateEntrySizes && entry.compressionMethod === 0) {\n        var expectedCompressedSize = entry.uncompressedSize;\n        if (entry.isEncrypted()) {\n          // traditional encryption prefixes the file data with a header\n          expectedCompressedSize += 12;\n        }\n        if (entry.compressedSize !== expectedCompressedSize) {\n          var msg = \"compressed/uncompressed size mismatch for stored file: \" + entry.compressedSize + \" != \" + entry.uncompressedSize;\n          return emitErrorAndAutoClose(self, new Error(msg));\n        }\n      }\n\n      if (self.decodeStrings) {\n        if (!self.strictFileNames) {\n          // allow backslash\n          entry.fileName = entry.fileName.replace(/\\\\/g, \"/\");\n        }\n        var errorMessage = validateFileName(entry.fileName, self.validateFileNameOptions);\n        if (errorMessage != null) return emitErrorAndAutoClose(self, new Error(errorMessage));\n      }\n      self.emit(\"entry\", entry);\n\n      if (!self.lazyEntries) self._readEntry();\n    });\n  });\n};\n\nZipFile.prototype.openReadStream = function(entry, options, callback) {\n  var self = this;\n  // parameter validation\n  var relativeStart = 0;\n  var relativeEnd = entry.compressedSize;\n  if (callback == null) {\n    callback = options;\n    options = {};\n  } else {\n    // validate options that the caller has no excuse to get wrong\n    if (options.decrypt != null) {\n      if (!entry.isEncrypted()) {\n        throw new Error(\"options.decrypt can only be specified for encrypted entries\");\n      }\n      if (options.decrypt !== false) throw new Error(\"invalid options.decrypt value: \" + options.decrypt);\n      if (entry.isCompressed()) {\n        if (options.decompress !== false) throw new Error(\"entry is encrypted and compressed, and options.decompress !== false\");\n      }\n    }\n    if (options.decompress != null) {\n      if (!entry.isCompressed()) {\n        throw new Error(\"options.decompress can only be specified for compressed entries\");\n      }\n      if (!(options.decompress === false || options.decompress === true)) {\n        throw new Error(\"invalid options.decompress value: \" + options.decompress);\n      }\n    }\n    if (options.start != null || options.end != null) {\n      if (entry.isCompressed() && options.decompress !== false) {\n        throw new Error(\"start/end range not allowed for compressed entry without options.decompress === false\");\n      }\n      if (entry.isEncrypted() && options.decrypt !== false) {\n        throw new Error(\"start/end range not allowed for encrypted entry without options.decrypt === false\");\n      }\n    }\n    if (options.start != null) {\n      relativeStart = options.start;\n      if (relativeStart < 0) throw new Error(\"options.start < 0\");\n      if (relativeStart > entry.compressedSize) throw new Error(\"options.start > entry.compressedSize\");\n    }\n    if (options.end != null) {\n      relativeEnd = options.end;\n      if (relativeEnd < 0) throw new Error(\"options.end < 0\");\n      if (relativeEnd > entry.compressedSize) throw new Error(\"options.end > entry.compressedSize\");\n      if (relativeEnd < relativeStart) throw new Error(\"options.end < options.start\");\n    }\n  }\n  // any further errors can either be caused by the zipfile,\n  // or were introduced in a minor version of yauzl,\n  // so should be passed to the client rather than thrown.\n  if (!self.isOpen) return callback(new Error(\"closed\"));\n  if (entry.isEncrypted()) {\n    if (options.decrypt !== false) return callback(new Error(\"entry is encrypted, and options.decrypt !== false\"));\n  }\n  // make sure we don't lose the fd before we open the actual read stream\n  self.reader.ref();\n  var buffer = newBuffer(30);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, entry.relativeOffsetOfLocalHeader, function(err) {\n    try {\n      if (err) return callback(err);\n      // 0 - Local file header signature = 0x04034b50\n      var signature = buffer.readUInt32LE(0);\n      if (signature !== 0x04034b50) {\n        return callback(new Error(\"invalid local file header signature: 0x\" + signature.toString(16)));\n      }\n      // all this should be redundant\n      // 4 - Version needed to extract (minimum)\n      // 6 - General purpose bit flag\n      // 8 - Compression method\n      // 10 - File last modification time\n      // 12 - File last modification date\n      // 14 - CRC-32\n      // 18 - Compressed size\n      // 22 - Uncompressed size\n      // 26 - File name length (n)\n      var fileNameLength = buffer.readUInt16LE(26);\n      // 28 - Extra field length (m)\n      var extraFieldLength = buffer.readUInt16LE(28);\n      // 30 - File name\n      // 30+n - Extra field\n      var localFileHeaderEnd = entry.relativeOffsetOfLocalHeader + buffer.length + fileNameLength + extraFieldLength;\n      var decompress;\n      if (entry.compressionMethod === 0) {\n        // 0 - The file is stored (no compression)\n        decompress = false;\n      } else if (entry.compressionMethod === 8) {\n        // 8 - The file is Deflated\n        decompress = options.decompress != null ? options.decompress : true;\n      } else {\n        return callback(new Error(\"unsupported compression method: \" + entry.compressionMethod));\n      }\n      var fileDataStart = localFileHeaderEnd;\n      var fileDataEnd = fileDataStart + entry.compressedSize;\n      if (entry.compressedSize !== 0) {\n        // bounds check now, because the read streams will probably not complain loud enough.\n        // since we're dealing with an unsigned offset plus an unsigned size,\n        // we only have 1 thing to check for.\n        if (fileDataEnd > self.fileSize) {\n          return callback(new Error(\"file data overflows file bounds: \" +\n              fileDataStart + \" + \" + entry.compressedSize + \" > \" + self.fileSize));\n        }\n      }\n      var readStream = self.reader.createReadStream({\n        start: fileDataStart + relativeStart,\n        end: fileDataStart + relativeEnd,\n      });\n      var endpointStream = readStream;\n      if (decompress) {\n        var destroyed = false;\n        var inflateFilter = zlib.createInflateRaw();\n        readStream.on(\"error\", function(err) {\n          // setImmediate here because errors can be emitted during the first call to pipe()\n          setImmediate(function() {\n            if (!destroyed) inflateFilter.emit(\"error\", err);\n          });\n        });\n        readStream.pipe(inflateFilter);\n\n        if (self.validateEntrySizes) {\n          endpointStream = new AssertByteCountStream(entry.uncompressedSize);\n          inflateFilter.on(\"error\", function(err) {\n            // forward zlib errors to the client-visible stream\n            setImmediate(function() {\n              if (!destroyed) endpointStream.emit(\"error\", err);\n            });\n          });\n          inflateFilter.pipe(endpointStream);\n        } else {\n          // the zlib filter is the client-visible stream\n          endpointStream = inflateFilter;\n        }\n        // this is part of yauzl's API, so implement this function on the client-visible stream\n        endpointStream.destroy = function() {\n          destroyed = true;\n          if (inflateFilter !== endpointStream) inflateFilter.unpipe(endpointStream);\n          readStream.unpipe(inflateFilter);\n          // TODO: the inflateFilter may cause a memory leak. see Issue #27.\n          readStream.destroy();\n        };\n      }\n      callback(null, endpointStream);\n    } finally {\n      self.reader.unref();\n    }\n  });\n};\n\nfunction Entry() {\n}\nEntry.prototype.getLastModDate = function() {\n  return dosDateTimeToDate(this.lastModFileDate, this.lastModFileTime);\n};\nEntry.prototype.isEncrypted = function() {\n  return (this.generalPurposeBitFlag & 0x1) !== 0;\n};\nEntry.prototype.isCompressed = function() {\n  return this.compressionMethod === 8;\n};\n\nfunction dosDateTimeToDate(date, time) {\n  var day = date & 0x1f; // 1-31\n  var month = (date >> 5 & 0xf) - 1; // 1-12, 0-11\n  var year = (date >> 9 & 0x7f) + 1980; // 0-128, 1980-2108\n\n  var millisecond = 0;\n  var second = (time & 0x1f) * 2; // 0-29, 0-58 (even numbers)\n  var minute = time >> 5 & 0x3f; // 0-59\n  var hour = time >> 11 & 0x1f; // 0-23\n\n  return new Date(year, month, day, hour, minute, second, millisecond);\n}\n\nfunction validateFileName(fileName) {\n  if (fileName.indexOf(\"\\\\\") !== -1) {\n    return \"invalid characters in fileName: \" + fileName;\n  }\n  if (/^[a-zA-Z]:/.test(fileName) || /^\\//.test(fileName)) {\n    return \"absolute path: \" + fileName;\n  }\n  if (fileName.split(\"/\").indexOf(\"..\") !== -1) {\n    return \"invalid relative path: \" + fileName;\n  }\n  // all good\n  return null;\n}\n\nfunction readAndAssertNoEof(reader, buffer, offset, length, position, callback) {\n  if (length === 0) {\n    // fs.read will throw an out-of-bounds error if you try to read 0 bytes from a 0 byte file\n    return setImmediate(function() { callback(null, newBuffer(0)); });\n  }\n  reader.read(buffer, offset, length, position, function(err, bytesRead) {\n    if (err) return callback(err);\n    if (bytesRead < length) {\n      return callback(new Error(\"unexpected EOF\"));\n    }\n    callback();\n  });\n}\n\nutil.inherits(AssertByteCountStream, Transform);\nfunction AssertByteCountStream(byteCount) {\n  Transform.call(this);\n  this.actualByteCount = 0;\n  this.expectedByteCount = byteCount;\n}\nAssertByteCountStream.prototype._transform = function(chunk, encoding, cb) {\n  this.actualByteCount += chunk.length;\n  if (this.actualByteCount > this.expectedByteCount) {\n    var msg = \"too many bytes in the stream. expected \" + this.expectedByteCount + \". got at least \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n  cb(null, chunk);\n};\nAssertByteCountStream.prototype._flush = function(cb) {\n  if (this.actualByteCount < this.expectedByteCount) {\n    var msg = \"not enough bytes in the stream. expected \" + this.expectedByteCount + \". got only \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n  cb();\n};\n\nutil.inherits(RandomAccessReader, EventEmitter);\nfunction RandomAccessReader() {\n  EventEmitter.call(this);\n  this.refCount = 0;\n}\nRandomAccessReader.prototype.ref = function() {\n  this.refCount += 1;\n};\nRandomAccessReader.prototype.unref = function() {\n  var self = this;\n  self.refCount -= 1;\n\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n\n  self.close(onCloseDone);\n\n  function onCloseDone(err) {\n    if (err) return self.emit('error', err);\n    self.emit('close');\n  }\n};\nRandomAccessReader.prototype.createReadStream = function(options) {\n  var start = options.start;\n  var end = options.end;\n  if (start === end) {\n    var emptyStream = new PassThrough();\n    setImmediate(function() {\n      emptyStream.end();\n    });\n    return emptyStream;\n  }\n  var stream = this._readStreamForRange(start, end);\n\n  var destroyed = false;\n  var refUnrefFilter = new RefUnrefFilter(this);\n  stream.on(\"error\", function(err) {\n    setImmediate(function() {\n      if (!destroyed) refUnrefFilter.emit(\"error\", err);\n    });\n  });\n  refUnrefFilter.destroy = function() {\n    stream.unpipe(refUnrefFilter);\n    refUnrefFilter.unref();\n    stream.destroy();\n  };\n\n  var byteCounter = new AssertByteCountStream(end - start);\n  refUnrefFilter.on(\"error\", function(err) {\n    setImmediate(function() {\n      if (!destroyed) byteCounter.emit(\"error\", err);\n    });\n  });\n  byteCounter.destroy = function() {\n    destroyed = true;\n    refUnrefFilter.unpipe(byteCounter);\n    refUnrefFilter.destroy();\n  };\n\n  return stream.pipe(refUnrefFilter).pipe(byteCounter);\n};\nRandomAccessReader.prototype._readStreamForRange = function(start, end) {\n  throw new Error(\"not implemented\");\n};\nRandomAccessReader.prototype.read = function(buffer, offset, length, position, callback) {\n  var readStream = this.createReadStream({start: position, end: position + length});\n  var writeStream = new Writable();\n  var written = 0;\n  writeStream._write = function(chunk, encoding, cb) {\n    chunk.copy(buffer, offset + written, 0, chunk.length);\n    written += chunk.length;\n    cb();\n  };\n  writeStream.on(\"finish\", callback);\n  readStream.on(\"error\", function(error) {\n    callback(error);\n  });\n  readStream.pipe(writeStream);\n};\nRandomAccessReader.prototype.close = function(callback) {\n  setImmediate(callback);\n};\n\nutil.inherits(RefUnrefFilter, PassThrough);\nfunction RefUnrefFilter(context) {\n  PassThrough.call(this);\n  this.context = context;\n  this.context.ref();\n  this.unreffedYet = false;\n}\nRefUnrefFilter.prototype._flush = function(cb) {\n  this.unref();\n  cb();\n};\nRefUnrefFilter.prototype.unref = function(cb) {\n  if (this.unreffedYet) return;\n  this.unreffedYet = true;\n  this.context.unref();\n};\n\nvar cp437 = '\\u0000 !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~';\nfunction decodeBuffer(buffer, start, end, isUtf8) {\n  if (isUtf8) {\n    return buffer.toString(\"utf8\", start, end);\n  } else {\n    var result = \"\";\n    for (var i = start; i < end; i++) {\n      result += cp437[buffer[i]];\n    }\n    return result;\n  }\n}\n\nfunction readUInt64LE(buffer, offset) {\n  // there is no native function for this, because we can't actually store 64-bit integers precisely.\n  // after 53 bits, JavaScript's Number type (IEEE 754 double) can't store individual integers anymore.\n  // but since 53 bits is a whole lot more than 32 bits, we do our best anyway.\n  var lower32 = buffer.readUInt32LE(offset);\n  var upper32 = buffer.readUInt32LE(offset + 4);\n  // we can't use bitshifting here, because JavaScript bitshifting only works on 32-bit integers.\n  return upper32 * 0x100000000 + lower32;\n  // as long as we're bounds checking the result of this function against the total file size,\n  // we'll catch any overflow errors, because we already made sure the total file size was within reason.\n}\n\n// Node 10 deprecated new Buffer().\nvar newBuffer;\nif (typeof Buffer.allocUnsafe === \"function\") {\n  newBuffer = function(len) {\n    return Buffer.allocUnsafe(len);\n  };\n} else {\n  newBuffer = function(len) {\n    return new Buffer(len);\n  };\n}\n\nfunction defaultCallback(err) {\n  if (err) throw err;\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/yauzl@2.10.0/node_modules/yauzl/index.js?");

/***/ }),

/***/ "assert":
/*!*************************!*\
  !*** external "assert" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("assert");

/***/ }),

/***/ "buffer":
/*!*************************!*\
  !*** external "buffer" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("buffer");

/***/ }),

/***/ "constants":
/*!****************************!*\
  !*** external "constants" ***!
  \****************************/
/***/ ((module) => {

"use strict";
module.exports = require("constants");

/***/ }),

/***/ "crypto":
/*!*************************!*\
  !*** external "crypto" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("crypto");

/***/ }),

/***/ "events":
/*!*************************!*\
  !*** external "events" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("events");

/***/ }),

/***/ "fs":
/*!*********************!*\
  !*** external "fs" ***!
  \*********************/
/***/ ((module) => {

"use strict";
module.exports = require("fs");

/***/ }),

/***/ "node:buffer":
/*!******************************!*\
  !*** external "node:buffer" ***!
  \******************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:buffer");

/***/ }),

/***/ "node:fs":
/*!**************************!*\
  !*** external "node:fs" ***!
  \**************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:fs");

/***/ }),

/***/ "node:stream":
/*!******************************!*\
  !*** external "node:stream" ***!
  \******************************/
/***/ ((module) => {

"use strict";
module.exports = require("node:stream");

/***/ }),

/***/ "path":
/*!***********************!*\
  !*** external "path" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("path");

/***/ }),

/***/ "process":
/*!**************************!*\
  !*** external "process" ***!
  \**************************/
/***/ ((module) => {

"use strict";
module.exports = require("process");

/***/ }),

/***/ "stream":
/*!*************************!*\
  !*** external "stream" ***!
  \*************************/
/***/ ((module) => {

"use strict";
module.exports = require("stream");

/***/ }),

/***/ "string_decoder":
/*!*********************************!*\
  !*** external "string_decoder" ***!
  \*********************************/
/***/ ((module) => {

"use strict";
module.exports = require("string_decoder");

/***/ }),

/***/ "util":
/*!***********************!*\
  !*** external "util" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("util");

/***/ }),

/***/ "zlib":
/*!***********************!*\
  !*** external "zlib" ***!
  \***********************/
/***/ ((module) => {

"use strict";
module.exports = require("zlib");

/***/ }),

/***/ "./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/core.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/core.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"fileTypeFromBuffer\": () => (/* binding */ fileTypeFromBuffer),\n/* harmony export */   \"fileTypeFromStream\": () => (/* binding */ fileTypeFromStream),\n/* harmony export */   \"fileTypeFromTokenizer\": () => (/* binding */ fileTypeFromTokenizer),\n/* harmony export */   \"fileTypeStream\": () => (/* binding */ fileTypeStream),\n/* harmony export */   \"supportedExtensions\": () => (/* binding */ supportedExtensions),\n/* harmony export */   \"supportedMimeTypes\": () => (/* binding */ supportedMimeTypes)\n/* harmony export */ });\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n/* harmony import */ var token_types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@5.0.1/node_modules/token-types/lib/index.js\");\n/* harmony import */ var strtok3_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strtok3/core */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/core.js\");\n/* harmony import */ var _util_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./util.js */ \"./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/util.js\");\n/* harmony import */ var _supported_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./supported.js */ \"./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/supported.js\");\n\n\n // eslint-disable-line n/file-extension-in-import\n\n\n\nconst minimumBytes = 4100; // A fair amount of file-types are detectable within this range.\n\nasync function fileTypeFromStream(stream) {\n\tconst tokenizer = await strtok3_core__WEBPACK_IMPORTED_MODULE_2__.fromStream(stream);\n\ttry {\n\t\treturn await fileTypeFromTokenizer(tokenizer);\n\t} finally {\n\t\tawait tokenizer.close();\n\t}\n}\n\nasync function fileTypeFromBuffer(input) {\n\tif (!(input instanceof Uint8Array || input instanceof ArrayBuffer)) {\n\t\tthrow new TypeError(`Expected the \\`input\\` argument to be of type \\`Uint8Array\\` or \\`Buffer\\` or \\`ArrayBuffer\\`, got \\`${typeof input}\\``);\n\t}\n\n\tconst buffer = input instanceof Uint8Array ? input : new Uint8Array(input);\n\n\tif (!(buffer?.length > 1)) {\n\t\treturn;\n\t}\n\n\treturn fileTypeFromTokenizer(strtok3_core__WEBPACK_IMPORTED_MODULE_2__.fromBuffer(buffer));\n}\n\nfunction _check(buffer, headers, options) {\n\toptions = {\n\t\toffset: 0,\n\t\t...options,\n\t};\n\n\tfor (const [index, header] of headers.entries()) {\n\t\t// If a bitmask is set\n\t\tif (options.mask) {\n\t\t\t// If header doesn't equal `buf` with bits masked off\n\t\t\tif (header !== (options.mask[index] & buffer[index + options.offset])) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t} else if (header !== buffer[index + options.offset]) {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}\n\nasync function fileTypeFromTokenizer(tokenizer) {\n\ttry {\n\t\treturn new FileTypeParser().parse(tokenizer);\n\t} catch (error) {\n\t\tif (!(error instanceof strtok3_core__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError)) {\n\t\t\tthrow error;\n\t\t}\n\t}\n}\n\nclass FileTypeParser {\n\tcheck(header, options) {\n\t\treturn _check(this.buffer, header, options);\n\t}\n\n\tcheckString(header, options) {\n\t\treturn this.check((0,_util_js__WEBPACK_IMPORTED_MODULE_3__.stringToBytes)(header), options);\n\t}\n\n\tasync parse(tokenizer) {\n\t\tthis.buffer = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(minimumBytes);\n\n\t\t// Keep reading until EOF if the file size is unknown.\n\t\tif (tokenizer.fileInfo.size === undefined) {\n\t\t\ttokenizer.fileInfo.size = Number.MAX_SAFE_INTEGER;\n\t\t}\n\n\t\tthis.tokenizer = tokenizer;\n\n\t\tawait tokenizer.peekBuffer(this.buffer, {length: 12, mayBeLess: true});\n\n\t\t// -- 2-byte signatures --\n\n\t\tif (this.check([0x42, 0x4D])) {\n\t\t\treturn {\n\t\t\t\text: 'bmp',\n\t\t\t\tmime: 'image/bmp',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x0B, 0x77])) {\n\t\t\treturn {\n\t\t\t\text: 'ac3',\n\t\t\t\tmime: 'audio/vnd.dolby.dd-raw',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x78, 0x01])) {\n\t\t\treturn {\n\t\t\t\text: 'dmg',\n\t\t\t\tmime: 'application/x-apple-diskimage',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x4D, 0x5A])) {\n\t\t\treturn {\n\t\t\t\text: 'exe',\n\t\t\t\tmime: 'application/x-msdownload',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x25, 0x21])) {\n\t\t\tawait tokenizer.peekBuffer(this.buffer, {length: 24, mayBeLess: true});\n\n\t\t\tif (\n\t\t\t\tthis.checkString('PS-Adobe-', {offset: 2})\n\t\t\t\t&& this.checkString(' EPSF-', {offset: 14})\n\t\t\t) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'eps',\n\t\t\t\t\tmime: 'application/eps',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\text: 'ps',\n\t\t\t\tmime: 'application/postscript',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x1F, 0xA0])\n\t\t\t|| this.check([0x1F, 0x9D])\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'Z',\n\t\t\t\tmime: 'application/x-compress',\n\t\t\t};\n\t\t}\n\n\t\t// -- 3-byte signatures --\n\n\t\tif (this.check([0xEF, 0xBB, 0xBF])) { // UTF-8-BOM\n\t\t\t// Strip off UTF-8-BOM\n\t\t\tthis.tokenizer.ignore(3);\n\t\t\treturn this.parse(tokenizer);\n\t\t}\n\n\t\tif (this.check([0x47, 0x49, 0x46])) {\n\t\t\treturn {\n\t\t\t\text: 'gif',\n\t\t\t\tmime: 'image/gif',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xFF, 0xD8, 0xFF])) {\n\t\t\treturn {\n\t\t\t\text: 'jpg',\n\t\t\t\tmime: 'image/jpeg',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x49, 0x49, 0xBC])) {\n\t\t\treturn {\n\t\t\t\text: 'jxr',\n\t\t\t\tmime: 'image/vnd.ms-photo',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x1F, 0x8B, 0x8])) {\n\t\t\treturn {\n\t\t\t\text: 'gz',\n\t\t\t\tmime: 'application/gzip',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x42, 0x5A, 0x68])) {\n\t\t\treturn {\n\t\t\t\text: 'bz2',\n\t\t\t\tmime: 'application/x-bzip2',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('ID3')) {\n\t\t\tawait tokenizer.ignore(6); // Skip ID3 header until the header size\n\t\t\tconst id3HeaderLength = await tokenizer.readToken(_util_js__WEBPACK_IMPORTED_MODULE_3__.uint32SyncSafeToken);\n\t\t\tif (tokenizer.position + id3HeaderLength > tokenizer.fileInfo.size) {\n\t\t\t\t// Guess file type based on ID3 header for backward compatibility\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp3',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tawait tokenizer.ignore(id3HeaderLength);\n\t\t\treturn fileTypeFromTokenizer(tokenizer); // Skip ID3 header, recursion\n\t\t}\n\n\t\t// Musepack, SV7\n\t\tif (this.checkString('MP+')) {\n\t\t\treturn {\n\t\t\t\text: 'mpc',\n\t\t\t\tmime: 'audio/x-musepack',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\t(this.buffer[0] === 0x43 || this.buffer[0] === 0x46)\n\t\t\t&& this.check([0x57, 0x53], {offset: 1})\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'swf',\n\t\t\t\tmime: 'application/x-shockwave-flash',\n\t\t\t};\n\t\t}\n\n\t\t// -- 4-byte signatures --\n\n\t\tif (this.checkString('FLIF')) {\n\t\t\treturn {\n\t\t\t\text: 'flif',\n\t\t\t\tmime: 'image/flif',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('8BPS')) {\n\t\t\treturn {\n\t\t\t\text: 'psd',\n\t\t\t\tmime: 'image/vnd.adobe.photoshop',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('WEBP', {offset: 8})) {\n\t\t\treturn {\n\t\t\t\text: 'webp',\n\t\t\t\tmime: 'image/webp',\n\t\t\t};\n\t\t}\n\n\t\t// Musepack, SV8\n\t\tif (this.checkString('MPCK')) {\n\t\t\treturn {\n\t\t\t\text: 'mpc',\n\t\t\t\tmime: 'audio/x-musepack',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('FORM')) {\n\t\t\treturn {\n\t\t\t\text: 'aif',\n\t\t\t\tmime: 'audio/aiff',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('icns', {offset: 0})) {\n\t\t\treturn {\n\t\t\t\text: 'icns',\n\t\t\t\tmime: 'image/icns',\n\t\t\t};\n\t\t}\n\n\t\t// Zip-based file formats\n\t\t// Need to be before the `zip` check\n\t\tif (this.check([0x50, 0x4B, 0x3, 0x4])) { // Local file header signature\n\t\t\ttry {\n\t\t\t\twhile (tokenizer.position + 30 < tokenizer.fileInfo.size) {\n\t\t\t\t\tawait tokenizer.readBuffer(this.buffer, {length: 30});\n\n\t\t\t\t\t// https://en.wikipedia.org/wiki/Zip_(file_format)#File_headers\n\t\t\t\t\tconst zipHeader = {\n\t\t\t\t\t\tcompressedSize: this.buffer.readUInt32LE(18),\n\t\t\t\t\t\tuncompressedSize: this.buffer.readUInt32LE(22),\n\t\t\t\t\t\tfilenameLength: this.buffer.readUInt16LE(26),\n\t\t\t\t\t\textraFieldLength: this.buffer.readUInt16LE(28),\n\t\t\t\t\t};\n\n\t\t\t\t\tzipHeader.filename = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(zipHeader.filenameLength, 'utf-8'));\n\t\t\t\t\tawait tokenizer.ignore(zipHeader.extraFieldLength);\n\n\t\t\t\t\t// Assumes signed `.xpi` from addons.mozilla.org\n\t\t\t\t\tif (zipHeader.filename === 'META-INF/mozilla.rsa') {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'xpi',\n\t\t\t\t\t\t\tmime: 'application/x-xpinstall',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (zipHeader.filename.endsWith('.rels') || zipHeader.filename.endsWith('.xml')) {\n\t\t\t\t\t\tconst type = zipHeader.filename.split('/')[0];\n\t\t\t\t\t\tswitch (type) {\n\t\t\t\t\t\t\tcase '_rels':\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase 'word':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'docx',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'ppt':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'pptx',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'xl':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'xlsx',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif (zipHeader.filename.startsWith('xl/')) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'xlsx',\n\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (zipHeader.filename.startsWith('3D/') && zipHeader.filename.endsWith('.model')) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: '3mf',\n\t\t\t\t\t\t\tmime: 'model/3mf',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\t// The docx, xlsx and pptx file types extend the Office Open XML file format:\n\t\t\t\t\t// https://en.wikipedia.org/wiki/Office_Open_XML_file_formats\n\t\t\t\t\t// We look for:\n\t\t\t\t\t// - one entry named '[Content_Types].xml' or '_rels/.rels',\n\t\t\t\t\t// - one entry indicating specific type of file.\n\t\t\t\t\t// MS Office, OpenOffice and LibreOffice may put the parts in different order, so the check should not rely on it.\n\t\t\t\t\tif (zipHeader.filename === 'mimetype' && zipHeader.compressedSize === zipHeader.uncompressedSize) {\n\t\t\t\t\t\tlet mimeType = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(zipHeader.compressedSize, 'utf-8'));\n\t\t\t\t\t\tmimeType = mimeType.trim();\n\n\t\t\t\t\t\tswitch (mimeType) {\n\t\t\t\t\t\t\tcase 'application/epub+zip':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'epub',\n\t\t\t\t\t\t\t\t\tmime: 'application/epub+zip',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.text':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'odt',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.text',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.spreadsheet':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'ods',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.spreadsheet',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.presentation':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'odp',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.presentation',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Try to find next header manually when current one is corrupted\n\t\t\t\t\tif (zipHeader.compressedSize === 0) {\n\t\t\t\t\t\tlet nextHeaderIndex = -1;\n\n\t\t\t\t\t\twhile (nextHeaderIndex < 0 && (tokenizer.position < tokenizer.fileInfo.size)) {\n\t\t\t\t\t\t\tawait tokenizer.peekBuffer(this.buffer, {mayBeLess: true});\n\n\t\t\t\t\t\t\tnextHeaderIndex = this.buffer.indexOf('504B0304', 0, 'hex');\n\t\t\t\t\t\t\t// Move position to the next header if found, skip the whole buffer otherwise\n\t\t\t\t\t\t\tawait tokenizer.ignore(nextHeaderIndex >= 0 ? nextHeaderIndex : this.buffer.length);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tawait tokenizer.ignore(zipHeader.compressedSize);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\tif (!(error instanceof strtok3_core__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError)) {\n\t\t\t\t\tthrow error;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\text: 'zip',\n\t\t\t\tmime: 'application/zip',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('OggS')) {\n\t\t\t// This is an OGG container\n\t\t\tawait tokenizer.ignore(28);\n\t\t\tconst type = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(8);\n\t\t\tawait tokenizer.readBuffer(type);\n\n\t\t\t// Needs to be before `ogg` check\n\t\t\tif (_check(type, [0x4F, 0x70, 0x75, 0x73, 0x48, 0x65, 0x61, 0x64])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'opus',\n\t\t\t\t\tmime: 'audio/opus',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If ' theora' in header.\n\t\t\tif (_check(type, [0x80, 0x74, 0x68, 0x65, 0x6F, 0x72, 0x61])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ogv',\n\t\t\t\t\tmime: 'video/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If '\\x01video' in header.\n\t\t\tif (_check(type, [0x01, 0x76, 0x69, 0x64, 0x65, 0x6F, 0x00])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ogm',\n\t\t\t\t\tmime: 'video/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If ' FLAC' in header  https://xiph.org/flac/faq.html\n\t\t\tif (_check(type, [0x7F, 0x46, 0x4C, 0x41, 0x43])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'oga',\n\t\t\t\t\tmime: 'audio/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// 'Speex  ' in header https://en.wikipedia.org/wiki/Speex\n\t\t\tif (_check(type, [0x53, 0x70, 0x65, 0x65, 0x78, 0x20, 0x20])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'spx',\n\t\t\t\t\tmime: 'audio/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If '\\x01vorbis' in header\n\t\t\tif (_check(type, [0x01, 0x76, 0x6F, 0x72, 0x62, 0x69, 0x73])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ogg',\n\t\t\t\t\tmime: 'audio/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Default OGG container https://www.iana.org/assignments/media-types/application/ogg\n\t\t\treturn {\n\t\t\t\text: 'ogx',\n\t\t\t\tmime: 'application/ogg',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x50, 0x4B])\n\t\t\t&& (this.buffer[2] === 0x3 || this.buffer[2] === 0x5 || this.buffer[2] === 0x7)\n\t\t\t&& (this.buffer[3] === 0x4 || this.buffer[3] === 0x6 || this.buffer[3] === 0x8)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'zip',\n\t\t\t\tmime: 'application/zip',\n\t\t\t};\n\t\t}\n\n\t\t//\n\n\t\t// File Type Box (https://en.wikipedia.org/wiki/ISO_base_media_file_format)\n\t\t// It's not required to be first, but it's recommended to be. Almost all ISO base media files start with `ftyp` box.\n\t\t// `ftyp` box must contain a brand major identifier, which must consist of ISO 8859-1 printable characters.\n\t\t// Here we check for 8859-1 printable characters (for simplicity, it's a mask which also catches one non-printable character).\n\t\tif (\n\t\t\tthis.checkString('ftyp', {offset: 4})\n\t\t\t&& (this.buffer[8] & 0x60) !== 0x00 // Brand major, first character ASCII?\n\t\t) {\n\t\t\t// They all can have MIME `video/mp4` except `application/mp4` special-case which is hard to detect.\n\t\t\t// For some cases, we're specific, everything else falls to `video/mp4` with `mp4` extension.\n\t\t\tconst brandMajor = this.buffer.toString('binary', 8, 12).replace('\\0', ' ').trim();\n\t\t\tswitch (brandMajor) {\n\t\t\t\tcase 'avif':\n\t\t\t\tcase 'avis':\n\t\t\t\t\treturn {ext: 'avif', mime: 'image/avif'};\n\t\t\t\tcase 'mif1':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heif'};\n\t\t\t\tcase 'msf1':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heif-sequence'};\n\t\t\t\tcase 'heic':\n\t\t\t\tcase 'heix':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heic'};\n\t\t\t\tcase 'hevc':\n\t\t\t\tcase 'hevx':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heic-sequence'};\n\t\t\t\tcase 'qt':\n\t\t\t\t\treturn {ext: 'mov', mime: 'video/quicktime'};\n\t\t\t\tcase 'M4V':\n\t\t\t\tcase 'M4VH':\n\t\t\t\tcase 'M4VP':\n\t\t\t\t\treturn {ext: 'm4v', mime: 'video/x-m4v'};\n\t\t\t\tcase 'M4P':\n\t\t\t\t\treturn {ext: 'm4p', mime: 'video/mp4'};\n\t\t\t\tcase 'M4B':\n\t\t\t\t\treturn {ext: 'm4b', mime: 'audio/mp4'};\n\t\t\t\tcase 'M4A':\n\t\t\t\t\treturn {ext: 'm4a', mime: 'audio/x-m4a'};\n\t\t\t\tcase 'F4V':\n\t\t\t\t\treturn {ext: 'f4v', mime: 'video/mp4'};\n\t\t\t\tcase 'F4P':\n\t\t\t\t\treturn {ext: 'f4p', mime: 'video/mp4'};\n\t\t\t\tcase 'F4A':\n\t\t\t\t\treturn {ext: 'f4a', mime: 'audio/mp4'};\n\t\t\t\tcase 'F4B':\n\t\t\t\t\treturn {ext: 'f4b', mime: 'audio/mp4'};\n\t\t\t\tcase 'crx':\n\t\t\t\t\treturn {ext: 'cr3', mime: 'image/x-canon-cr3'};\n\t\t\t\tdefault:\n\t\t\t\t\tif (brandMajor.startsWith('3g')) {\n\t\t\t\t\t\tif (brandMajor.startsWith('3g2')) {\n\t\t\t\t\t\t\treturn {ext: '3g2', mime: 'video/3gpp2'};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn {ext: '3gp', mime: 'video/3gpp'};\n\t\t\t\t\t}\n\n\t\t\t\t\treturn {ext: 'mp4', mime: 'video/mp4'};\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('MThd')) {\n\t\t\treturn {\n\t\t\t\text: 'mid',\n\t\t\t\tmime: 'audio/midi',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('wOFF')\n\t\t\t&& (\n\t\t\t\tthis.check([0x00, 0x01, 0x00, 0x00], {offset: 4})\n\t\t\t\t|| this.checkString('OTTO', {offset: 4})\n\t\t\t)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'woff',\n\t\t\t\tmime: 'font/woff',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('wOF2')\n\t\t\t&& (\n\t\t\t\tthis.check([0x00, 0x01, 0x00, 0x00], {offset: 4})\n\t\t\t\t|| this.checkString('OTTO', {offset: 4})\n\t\t\t)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'woff2',\n\t\t\t\tmime: 'font/woff2',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xD4, 0xC3, 0xB2, 0xA1]) || this.check([0xA1, 0xB2, 0xC3, 0xD4])) {\n\t\t\treturn {\n\t\t\t\text: 'pcap',\n\t\t\t\tmime: 'application/vnd.tcpdump.pcap',\n\t\t\t};\n\t\t}\n\n\t\t// Sony DSD Stream File (DSF)\n\t\tif (this.checkString('DSD ')) {\n\t\t\treturn {\n\t\t\t\text: 'dsf',\n\t\t\t\tmime: 'audio/x-dsf', // Non-standard\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('LZIP')) {\n\t\t\treturn {\n\t\t\t\text: 'lz',\n\t\t\t\tmime: 'application/x-lzip',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('fLaC')) {\n\t\t\treturn {\n\t\t\t\text: 'flac',\n\t\t\t\tmime: 'audio/x-flac',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x42, 0x50, 0x47, 0xFB])) {\n\t\t\treturn {\n\t\t\t\text: 'bpg',\n\t\t\t\tmime: 'image/bpg',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('wvpk')) {\n\t\t\treturn {\n\t\t\t\text: 'wv',\n\t\t\t\tmime: 'audio/wavpack',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('%PDF')) {\n\t\t\tawait tokenizer.ignore(1350);\n\t\t\tconst maxBufferSize = 10 * 1024 * 1024;\n\t\t\tconst buffer = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(Math.min(maxBufferSize, tokenizer.fileInfo.size));\n\t\t\tawait tokenizer.readBuffer(buffer, {mayBeLess: true});\n\n\t\t\t// Check if this is an Adobe Illustrator file\n\t\t\tif (buffer.includes(node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.from('AIPrivateData'))) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ai',\n\t\t\t\t\tmime: 'application/postscript',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Assume this is just a normal PDF\n\t\t\treturn {\n\t\t\t\text: 'pdf',\n\t\t\t\tmime: 'application/pdf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x61, 0x73, 0x6D])) {\n\t\t\treturn {\n\t\t\t\text: 'wasm',\n\t\t\t\tmime: 'application/wasm',\n\t\t\t};\n\t\t}\n\n\t\t// TIFF, little-endian type\n\t\tif (this.check([0x49, 0x49])) {\n\t\t\tconst fileType = await this.readTiffHeader(false);\n\t\t\tif (fileType) {\n\t\t\t\treturn fileType;\n\t\t\t}\n\t\t}\n\n\t\t// TIFF, big-endian type\n\t\tif (this.check([0x4D, 0x4D])) {\n\t\t\tconst fileType = await this.readTiffHeader(true);\n\t\t\tif (fileType) {\n\t\t\t\treturn fileType;\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('MAC ')) {\n\t\t\treturn {\n\t\t\t\text: 'ape',\n\t\t\t\tmime: 'audio/ape',\n\t\t\t};\n\t\t}\n\n\t\t// https://github.com/threatstack/libmagic/blob/master/magic/Magdir/matroska\n\t\tif (this.check([0x1A, 0x45, 0xDF, 0xA3])) { // Root element: EBML\n\t\t\tasync function readField() {\n\t\t\t\tconst msb = await tokenizer.peekNumber(token_types__WEBPACK_IMPORTED_MODULE_1__.UINT8);\n\t\t\t\tlet mask = 0x80;\n\t\t\t\tlet ic = 0; // 0 = A, 1 = B, 2 = C, 3\n\t\t\t\t// = D\n\n\t\t\t\twhile ((msb & mask) === 0 && mask !== 0) {\n\t\t\t\t\t++ic;\n\t\t\t\t\tmask >>= 1;\n\t\t\t\t}\n\n\t\t\t\tconst id = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(ic + 1);\n\t\t\t\tawait tokenizer.readBuffer(id);\n\t\t\t\treturn id;\n\t\t\t}\n\n\t\t\tasync function readElement() {\n\t\t\t\tconst id = await readField();\n\t\t\t\tconst lengthField = await readField();\n\t\t\t\tlengthField[0] ^= 0x80 >> (lengthField.length - 1);\n\t\t\t\tconst nrLength = Math.min(6, lengthField.length); // JavaScript can max read 6 bytes integer\n\t\t\t\treturn {\n\t\t\t\t\tid: id.readUIntBE(0, id.length),\n\t\t\t\t\tlen: lengthField.readUIntBE(lengthField.length - nrLength, nrLength),\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tasync function readChildren(children) {\n\t\t\t\twhile (children > 0) {\n\t\t\t\t\tconst element = await readElement();\n\t\t\t\t\tif (element.id === 0x42_82) {\n\t\t\t\t\t\tconst rawValue = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(element.len, 'utf-8'));\n\t\t\t\t\t\treturn rawValue.replace(/\\00.*$/g, ''); // Return DocType\n\t\t\t\t\t}\n\n\t\t\t\t\tawait tokenizer.ignore(element.len); // ignore payload\n\t\t\t\t\t--children;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tconst re = await readElement();\n\t\t\tconst docType = await readChildren(re.len);\n\n\t\t\tswitch (docType) {\n\t\t\t\tcase 'webm':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'webm',\n\t\t\t\t\t\tmime: 'video/webm',\n\t\t\t\t\t};\n\n\t\t\t\tcase 'matroska':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'mkv',\n\t\t\t\t\t\tmime: 'video/x-matroska',\n\t\t\t\t\t};\n\n\t\t\t\tdefault:\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\t// RIFF file format which might be AVI, WAV, QCP, etc\n\t\tif (this.check([0x52, 0x49, 0x46, 0x46])) {\n\t\t\tif (this.check([0x41, 0x56, 0x49], {offset: 8})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'avi',\n\t\t\t\t\tmime: 'video/vnd.avi',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (this.check([0x57, 0x41, 0x56, 0x45], {offset: 8})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'wav',\n\t\t\t\t\tmime: 'audio/vnd.wave',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// QLCM, QCP file\n\t\t\tif (this.check([0x51, 0x4C, 0x43, 0x4D], {offset: 8})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'qcp',\n\t\t\t\t\tmime: 'audio/qcelp',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('SQLi')) {\n\t\t\treturn {\n\t\t\t\text: 'sqlite',\n\t\t\t\tmime: 'application/x-sqlite3',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x4E, 0x45, 0x53, 0x1A])) {\n\t\t\treturn {\n\t\t\t\text: 'nes',\n\t\t\t\tmime: 'application/x-nintendo-nes-rom',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('Cr24')) {\n\t\t\treturn {\n\t\t\t\text: 'crx',\n\t\t\t\tmime: 'application/x-google-chrome-extension',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('MSCF')\n\t\t\t|| this.checkString('ISc(')\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'cab',\n\t\t\t\tmime: 'application/vnd.ms-cab-compressed',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xED, 0xAB, 0xEE, 0xDB])) {\n\t\t\treturn {\n\t\t\t\text: 'rpm',\n\t\t\t\tmime: 'application/x-rpm',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xC5, 0xD0, 0xD3, 0xC6])) {\n\t\t\treturn {\n\t\t\t\text: 'eps',\n\t\t\t\tmime: 'application/eps',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x28, 0xB5, 0x2F, 0xFD])) {\n\t\t\treturn {\n\t\t\t\text: 'zst',\n\t\t\t\tmime: 'application/zstd',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x7F, 0x45, 0x4C, 0x46])) {\n\t\t\treturn {\n\t\t\t\text: 'elf',\n\t\t\t\tmime: 'application/x-elf',\n\t\t\t};\n\t\t}\n\n\t\t// -- 5-byte signatures --\n\n\t\tif (this.check([0x4F, 0x54, 0x54, 0x4F, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'otf',\n\t\t\t\tmime: 'font/otf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('#!AMR')) {\n\t\t\treturn {\n\t\t\t\text: 'amr',\n\t\t\t\tmime: 'audio/amr',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('{\\\\rtf')) {\n\t\t\treturn {\n\t\t\t\text: 'rtf',\n\t\t\t\tmime: 'application/rtf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x46, 0x4C, 0x56, 0x01])) {\n\t\t\treturn {\n\t\t\t\text: 'flv',\n\t\t\t\tmime: 'video/x-flv',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('IMPM')) {\n\t\t\treturn {\n\t\t\t\text: 'it',\n\t\t\t\tmime: 'audio/x-it',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('-lh0-', {offset: 2})\n\t\t\t|| this.checkString('-lh1-', {offset: 2})\n\t\t\t|| this.checkString('-lh2-', {offset: 2})\n\t\t\t|| this.checkString('-lh3-', {offset: 2})\n\t\t\t|| this.checkString('-lh4-', {offset: 2})\n\t\t\t|| this.checkString('-lh5-', {offset: 2})\n\t\t\t|| this.checkString('-lh6-', {offset: 2})\n\t\t\t|| this.checkString('-lh7-', {offset: 2})\n\t\t\t|| this.checkString('-lzs-', {offset: 2})\n\t\t\t|| this.checkString('-lz4-', {offset: 2})\n\t\t\t|| this.checkString('-lz5-', {offset: 2})\n\t\t\t|| this.checkString('-lhd-', {offset: 2})\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'lzh',\n\t\t\t\tmime: 'application/x-lzh-compressed',\n\t\t\t};\n\t\t}\n\n\t\t// MPEG program stream (PS or MPEG-PS)\n\t\tif (this.check([0x00, 0x00, 0x01, 0xBA])) {\n\t\t\t//  MPEG-PS, MPEG-1 Part 1\n\t\t\tif (this.check([0x21], {offset: 4, mask: [0xF1]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mpg', // May also be .ps, .mpeg\n\t\t\t\t\tmime: 'video/MP1S',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// MPEG-PS, MPEG-2 Part 1\n\t\t\tif (this.check([0x44], {offset: 4, mask: [0xC4]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mpg', // May also be .mpg, .m2p, .vob or .sub\n\t\t\t\t\tmime: 'video/MP2P',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('ITSF')) {\n\t\t\treturn {\n\t\t\t\text: 'chm',\n\t\t\t\tmime: 'application/vnd.ms-htmlhelp',\n\t\t\t};\n\t\t}\n\n\t\t// -- 6-byte signatures --\n\n\t\tif (this.check([0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'xz',\n\t\t\t\tmime: 'application/x-xz',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('<?xml ')) {\n\t\t\treturn {\n\t\t\t\text: 'xml',\n\t\t\t\tmime: 'application/xml',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x37, 0x7A, 0xBC, 0xAF, 0x27, 0x1C])) {\n\t\t\treturn {\n\t\t\t\text: '7z',\n\t\t\t\tmime: 'application/x-7z-compressed',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x52, 0x61, 0x72, 0x21, 0x1A, 0x7])\n\t\t\t&& (this.buffer[6] === 0x0 || this.buffer[6] === 0x1)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'rar',\n\t\t\t\tmime: 'application/x-rar-compressed',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('solid ')) {\n\t\t\treturn {\n\t\t\t\text: 'stl',\n\t\t\t\tmime: 'model/stl',\n\t\t\t};\n\t\t}\n\n\t\t// -- 7-byte signatures --\n\n\t\tif (this.checkString('BLENDER')) {\n\t\t\treturn {\n\t\t\t\text: 'blend',\n\t\t\t\tmime: 'application/x-blender',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('!<arch>')) {\n\t\t\tawait tokenizer.ignore(8);\n\t\t\tconst string = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(13, 'ascii'));\n\t\t\tif (string === 'debian-binary') {\n\t\t\t\treturn {\n\t\t\t\t\text: 'deb',\n\t\t\t\t\tmime: 'application/x-deb',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\text: 'ar',\n\t\t\t\tmime: 'application/x-unix-archive',\n\t\t\t};\n\t\t}\n\n\t\t// -- 8-byte signatures --\n\n\t\tif (this.check([0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\t\t// APNG format (https://wiki.mozilla.org/APNG_Specification)\n\t\t\t// 1. Find the first IDAT (image data) chunk (49 44 41 54)\n\t\t\t// 2. Check if there is an \"acTL\" chunk before the IDAT one (61 63 54 4C)\n\n\t\t\t// Offset calculated as follows:\n\t\t\t// - 8 bytes: PNG signature\n\t\t\t// - 4 (length) + 4 (chunk type) + 13 (chunk data) + 4 (CRC): IHDR chunk\n\n\t\t\tawait tokenizer.ignore(8); // ignore PNG signature\n\n\t\t\tasync function readChunkHeader() {\n\t\t\t\treturn {\n\t\t\t\t\tlength: await tokenizer.readToken(token_types__WEBPACK_IMPORTED_MODULE_1__.INT32_BE),\n\t\t\t\t\ttype: await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(4, 'binary')),\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tdo {\n\t\t\t\tconst chunk = await readChunkHeader();\n\t\t\t\tif (chunk.length < 0) {\n\t\t\t\t\treturn; // Invalid chunk length\n\t\t\t\t}\n\n\t\t\t\tswitch (chunk.type) {\n\t\t\t\t\tcase 'IDAT':\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'png',\n\t\t\t\t\t\t\tmime: 'image/png',\n\t\t\t\t\t\t};\n\t\t\t\t\tcase 'acTL':\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'apng',\n\t\t\t\t\t\t\tmime: 'image/apng',\n\t\t\t\t\t\t};\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tawait tokenizer.ignore(chunk.length + 4); // Ignore chunk-data + CRC\n\t\t\t\t}\n\t\t\t} while (tokenizer.position + 8 < tokenizer.fileInfo.size);\n\n\t\t\treturn {\n\t\t\t\text: 'png',\n\t\t\t\tmime: 'image/png',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x41, 0x52, 0x52, 0x4F, 0x57, 0x31, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'arrow',\n\t\t\t\tmime: 'application/x-apache-arrow',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x67, 0x6C, 0x54, 0x46, 0x02, 0x00, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'glb',\n\t\t\t\tmime: 'model/gltf-binary',\n\t\t\t};\n\t\t}\n\n\t\t// `mov` format variants\n\t\tif (\n\t\t\tthis.check([0x66, 0x72, 0x65, 0x65], {offset: 4}) // `free`\n\t\t\t|| this.check([0x6D, 0x64, 0x61, 0x74], {offset: 4}) // `mdat` MJPEG\n\t\t\t|| this.check([0x6D, 0x6F, 0x6F, 0x76], {offset: 4}) // `moov`\n\t\t\t|| this.check([0x77, 0x69, 0x64, 0x65], {offset: 4}) // `wide`\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'mov',\n\t\t\t\tmime: 'video/quicktime',\n\t\t\t};\n\t\t}\n\n\t\t// -- 9-byte signatures --\n\n\t\tif (this.check([0x49, 0x49, 0x52, 0x4F, 0x08, 0x00, 0x00, 0x00, 0x18])) {\n\t\t\treturn {\n\t\t\t\text: 'orf',\n\t\t\t\tmime: 'image/x-olympus-orf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('gimp xcf ')) {\n\t\t\treturn {\n\t\t\t\text: 'xcf',\n\t\t\t\tmime: 'image/x-xcf',\n\t\t\t};\n\t\t}\n\n\t\t// -- 12-byte signatures --\n\n\t\tif (this.check([0x49, 0x49, 0x55, 0x00, 0x18, 0x00, 0x00, 0x00, 0x88, 0xE7, 0x74, 0xD8])) {\n\t\t\treturn {\n\t\t\t\text: 'rw2',\n\t\t\t\tmime: 'image/x-panasonic-rw2',\n\t\t\t};\n\t\t}\n\n\t\t// ASF_Header_Object first 80 bytes\n\t\tif (this.check([0x30, 0x26, 0xB2, 0x75, 0x8E, 0x66, 0xCF, 0x11, 0xA6, 0xD9])) {\n\t\t\tasync function readHeader() {\n\t\t\t\tconst guid = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(16);\n\t\t\t\tawait tokenizer.readBuffer(guid);\n\t\t\t\treturn {\n\t\t\t\t\tid: guid,\n\t\t\t\t\tsize: Number(await tokenizer.readToken(token_types__WEBPACK_IMPORTED_MODULE_1__.UINT64_LE)),\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tawait tokenizer.ignore(30);\n\t\t\t// Search for header should be in first 1KB of file.\n\t\t\twhile (tokenizer.position + 24 < tokenizer.fileInfo.size) {\n\t\t\t\tconst header = await readHeader();\n\t\t\t\tlet payload = header.size - 24;\n\t\t\t\tif (_check(header.id, [0x91, 0x07, 0xDC, 0xB7, 0xB7, 0xA9, 0xCF, 0x11, 0x8E, 0xE6, 0x00, 0xC0, 0x0C, 0x20, 0x53, 0x65])) {\n\t\t\t\t\t// Sync on Stream-Properties-Object (B7DC0791-A9B7-11CF-8EE6-00C00C205365)\n\t\t\t\t\tconst typeId = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(16);\n\t\t\t\t\tpayload -= await tokenizer.readBuffer(typeId);\n\n\t\t\t\t\tif (_check(typeId, [0x40, 0x9E, 0x69, 0xF8, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {\n\t\t\t\t\t\t// Found audio:\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'asf',\n\t\t\t\t\t\t\tmime: 'audio/x-ms-asf',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (_check(typeId, [0xC0, 0xEF, 0x19, 0xBC, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {\n\t\t\t\t\t\t// Found video:\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'asf',\n\t\t\t\t\t\t\tmime: 'video/x-ms-asf',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tawait tokenizer.ignore(payload);\n\t\t\t}\n\n\t\t\t// Default to ASF generic extension\n\t\t\treturn {\n\t\t\t\text: 'asf',\n\t\t\t\tmime: 'application/vnd.ms-asf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xAB, 0x4B, 0x54, 0x58, 0x20, 0x31, 0x31, 0xBB, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\t\treturn {\n\t\t\t\text: 'ktx',\n\t\t\t\tmime: 'image/ktx',\n\t\t\t};\n\t\t}\n\n\t\tif ((this.check([0x7E, 0x10, 0x04]) || this.check([0x7E, 0x18, 0x04])) && this.check([0x30, 0x4D, 0x49, 0x45], {offset: 4})) {\n\t\t\treturn {\n\t\t\t\text: 'mie',\n\t\t\t\tmime: 'application/x-mie',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x27, 0x0A, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00], {offset: 2})) {\n\t\t\treturn {\n\t\t\t\text: 'shp',\n\t\t\t\tmime: 'application/x-esri-shape',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x00, 0x00, 0x0C, 0x6A, 0x50, 0x20, 0x20, 0x0D, 0x0A, 0x87, 0x0A])) {\n\t\t\t// JPEG-2000 family\n\n\t\t\tawait tokenizer.ignore(20);\n\t\t\tconst type = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(4, 'ascii'));\n\t\t\tswitch (type) {\n\t\t\t\tcase 'jp2 ':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'jp2',\n\t\t\t\t\t\tmime: 'image/jp2',\n\t\t\t\t\t};\n\t\t\t\tcase 'jpx ':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'jpx',\n\t\t\t\t\t\tmime: 'image/jpx',\n\t\t\t\t\t};\n\t\t\t\tcase 'jpm ':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'jpm',\n\t\t\t\t\t\tmime: 'image/jpm',\n\t\t\t\t\t};\n\t\t\t\tcase 'mjp2':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'mj2',\n\t\t\t\t\t\tmime: 'image/mj2',\n\t\t\t\t\t};\n\t\t\t\tdefault:\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0xFF, 0x0A])\n\t\t\t|| this.check([0x00, 0x00, 0x00, 0x0C, 0x4A, 0x58, 0x4C, 0x20, 0x0D, 0x0A, 0x87, 0x0A])\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'jxl',\n\t\t\t\tmime: 'image/jxl',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xFE, 0xFF])) { // UTF-16-BOM-LE\n\t\t\tif (this.check([0, 60, 0, 63, 0, 120, 0, 109, 0, 108], {offset: 2})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'xml',\n\t\t\t\t\tmime: 'application/xml',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn undefined; // Some unknown text based format\n\t\t}\n\n\t\t// -- Unsafe signatures --\n\n\t\tif (\n\t\t\tthis.check([0x0, 0x0, 0x1, 0xBA])\n\t\t\t|| this.check([0x0, 0x0, 0x1, 0xB3])\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'mpg',\n\t\t\t\tmime: 'video/mpeg',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x01, 0x00, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'ttf',\n\t\t\t\tmime: 'font/ttf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x00, 0x01, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'ico',\n\t\t\t\tmime: 'image/x-icon',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x00, 0x02, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'cur',\n\t\t\t\tmime: 'image/x-icon',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xD0, 0xCF, 0x11, 0xE0, 0xA1, 0xB1, 0x1A, 0xE1])) {\n\t\t\t// Detected Microsoft Compound File Binary File (MS-CFB) Format.\n\t\t\treturn {\n\t\t\t\text: 'cfb',\n\t\t\t\tmime: 'application/x-cfb',\n\t\t\t};\n\t\t}\n\n\t\t// Increase sample size from 12 to 256.\n\t\tawait tokenizer.peekBuffer(this.buffer, {length: Math.min(256, tokenizer.fileInfo.size), mayBeLess: true});\n\n\t\t// -- 15-byte signatures --\n\n\t\tif (this.checkString('BEGIN:')) {\n\t\t\tif (this.checkString('VCARD', {offset: 6})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'vcf',\n\t\t\t\t\tmime: 'text/vcard',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (this.checkString('VCALENDAR', {offset: 6})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ics',\n\t\t\t\t\tmime: 'text/calendar',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\n\t\t// `raf` is here just to keep all the raw image detectors together.\n\t\tif (this.checkString('FUJIFILMCCD-RAW')) {\n\t\t\treturn {\n\t\t\t\text: 'raf',\n\t\t\t\tmime: 'image/x-fujifilm-raf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('Extended Module:')) {\n\t\t\treturn {\n\t\t\t\text: 'xm',\n\t\t\t\tmime: 'audio/x-xm',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('Creative Voice File')) {\n\t\t\treturn {\n\t\t\t\text: 'voc',\n\t\t\t\tmime: 'audio/x-voc',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x04, 0x00, 0x00, 0x00]) && this.buffer.length >= 16) { // Rough & quick check Pickle/ASAR\n\t\t\tconst jsonSize = this.buffer.readUInt32LE(12);\n\t\t\tif (jsonSize > 12 && this.buffer.length >= jsonSize + 16) {\n\t\t\t\ttry {\n\t\t\t\t\tconst header = this.buffer.slice(16, jsonSize + 16).toString();\n\t\t\t\t\tconst json = JSON.parse(header);\n\t\t\t\t\t// Check if Pickle is ASAR\n\t\t\t\t\tif (json.files) { // Final check, assuring Pickle/ASAR format\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'asar',\n\t\t\t\t\t\t\tmime: 'application/x-asar',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\t\t\t\t} catch {}\n\t\t\t}\n\t\t}\n\n\t\tif (this.check([0x06, 0x0E, 0x2B, 0x34, 0x02, 0x05, 0x01, 0x01, 0x0D, 0x01, 0x02, 0x01, 0x01, 0x02])) {\n\t\t\treturn {\n\t\t\t\text: 'mxf',\n\t\t\t\tmime: 'application/mxf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('SCRM', {offset: 44})) {\n\t\t\treturn {\n\t\t\t\text: 's3m',\n\t\t\t\tmime: 'audio/x-s3m',\n\t\t\t};\n\t\t}\n\n\t\t// Raw MPEG-2 transport stream (188-byte packets)\n\t\tif (this.check([0x47]) && this.check([0x47], {offset: 188})) {\n\t\t\treturn {\n\t\t\t\text: 'mts',\n\t\t\t\tmime: 'video/mp2t',\n\t\t\t};\n\t\t}\n\n\t\t// Blu-ray Disc Audio-Video (BDAV) MPEG-2 transport stream has 4-byte TP_extra_header before each 188-byte packet\n\t\tif (this.check([0x47], {offset: 4}) && this.check([0x47], {offset: 196})) {\n\t\t\treturn {\n\t\t\t\text: 'mts',\n\t\t\t\tmime: 'video/mp2t',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x42, 0x4F, 0x4F, 0x4B, 0x4D, 0x4F, 0x42, 0x49], {offset: 60})) {\n\t\t\treturn {\n\t\t\t\text: 'mobi',\n\t\t\t\tmime: 'application/x-mobipocket-ebook',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x44, 0x49, 0x43, 0x4D], {offset: 128})) {\n\t\t\treturn {\n\t\t\t\text: 'dcm',\n\t\t\t\tmime: 'application/dicom',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x4C, 0x00, 0x00, 0x00, 0x01, 0x14, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0xC0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x46])) {\n\t\t\treturn {\n\t\t\t\text: 'lnk',\n\t\t\t\tmime: 'application/x.ms.shortcut', // Invented by us\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x62, 0x6F, 0x6F, 0x6B, 0x00, 0x00, 0x00, 0x00, 0x6D, 0x61, 0x72, 0x6B, 0x00, 0x00, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'alias',\n\t\t\t\tmime: 'application/x.apple.alias', // Invented by us\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x4C, 0x50], {offset: 34})\n\t\t\t&& (\n\t\t\t\tthis.check([0x00, 0x00, 0x01], {offset: 8})\n\t\t\t\t|| this.check([0x01, 0x00, 0x02], {offset: 8})\n\t\t\t\t|| this.check([0x02, 0x00, 0x02], {offset: 8})\n\t\t\t)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'eot',\n\t\t\t\tmime: 'application/vnd.ms-fontobject',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x06, 0x06, 0xED, 0xF5, 0xD8, 0x1D, 0x46, 0xE5, 0xBD, 0x31, 0xEF, 0xE7, 0xFE, 0x74, 0xB7, 0x1D])) {\n\t\t\treturn {\n\t\t\t\text: 'indd',\n\t\t\t\tmime: 'application/x-indesign',\n\t\t\t};\n\t\t}\n\n\t\t// Increase sample size from 256 to 512\n\t\tawait tokenizer.peekBuffer(this.buffer, {length: Math.min(512, tokenizer.fileInfo.size), mayBeLess: true});\n\n\t\t// Requires a buffer size of 512 bytes\n\t\tif ((0,_util_js__WEBPACK_IMPORTED_MODULE_3__.tarHeaderChecksumMatches)(this.buffer)) {\n\t\t\treturn {\n\t\t\t\text: 'tar',\n\t\t\t\tmime: 'application/x-tar',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xFF, 0xFE])) { // UTF-16-BOM-BE\n\t\t\tif (this.check([60, 0, 63, 0, 120, 0, 109, 0, 108, 0], {offset: 2})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'xml',\n\t\t\t\t\tmime: 'application/xml',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (this.check([0xFF, 0x0E, 0x53, 0x00, 0x6B, 0x00, 0x65, 0x00, 0x74, 0x00, 0x63, 0x00, 0x68, 0x00, 0x55, 0x00, 0x70, 0x00, 0x20, 0x00, 0x4D, 0x00, 0x6F, 0x00, 0x64, 0x00, 0x65, 0x00, 0x6C, 0x00], {offset: 2})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'skp',\n\t\t\t\t\tmime: 'application/vnd.sketchup.skp',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn undefined; // Some text based format\n\t\t}\n\n\t\tif (this.checkString('-----BEGIN PGP MESSAGE-----')) {\n\t\t\treturn {\n\t\t\t\text: 'pgp',\n\t\t\t\tmime: 'application/pgp-encrypted',\n\t\t\t};\n\t\t}\n\n\t\t// Check MPEG 1 or 2 Layer 3 header, or 'layer 0' for ADTS (MPEG sync-word 0xFFE)\n\t\tif (this.buffer.length >= 2 && this.check([0xFF, 0xE0], {offset: 0, mask: [0xFF, 0xE0]})) {\n\t\t\tif (this.check([0x10], {offset: 1, mask: [0x16]})) {\n\t\t\t\t// Check for (ADTS) MPEG-2\n\t\t\t\tif (this.check([0x08], {offset: 1, mask: [0x08]})) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'aac',\n\t\t\t\t\t\tmime: 'audio/aac',\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\t// Must be (ADTS) MPEG-4\n\t\t\t\treturn {\n\t\t\t\t\text: 'aac',\n\t\t\t\t\tmime: 'audio/aac',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// MPEG 1 or 2 Layer 3 header\n\t\t\t// Check for MPEG layer 3\n\t\t\tif (this.check([0x02], {offset: 1, mask: [0x06]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp3',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Check for MPEG layer 2\n\t\t\tif (this.check([0x04], {offset: 1, mask: [0x06]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp2',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Check for MPEG layer 1\n\t\t\tif (this.check([0x06], {offset: 1, mask: [0x06]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp1',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\tasync readTiffTag(bigEndian) {\n\t\tconst tagId = await this.tokenizer.readToken(bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_LE);\n\t\tthis.tokenizer.ignore(10);\n\t\tswitch (tagId) {\n\t\t\tcase 50_341:\n\t\t\t\treturn {\n\t\t\t\t\text: 'arw',\n\t\t\t\t\tmime: 'image/x-sony-arw',\n\t\t\t\t};\n\t\t\tcase 50_706:\n\t\t\t\treturn {\n\t\t\t\t\text: 'dng',\n\t\t\t\t\tmime: 'image/x-adobe-dng',\n\t\t\t\t};\n\t\t\tdefault:\n\t\t}\n\t}\n\n\tasync readTiffIFD(bigEndian) {\n\t\tconst numberOfTags = await this.tokenizer.readToken(bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_LE);\n\t\tfor (let n = 0; n < numberOfTags; ++n) {\n\t\t\tconst fileType = await this.readTiffTag(bigEndian);\n\t\t\tif (fileType) {\n\t\t\t\treturn fileType;\n\t\t\t}\n\t\t}\n\t}\n\n\tasync readTiffHeader(bigEndian) {\n\t\tconst version = (bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_LE).get(this.buffer, 2);\n\t\tconst ifdOffset = (bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_LE).get(this.buffer, 4);\n\n\t\tif (version === 42) {\n\t\t\t// TIFF file header\n\t\t\tif (ifdOffset >= 6) {\n\t\t\t\tif (this.checkString('CR', {offset: 8})) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'cr2',\n\t\t\t\t\t\tmime: 'image/x-canon-cr2',\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\tif (ifdOffset >= 8 && (this.check([0x1C, 0x00, 0xFE, 0x00], {offset: 8}) || this.check([0x1F, 0x00, 0x0B, 0x00], {offset: 8}))) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'nef',\n\t\t\t\t\t\tmime: 'image/x-nikon-nef',\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tawait this.tokenizer.ignore(ifdOffset);\n\t\t\tconst fileType = await this.readTiffIFD(false);\n\t\t\treturn fileType ? fileType : {\n\t\t\t\text: 'tif',\n\t\t\t\tmime: 'image/tiff',\n\t\t\t};\n\t\t}\n\n\t\tif (version === 43) {\t// Big TIFF file header\n\t\t\treturn {\n\t\t\t\text: 'tif',\n\t\t\t\tmime: 'image/tiff',\n\t\t\t};\n\t\t}\n\t}\n}\n\nasync function fileTypeStream(readableStream, {sampleSize = minimumBytes} = {}) {\n\tconst {default: stream} = await Promise.resolve(/*! import() */).then(__webpack_require__.t.bind(__webpack_require__, /*! node:stream */ \"node:stream\", 19));\n\n\treturn new Promise((resolve, reject) => {\n\t\treadableStream.on('error', reject);\n\n\t\treadableStream.once('readable', () => {\n\t\t\t(async () => {\n\t\t\t\ttry {\n\t\t\t\t\t// Set up output stream\n\t\t\t\t\tconst pass = new stream.PassThrough();\n\t\t\t\t\tconst outputStream = stream.pipeline ? stream.pipeline(readableStream, pass, () => {}) : readableStream.pipe(pass);\n\n\t\t\t\t\t// Read the input stream and detect the filetype\n\t\t\t\t\tconst chunk = readableStream.read(sampleSize) ?? readableStream.read() ?? node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(0);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tconst fileType = await fileTypeFromBuffer(chunk);\n\t\t\t\t\t\tpass.fileType = fileType;\n\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\tif (error instanceof strtok3_core__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError) {\n\t\t\t\t\t\t\tpass.fileType = undefined;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tresolve(outputStream);\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t})();\n\t\t});\n\t});\n}\n\nconst supportedExtensions = new Set(_supported_js__WEBPACK_IMPORTED_MODULE_4__.extensions);\nconst supportedMimeTypes = new Set(_supported_js__WEBPACK_IMPORTED_MODULE_4__.mimeTypes);\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/core.js?");

/***/ }),

/***/ "./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/index.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/index.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"fileTypeFromBuffer\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.fileTypeFromBuffer),\n/* harmony export */   \"fileTypeFromFile\": () => (/* binding */ fileTypeFromFile),\n/* harmony export */   \"fileTypeFromStream\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.fileTypeFromStream),\n/* harmony export */   \"fileTypeFromTokenizer\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.fileTypeFromTokenizer),\n/* harmony export */   \"fileTypeStream\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.fileTypeStream),\n/* harmony export */   \"supportedExtensions\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.supportedExtensions),\n/* harmony export */   \"supportedMimeTypes\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.supportedMimeTypes)\n/* harmony export */ });\n/* harmony import */ var strtok3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! strtok3 */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/index.js\");\n/* harmony import */ var _core_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./core.js */ \"./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/core.js\");\n\n\n\nasync function fileTypeFromFile(path) {\n\tconst tokenizer = await strtok3__WEBPACK_IMPORTED_MODULE_0__.fromFile(path);\n\ttry {\n\t\treturn await (0,_core_js__WEBPACK_IMPORTED_MODULE_1__.fileTypeFromTokenizer)(tokenizer);\n\t} finally {\n\t\tawait tokenizer.close();\n\t}\n}\n\n\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/supported.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/supported.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"extensions\": () => (/* binding */ extensions),\n/* harmony export */   \"mimeTypes\": () => (/* binding */ mimeTypes)\n/* harmony export */ });\nconst extensions = [\n\t'jpg',\n\t'png',\n\t'apng',\n\t'gif',\n\t'webp',\n\t'flif',\n\t'xcf',\n\t'cr2',\n\t'cr3',\n\t'orf',\n\t'arw',\n\t'dng',\n\t'nef',\n\t'rw2',\n\t'raf',\n\t'tif',\n\t'bmp',\n\t'icns',\n\t'jxr',\n\t'psd',\n\t'indd',\n\t'zip',\n\t'tar',\n\t'rar',\n\t'gz',\n\t'bz2',\n\t'7z',\n\t'dmg',\n\t'mp4',\n\t'mid',\n\t'mkv',\n\t'webm',\n\t'mov',\n\t'avi',\n\t'mpg',\n\t'mp2',\n\t'mp3',\n\t'm4a',\n\t'oga',\n\t'ogg',\n\t'ogv',\n\t'opus',\n\t'flac',\n\t'wav',\n\t'spx',\n\t'amr',\n\t'pdf',\n\t'epub',\n\t'elf',\n\t'exe',\n\t'swf',\n\t'rtf',\n\t'wasm',\n\t'woff',\n\t'woff2',\n\t'eot',\n\t'ttf',\n\t'otf',\n\t'ico',\n\t'flv',\n\t'ps',\n\t'xz',\n\t'sqlite',\n\t'nes',\n\t'crx',\n\t'xpi',\n\t'cab',\n\t'deb',\n\t'ar',\n\t'rpm',\n\t'Z',\n\t'lz',\n\t'cfb',\n\t'mxf',\n\t'mts',\n\t'blend',\n\t'bpg',\n\t'docx',\n\t'pptx',\n\t'xlsx',\n\t'3gp',\n\t'3g2',\n\t'jp2',\n\t'jpm',\n\t'jpx',\n\t'mj2',\n\t'aif',\n\t'qcp',\n\t'odt',\n\t'ods',\n\t'odp',\n\t'xml',\n\t'mobi',\n\t'heic',\n\t'cur',\n\t'ktx',\n\t'ape',\n\t'wv',\n\t'dcm',\n\t'ics',\n\t'glb',\n\t'pcap',\n\t'dsf',\n\t'lnk',\n\t'alias',\n\t'voc',\n\t'ac3',\n\t'm4v',\n\t'm4p',\n\t'm4b',\n\t'f4v',\n\t'f4p',\n\t'f4b',\n\t'f4a',\n\t'mie',\n\t'asf',\n\t'ogm',\n\t'ogx',\n\t'mpc',\n\t'arrow',\n\t'shp',\n\t'aac',\n\t'mp1',\n\t'it',\n\t's3m',\n\t'xm',\n\t'ai',\n\t'skp',\n\t'avif',\n\t'eps',\n\t'lzh',\n\t'pgp',\n\t'asar',\n\t'stl',\n\t'chm',\n\t'3mf',\n\t'zst',\n\t'jxl',\n\t'vcf',\n];\n\nconst mimeTypes = [\n\t'image/jpeg',\n\t'image/png',\n\t'image/gif',\n\t'image/webp',\n\t'image/flif',\n\t'image/x-xcf',\n\t'image/x-canon-cr2',\n\t'image/x-canon-cr3',\n\t'image/tiff',\n\t'image/bmp',\n\t'image/vnd.ms-photo',\n\t'image/vnd.adobe.photoshop',\n\t'application/x-indesign',\n\t'application/epub+zip',\n\t'application/x-xpinstall',\n\t'application/vnd.oasis.opendocument.text',\n\t'application/vnd.oasis.opendocument.spreadsheet',\n\t'application/vnd.oasis.opendocument.presentation',\n\t'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n\t'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n\t'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n\t'application/zip',\n\t'application/x-tar',\n\t'application/x-rar-compressed',\n\t'application/gzip',\n\t'application/x-bzip2',\n\t'application/x-7z-compressed',\n\t'application/x-apple-diskimage',\n\t'application/x-apache-arrow',\n\t'video/mp4',\n\t'audio/midi',\n\t'video/x-matroska',\n\t'video/webm',\n\t'video/quicktime',\n\t'video/vnd.avi',\n\t'audio/vnd.wave',\n\t'audio/qcelp',\n\t'audio/x-ms-asf',\n\t'video/x-ms-asf',\n\t'application/vnd.ms-asf',\n\t'video/mpeg',\n\t'video/3gpp',\n\t'audio/mpeg',\n\t'audio/mp4', // RFC 4337\n\t'audio/opus',\n\t'video/ogg',\n\t'audio/ogg',\n\t'application/ogg',\n\t'audio/x-flac',\n\t'audio/ape',\n\t'audio/wavpack',\n\t'audio/amr',\n\t'application/pdf',\n\t'application/x-elf',\n\t'application/x-msdownload',\n\t'application/x-shockwave-flash',\n\t'application/rtf',\n\t'application/wasm',\n\t'font/woff',\n\t'font/woff2',\n\t'application/vnd.ms-fontobject',\n\t'font/ttf',\n\t'font/otf',\n\t'image/x-icon',\n\t'video/x-flv',\n\t'application/postscript',\n\t'application/eps',\n\t'application/x-xz',\n\t'application/x-sqlite3',\n\t'application/x-nintendo-nes-rom',\n\t'application/x-google-chrome-extension',\n\t'application/vnd.ms-cab-compressed',\n\t'application/x-deb',\n\t'application/x-unix-archive',\n\t'application/x-rpm',\n\t'application/x-compress',\n\t'application/x-lzip',\n\t'application/x-cfb',\n\t'application/x-mie',\n\t'application/mxf',\n\t'video/mp2t',\n\t'application/x-blender',\n\t'image/bpg',\n\t'image/jp2',\n\t'image/jpx',\n\t'image/jpm',\n\t'image/mj2',\n\t'audio/aiff',\n\t'application/xml',\n\t'application/x-mobipocket-ebook',\n\t'image/heif',\n\t'image/heif-sequence',\n\t'image/heic',\n\t'image/heic-sequence',\n\t'image/icns',\n\t'image/ktx',\n\t'application/dicom',\n\t'audio/x-musepack',\n\t'text/calendar',\n\t'text/vcard',\n\t'model/gltf-binary',\n\t'application/vnd.tcpdump.pcap',\n\t'audio/x-dsf', // Non-standard\n\t'application/x.ms.shortcut', // Invented by us\n\t'application/x.apple.alias', // Invented by us\n\t'audio/x-voc',\n\t'audio/vnd.dolby.dd-raw',\n\t'audio/x-m4a',\n\t'image/apng',\n\t'image/x-olympus-orf',\n\t'image/x-sony-arw',\n\t'image/x-adobe-dng',\n\t'image/x-nikon-nef',\n\t'image/x-panasonic-rw2',\n\t'image/x-fujifilm-raf',\n\t'video/x-m4v',\n\t'video/3gpp2',\n\t'application/x-esri-shape',\n\t'audio/aac',\n\t'audio/x-it',\n\t'audio/x-s3m',\n\t'audio/x-xm',\n\t'video/MP1S',\n\t'video/MP2P',\n\t'application/vnd.sketchup.skp',\n\t'image/avif',\n\t'application/x-lzh-compressed',\n\t'application/pgp-encrypted',\n\t'application/x-asar',\n\t'model/stl',\n\t'application/vnd.ms-htmlhelp',\n\t'model/3mf',\n\t'image/jxl',\n\t'application/zstd',\n];\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/supported.js?");

/***/ }),

/***/ "./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/util.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/util.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"stringToBytes\": () => (/* binding */ stringToBytes),\n/* harmony export */   \"tarHeaderChecksumMatches\": () => (/* binding */ tarHeaderChecksumMatches),\n/* harmony export */   \"uint32SyncSafeToken\": () => (/* binding */ uint32SyncSafeToken)\n/* harmony export */ });\nfunction stringToBytes(string) {\n\treturn [...string].map(character => character.charCodeAt(0)); // eslint-disable-line unicorn/prefer-code-point\n}\n\n/**\nChecks whether the TAR checksum is valid.\n\n@param {Buffer} buffer - The TAR header `[offset ... offset + 512]`.\n@param {number} offset - TAR header offset.\n@returns {boolean} `true` if the TAR checksum is valid, otherwise `false`.\n*/\nfunction tarHeaderChecksumMatches(buffer, offset = 0) {\n\tconst readSum = Number.parseInt(buffer.toString('utf8', 148, 154).replace(/\\0.*$/, '').trim(), 8); // Read sum in header\n\tif (Number.isNaN(readSum)) {\n\t\treturn false;\n\t}\n\n\tlet sum = 8 * 0x20; // Initialize signed bit sum\n\n\tfor (let index = offset; index < offset + 148; index++) {\n\t\tsum += buffer[index];\n\t}\n\n\tfor (let index = offset + 156; index < offset + 512; index++) {\n\t\tsum += buffer[index];\n\t}\n\n\treturn readSum === sum;\n}\n\n/**\nID3 UINT32 sync-safe tokenizer token.\n28 bits (representing up to 256MB) integer, the msb is 0 to avoid \"false syncsignals\".\n*/\nconst uint32SyncSafeToken = {\n\tget: (buffer, offset) => (buffer[offset + 3] & 0x7F) | ((buffer[offset + 2]) << 7) | ((buffer[offset + 1]) << 14) | ((buffer[offset]) << 21),\n\tlen: 4,\n};\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/file-type@18.0.0/node_modules/file-type/util.js?");

/***/ }),

/***/ "./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/Deferred.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/Deferred.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Deferred\": () => (/* binding */ Deferred)\n/* harmony export */ });\nclass Deferred {\n    constructor() {\n        this.resolve = () => null;\n        this.reject = () => null;\n        this.promise = new Promise((resolve, reject) => {\n            this.reject = reject;\n            this.resolve = resolve;\n        });\n    }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/Deferred.js?");

/***/ }),

/***/ "./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/EndOfFileStream.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/EndOfFileStream.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* binding */ EndOfStreamError),\n/* harmony export */   \"defaultMessages\": () => (/* binding */ defaultMessages)\n/* harmony export */ });\nconst defaultMessages = 'End-Of-Stream';\n/**\n * Thrown on read operation of the end of file or stream has been reached\n */\nclass EndOfStreamError extends Error {\n    constructor() {\n        super(defaultMessages);\n    }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/EndOfFileStream.js?");

/***/ }),

/***/ "./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/StreamReader.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/StreamReader.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* reexport safe */ _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError),\n/* harmony export */   \"StreamReader\": () => (/* binding */ StreamReader)\n/* harmony export */ });\n/* harmony import */ var _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./EndOfFileStream.js */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/EndOfFileStream.js\");\n/* harmony import */ var _Deferred_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Deferred.js */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/Deferred.js\");\n\n\n\nconst maxStreamReadSize = 1 * 1024 * 1024; // Maximum request length on read-stream operation\nclass StreamReader {\n    constructor(s) {\n        this.s = s;\n        /**\n         * Deferred used for postponed read request (as not data is yet available to read)\n         */\n        this.deferred = null;\n        this.endOfStream = false;\n        /**\n         * Store peeked data\n         * @type {Array}\n         */\n        this.peekQueue = [];\n        if (!s.read || !s.once) {\n            throw new Error('Expected an instance of stream.Readable');\n        }\n        this.s.once('end', () => this.reject(new _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError()));\n        this.s.once('error', err => this.reject(err));\n        this.s.once('close', () => this.reject(new Error('Stream closed')));\n    }\n    /**\n     * Read ahead (peek) from stream. Subsequent read or peeks will return the same data\n     * @param uint8Array - Uint8Array (or Buffer) to store data read from stream in\n     * @param offset - Offset target\n     * @param length - Number of bytes to read\n     * @returns Number of bytes peeked\n     */\n    async peek(uint8Array, offset, length) {\n        const bytesRead = await this.read(uint8Array, offset, length);\n        this.peekQueue.push(uint8Array.subarray(offset, offset + bytesRead)); // Put read data back to peek buffer\n        return bytesRead;\n    }\n    /**\n     * Read chunk from stream\n     * @param buffer - Target Uint8Array (or Buffer) to store data read from stream in\n     * @param offset - Offset target\n     * @param length - Number of bytes to read\n     * @returns Number of bytes read\n     */\n    async read(buffer, offset, length) {\n        if (length === 0) {\n            return 0;\n        }\n        if (this.peekQueue.length === 0 && this.endOfStream) {\n            throw new _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        }\n        let remaining = length;\n        let bytesRead = 0;\n        // consume peeked data first\n        while (this.peekQueue.length > 0 && remaining > 0) {\n            const peekData = this.peekQueue.pop(); // Front of queue\n            if (!peekData)\n                throw new Error('peekData should be defined');\n            const lenCopy = Math.min(peekData.length, remaining);\n            buffer.set(peekData.subarray(0, lenCopy), offset + bytesRead);\n            bytesRead += lenCopy;\n            remaining -= lenCopy;\n            if (lenCopy < peekData.length) {\n                // remainder back to queue\n                this.peekQueue.push(peekData.subarray(lenCopy));\n            }\n        }\n        // continue reading from stream if required\n        while (remaining > 0 && !this.endOfStream) {\n            const reqLen = Math.min(remaining, maxStreamReadSize);\n            const chunkLen = await this.readFromStream(buffer, offset + bytesRead, reqLen);\n            bytesRead += chunkLen;\n            if (chunkLen < reqLen)\n                break;\n            remaining -= chunkLen;\n        }\n        return bytesRead;\n    }\n    /**\n     * Read chunk from stream\n     * @param buffer Target Uint8Array (or Buffer) to store data read from stream in\n     * @param offset Offset target\n     * @param length Number of bytes to read\n     * @returns Number of bytes read\n     */\n    async readFromStream(buffer, offset, length) {\n        const readBuffer = this.s.read(length);\n        if (readBuffer) {\n            buffer.set(readBuffer, offset);\n            return readBuffer.length;\n        }\n        else {\n            const request = {\n                buffer,\n                offset,\n                length,\n                deferred: new _Deferred_js__WEBPACK_IMPORTED_MODULE_1__.Deferred()\n            };\n            this.deferred = request.deferred;\n            this.s.once('readable', () => {\n                this.readDeferred(request);\n            });\n            return request.deferred.promise;\n        }\n    }\n    /**\n     * Process deferred read request\n     * @param request Deferred read request\n     */\n    readDeferred(request) {\n        const readBuffer = this.s.read(request.length);\n        if (readBuffer) {\n            request.buffer.set(readBuffer, request.offset);\n            request.deferred.resolve(readBuffer.length);\n            this.deferred = null;\n        }\n        else {\n            this.s.once('readable', () => {\n                this.readDeferred(request);\n            });\n        }\n    }\n    reject(err) {\n        this.endOfStream = true;\n        if (this.deferred) {\n            this.deferred.reject(err);\n            this.deferred = null;\n        }\n    }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/StreamReader.js?");

/***/ }),

/***/ "./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* reexport safe */ _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError),\n/* harmony export */   \"StreamReader\": () => (/* reexport safe */ _StreamReader_js__WEBPACK_IMPORTED_MODULE_1__.StreamReader)\n/* harmony export */ });\n/* harmony import */ var _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./EndOfFileStream.js */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/EndOfFileStream.js\");\n/* harmony import */ var _StreamReader_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./StreamReader.js */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/StreamReader.js\");\n\n\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/AbstractTokenizer.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/AbstractTokenizer.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AbstractTokenizer\": () => (/* binding */ AbstractTokenizer)\n/* harmony export */ });\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! peek-readable */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js\");\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n\n\n/**\n * Core tokenizer\n */\nclass AbstractTokenizer {\n    constructor(fileInfo) {\n        /**\n         * Tokenizer-stream position\n         */\n        this.position = 0;\n        this.numBuffer = new Uint8Array(8);\n        this.fileInfo = fileInfo ? fileInfo : {};\n    }\n    /**\n     * Read a token from the tokenizer-stream\n     * @param token - The token to read\n     * @param position - If provided, the desired position in the tokenizer-stream\n     * @returns Promise with token data\n     */\n    async readToken(token, position = this.position) {\n        const uint8Array = node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.alloc(token.len);\n        const len = await this.readBuffer(uint8Array, { position });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(uint8Array, 0);\n    }\n    /**\n     * Peek a token from the tokenizer-stream.\n     * @param token - Token to peek from the tokenizer-stream.\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\n     * @returns Promise with token data\n     */\n    async peekToken(token, position = this.position) {\n        const uint8Array = node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.alloc(token.len);\n        const len = await this.peekBuffer(uint8Array, { position });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(uint8Array, 0);\n    }\n    /**\n     * Read a numeric token from the stream\n     * @param token - Numeric token\n     * @returns Promise with number\n     */\n    async readNumber(token) {\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(this.numBuffer, 0);\n    }\n    /**\n     * Read a numeric token from the stream\n     * @param token - Numeric token\n     * @returns Promise with number\n     */\n    async peekNumber(token) {\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(this.numBuffer, 0);\n    }\n    /**\n     * Ignore number of bytes, advances the pointer in under tokenizer-stream.\n     * @param length - Number of bytes to ignore\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\n     */\n    async ignore(length) {\n        if (this.fileInfo.size !== undefined) {\n            const bytesLeft = this.fileInfo.size - this.position;\n            if (length > bytesLeft) {\n                this.position += bytesLeft;\n                return bytesLeft;\n            }\n        }\n        this.position += length;\n        return length;\n    }\n    async close() {\n        // empty\n    }\n    normalizeOptions(uint8Array, options) {\n        if (options && options.position !== undefined && options.position < this.position) {\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n        }\n        if (options) {\n            return {\n                mayBeLess: options.mayBeLess === true,\n                offset: options.offset ? options.offset : 0,\n                length: options.length ? options.length : (uint8Array.length - (options.offset ? options.offset : 0)),\n                position: options.position ? options.position : this.position\n            };\n        }\n        return {\n            mayBeLess: false,\n            offset: 0,\n            length: uint8Array.length,\n            position: this.position\n        };\n    }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/AbstractTokenizer.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/BufferTokenizer.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/BufferTokenizer.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BufferTokenizer\": () => (/* binding */ BufferTokenizer)\n/* harmony export */ });\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! peek-readable */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js\");\n/* harmony import */ var _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AbstractTokenizer.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/AbstractTokenizer.js\");\n\n\nclass BufferTokenizer extends _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_1__.AbstractTokenizer {\n    /**\n     * Construct BufferTokenizer\n     * @param uint8Array - Uint8Array to tokenize\n     * @param fileInfo - Pass additional file information to the tokenizer\n     */\n    constructor(uint8Array, fileInfo) {\n        super(fileInfo);\n        this.uint8Array = uint8Array;\n        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : uint8Array.length;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param uint8Array - Uint8Array to tokenize\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async readBuffer(uint8Array, options) {\n        if (options && options.position) {\n            if (options.position < this.position) {\n                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n            }\n            this.position = options.position;\n        }\n        const bytesRead = await this.peekBuffer(uint8Array, options);\n        this.position += bytesRead;\n        return bytesRead;\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param uint8Array\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async peekBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        const bytes2read = Math.min(this.uint8Array.length - normOptions.position, normOptions.length);\n        if ((!normOptions.mayBeLess) && bytes2read < normOptions.length) {\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        }\n        else {\n            uint8Array.set(this.uint8Array.subarray(normOptions.position, normOptions.position + bytes2read), normOptions.offset);\n            return bytes2read;\n        }\n    }\n    async close() {\n        // empty\n    }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/BufferTokenizer.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FileTokenizer.js":
/*!************************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FileTokenizer.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FileTokenizer\": () => (/* binding */ FileTokenizer),\n/* harmony export */   \"fromFile\": () => (/* binding */ fromFile)\n/* harmony export */ });\n/* harmony import */ var _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AbstractTokenizer.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/AbstractTokenizer.js\");\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! peek-readable */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js\");\n/* harmony import */ var _FsPromise_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FsPromise.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FsPromise.js\");\n\n\n\nclass FileTokenizer extends _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_0__.AbstractTokenizer {\n    constructor(fd, fileInfo) {\n        super(fileInfo);\n        this.fd = fd;\n    }\n    /**\n     * Read buffer from file\n     * @param uint8Array - Uint8Array to write result to\n     * @param options - Read behaviour options\n     * @returns Promise number of bytes read\n     */\n    async readBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        this.position = normOptions.position;\n        const res = await _FsPromise_js__WEBPACK_IMPORTED_MODULE_2__.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n        this.position += res.bytesRead;\n        if (res.bytesRead < normOptions.length && (!options || !options.mayBeLess)) {\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError();\n        }\n        return res.bytesRead;\n    }\n    /**\n     * Peek buffer from file\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\n     * @param options - Read behaviour options\n     * @returns Promise number of bytes read\n     */\n    async peekBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        const res = await _FsPromise_js__WEBPACK_IMPORTED_MODULE_2__.read(this.fd, uint8Array, normOptions.offset, normOptions.length, normOptions.position);\n        if ((!normOptions.mayBeLess) && res.bytesRead < normOptions.length) {\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError();\n        }\n        return res.bytesRead;\n    }\n    async close() {\n        return _FsPromise_js__WEBPACK_IMPORTED_MODULE_2__.close(this.fd);\n    }\n}\nasync function fromFile(sourceFilePath) {\n    const stat = await _FsPromise_js__WEBPACK_IMPORTED_MODULE_2__.stat(sourceFilePath);\n    if (!stat.isFile) {\n        throw new Error(`File not a file: ${sourceFilePath}`);\n    }\n    const fd = await _FsPromise_js__WEBPACK_IMPORTED_MODULE_2__.open(sourceFilePath, 'r');\n    return new FileTokenizer(fd, { path: sourceFilePath, size: stat.size });\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FileTokenizer.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FsPromise.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FsPromise.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"close\": () => (/* binding */ close),\n/* harmony export */   \"createReadStream\": () => (/* binding */ createReadStream),\n/* harmony export */   \"open\": () => (/* binding */ open),\n/* harmony export */   \"pathExists\": () => (/* binding */ pathExists),\n/* harmony export */   \"read\": () => (/* binding */ read),\n/* harmony export */   \"readFile\": () => (/* binding */ readFile),\n/* harmony export */   \"stat\": () => (/* binding */ stat),\n/* harmony export */   \"writeFile\": () => (/* binding */ writeFile),\n/* harmony export */   \"writeFileSync\": () => (/* binding */ writeFileSync)\n/* harmony export */ });\n/* harmony import */ var node_fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:fs */ \"node:fs\");\n/**\n * Module convert fs functions to promise based functions\n */\n\nconst pathExists = node_fs__WEBPACK_IMPORTED_MODULE_0__.existsSync;\nconst createReadStream = node_fs__WEBPACK_IMPORTED_MODULE_0__.createReadStream;\nasync function stat(path) {\n    return new Promise((resolve, reject) => {\n        node_fs__WEBPACK_IMPORTED_MODULE_0__.stat(path, (err, stats) => {\n            if (err)\n                reject(err);\n            else\n                resolve(stats);\n        });\n    });\n}\nasync function close(fd) {\n    return new Promise((resolve, reject) => {\n        node_fs__WEBPACK_IMPORTED_MODULE_0__.close(fd, err => {\n            if (err)\n                reject(err);\n            else\n                resolve();\n        });\n    });\n}\nasync function open(path, mode) {\n    return new Promise((resolve, reject) => {\n        node_fs__WEBPACK_IMPORTED_MODULE_0__.open(path, mode, (err, fd) => {\n            if (err)\n                reject(err);\n            else\n                resolve(fd);\n        });\n    });\n}\nasync function read(fd, buffer, offset, length, position) {\n    return new Promise((resolve, reject) => {\n        node_fs__WEBPACK_IMPORTED_MODULE_0__.read(fd, buffer, offset, length, position, (err, bytesRead, _buffer) => {\n            if (err)\n                reject(err);\n            else\n                resolve({ bytesRead, buffer: _buffer });\n        });\n    });\n}\nasync function writeFile(path, data) {\n    return new Promise((resolve, reject) => {\n        node_fs__WEBPACK_IMPORTED_MODULE_0__.writeFile(path, data, err => {\n            if (err)\n                reject(err);\n            else\n                resolve();\n        });\n    });\n}\nfunction writeFileSync(path, data) {\n    node_fs__WEBPACK_IMPORTED_MODULE_0__.writeFileSync(path, data);\n}\nasync function readFile(path) {\n    return new Promise((resolve, reject) => {\n        node_fs__WEBPACK_IMPORTED_MODULE_0__.readFile(path, (err, buffer) => {\n            if (err)\n                reject(err);\n            else\n                resolve(buffer);\n        });\n    });\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FsPromise.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/ReadStreamTokenizer.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/ReadStreamTokenizer.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ReadStreamTokenizer\": () => (/* binding */ ReadStreamTokenizer)\n/* harmony export */ });\n/* harmony import */ var _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AbstractTokenizer.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/AbstractTokenizer.js\");\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! peek-readable */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js\");\n\n\nconst maxBufferSize = 256000;\nclass ReadStreamTokenizer extends _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_0__.AbstractTokenizer {\n    constructor(stream, fileInfo) {\n        super(fileInfo);\n        this.streamReader = new peek_readable__WEBPACK_IMPORTED_MODULE_1__.StreamReader(stream);\n    }\n    /**\n     * Get file information, an HTTP-client may implement this doing a HEAD request\n     * @return Promise with file information\n     */\n    async getFileInfo() {\n        return this.fileInfo;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param uint8Array - Target Uint8Array to fill with data read from the tokenizer-stream\n     * @param options - Read behaviour options\n     * @returns Promise with number of bytes read\n     */\n    async readBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        const skipBytes = normOptions.position - this.position;\n        if (skipBytes > 0) {\n            await this.ignore(skipBytes);\n            return this.readBuffer(uint8Array, options);\n        }\n        else if (skipBytes < 0) {\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n        }\n        if (normOptions.length === 0) {\n            return 0;\n        }\n        const bytesRead = await this.streamReader.read(uint8Array, normOptions.offset, normOptions.length);\n        this.position += bytesRead;\n        if ((!options || !options.mayBeLess) && bytesRead < normOptions.length) {\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError();\n        }\n        return bytesRead;\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\n     * @param options - Read behaviour options\n     * @returns Promise with number of bytes peeked\n     */\n    async peekBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        let bytesRead = 0;\n        if (normOptions.position) {\n            const skipBytes = normOptions.position - this.position;\n            if (skipBytes > 0) {\n                const skipBuffer = new Uint8Array(normOptions.length + skipBytes);\n                bytesRead = await this.peekBuffer(skipBuffer, { mayBeLess: normOptions.mayBeLess });\n                uint8Array.set(skipBuffer.subarray(skipBytes), normOptions.offset);\n                return bytesRead - skipBytes;\n            }\n            else if (skipBytes < 0) {\n                throw new Error('Cannot peek from a negative offset in a stream');\n            }\n        }\n        if (normOptions.length > 0) {\n            try {\n                bytesRead = await this.streamReader.peek(uint8Array, normOptions.offset, normOptions.length);\n            }\n            catch (err) {\n                if (options && options.mayBeLess && err instanceof peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError) {\n                    return 0;\n                }\n                throw err;\n            }\n            if ((!normOptions.mayBeLess) && bytesRead < normOptions.length) {\n                throw new peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError();\n            }\n        }\n        return bytesRead;\n    }\n    async ignore(length) {\n        // debug(`ignore ${this.position}...${this.position + length - 1}`);\n        const bufSize = Math.min(maxBufferSize, length);\n        const buf = new Uint8Array(bufSize);\n        let totBytesRead = 0;\n        while (totBytesRead < length) {\n            const remaining = length - totBytesRead;\n            const bytesRead = await this.readBuffer(buf, { length: Math.min(bufSize, remaining) });\n            if (bytesRead < 0) {\n                return bytesRead;\n            }\n            totBytesRead += bytesRead;\n        }\n        return totBytesRead;\n    }\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/ReadStreamTokenizer.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/core.js":
/*!***************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/core.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* reexport safe */ peek_readable__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError),\n/* harmony export */   \"fromBuffer\": () => (/* binding */ fromBuffer),\n/* harmony export */   \"fromStream\": () => (/* binding */ fromStream)\n/* harmony export */ });\n/* harmony import */ var _ReadStreamTokenizer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ReadStreamTokenizer.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/ReadStreamTokenizer.js\");\n/* harmony import */ var _BufferTokenizer_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./BufferTokenizer.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/BufferTokenizer.js\");\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! peek-readable */ \"./node_modules/.pnpm/peek-readable@5.0.0/node_modules/peek-readable/lib/index.js\");\n\n\n\n/**\n * Construct ReadStreamTokenizer from given Stream.\n * Will set fileSize, if provided given Stream has set the .path property/\n * @param stream - Read from Node.js Stream.Readable\n * @param fileInfo - Pass the file information, like size and MIME-type of the corresponding stream.\n * @returns ReadStreamTokenizer\n */\nfunction fromStream(stream, fileInfo) {\n    fileInfo = fileInfo ? fileInfo : {};\n    return new _ReadStreamTokenizer_js__WEBPACK_IMPORTED_MODULE_0__.ReadStreamTokenizer(stream, fileInfo);\n}\n/**\n * Construct ReadStreamTokenizer from given Buffer.\n * @param uint8Array - Uint8Array to tokenize\n * @param fileInfo - Pass additional file information to the tokenizer\n * @returns BufferTokenizer\n */\nfunction fromBuffer(uint8Array, fileInfo) {\n    return new _BufferTokenizer_js__WEBPACK_IMPORTED_MODULE_1__.BufferTokenizer(uint8Array, fileInfo);\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/core.js?");

/***/ }),

/***/ "./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/index.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError),\n/* harmony export */   \"fromBuffer\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_1__.fromBuffer),\n/* harmony export */   \"fromFile\": () => (/* reexport safe */ _FileTokenizer_js__WEBPACK_IMPORTED_MODULE_2__.fromFile),\n/* harmony export */   \"fromStream\": () => (/* binding */ fromStream)\n/* harmony export */ });\n/* harmony import */ var _FsPromise_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./FsPromise.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FsPromise.js\");\n/* harmony import */ var _core_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./core.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/core.js\");\n/* harmony import */ var _FileTokenizer_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FileTokenizer.js */ \"./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/FileTokenizer.js\");\n\n\n\n\n/**\n * Construct ReadStreamTokenizer from given Stream.\n * Will set fileSize, if provided given Stream has set the .path property.\n * @param stream - Node.js Stream.Readable\n * @param fileInfo - Pass additional file information to the tokenizer\n * @returns Tokenizer\n */\nasync function fromStream(stream, fileInfo) {\n    fileInfo = fileInfo ? fileInfo : {};\n    if (stream.path) {\n        const stat = await _FsPromise_js__WEBPACK_IMPORTED_MODULE_0__.stat(stream.path);\n        fileInfo.path = stream.path;\n        fileInfo.size = stat.size;\n    }\n    return _core_js__WEBPACK_IMPORTED_MODULE_1__.fromStream(stream, fileInfo);\n}\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/strtok3@7.0.0/node_modules/strtok3/lib/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/token-types@5.0.1/node_modules/token-types/lib/index.js":
/*!************************************************************************************!*\
  !*** ./node_modules/.pnpm/token-types@5.0.1/node_modules/token-types/lib/index.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AnsiStringType\": () => (/* binding */ AnsiStringType),\n/* harmony export */   \"BufferType\": () => (/* binding */ BufferType),\n/* harmony export */   \"Float16_BE\": () => (/* binding */ Float16_BE),\n/* harmony export */   \"Float16_LE\": () => (/* binding */ Float16_LE),\n/* harmony export */   \"Float32_BE\": () => (/* binding */ Float32_BE),\n/* harmony export */   \"Float32_LE\": () => (/* binding */ Float32_LE),\n/* harmony export */   \"Float64_BE\": () => (/* binding */ Float64_BE),\n/* harmony export */   \"Float64_LE\": () => (/* binding */ Float64_LE),\n/* harmony export */   \"Float80_BE\": () => (/* binding */ Float80_BE),\n/* harmony export */   \"Float80_LE\": () => (/* binding */ Float80_LE),\n/* harmony export */   \"INT16_BE\": () => (/* binding */ INT16_BE),\n/* harmony export */   \"INT16_LE\": () => (/* binding */ INT16_LE),\n/* harmony export */   \"INT24_BE\": () => (/* binding */ INT24_BE),\n/* harmony export */   \"INT24_LE\": () => (/* binding */ INT24_LE),\n/* harmony export */   \"INT32_BE\": () => (/* binding */ INT32_BE),\n/* harmony export */   \"INT32_LE\": () => (/* binding */ INT32_LE),\n/* harmony export */   \"INT64_BE\": () => (/* binding */ INT64_BE),\n/* harmony export */   \"INT64_LE\": () => (/* binding */ INT64_LE),\n/* harmony export */   \"INT8\": () => (/* binding */ INT8),\n/* harmony export */   \"IgnoreType\": () => (/* binding */ IgnoreType),\n/* harmony export */   \"StringType\": () => (/* binding */ StringType),\n/* harmony export */   \"UINT16_BE\": () => (/* binding */ UINT16_BE),\n/* harmony export */   \"UINT16_LE\": () => (/* binding */ UINT16_LE),\n/* harmony export */   \"UINT24_BE\": () => (/* binding */ UINT24_BE),\n/* harmony export */   \"UINT24_LE\": () => (/* binding */ UINT24_LE),\n/* harmony export */   \"UINT32_BE\": () => (/* binding */ UINT32_BE),\n/* harmony export */   \"UINT32_LE\": () => (/* binding */ UINT32_LE),\n/* harmony export */   \"UINT64_BE\": () => (/* binding */ UINT64_BE),\n/* harmony export */   \"UINT64_LE\": () => (/* binding */ UINT64_LE),\n/* harmony export */   \"UINT8\": () => (/* binding */ UINT8),\n/* harmony export */   \"Uint8ArrayType\": () => (/* binding */ Uint8ArrayType)\n/* harmony export */ });\n/* harmony import */ var ieee754__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ieee754 */ \"./node_modules/.pnpm/ieee754@1.2.1/node_modules/ieee754/index.js\");\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n\n\n// Primitive types\nfunction dv(array) {\n    return new DataView(array.buffer, array.byteOffset);\n}\n/**\n * 8-bit unsigned integer\n */\nconst UINT8 = {\n    len: 1,\n    get(array, offset) {\n        return dv(array).getUint8(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint8(offset, value);\n        return offset + 1;\n    }\n};\n/**\n * 16-bit unsigned integer, Little Endian byte order\n */\nconst UINT16_LE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getUint16(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setUint16(offset, value, true);\n        return offset + 2;\n    }\n};\n/**\n * 16-bit unsigned integer, Big Endian byte order\n */\nconst UINT16_BE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getUint16(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint16(offset, value);\n        return offset + 2;\n    }\n};\n/**\n * 24-bit unsigned integer, Little Endian byte order\n */\nconst UINT24_LE = {\n    len: 3,\n    get(array, offset) {\n        const dataView = dv(array);\n        return dataView.getUint8(offset) + (dataView.getUint16(offset + 1, true) << 8);\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint8(offset, value & 0xff);\n        dataView.setUint16(offset + 1, value >> 8, true);\n        return offset + 3;\n    }\n};\n/**\n * 24-bit unsigned integer, Big Endian byte order\n */\nconst UINT24_BE = {\n    len: 3,\n    get(array, offset) {\n        const dataView = dv(array);\n        return (dataView.getUint16(offset) << 8) + dataView.getUint8(offset + 2);\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint16(offset, value >> 8);\n        dataView.setUint8(offset + 2, value & 0xff);\n        return offset + 3;\n    }\n};\n/**\n * 32-bit unsigned integer, Little Endian byte order\n */\nconst UINT32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getUint32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setUint32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * 32-bit unsigned integer, Big Endian byte order\n */\nconst UINT32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getUint32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * 8-bit signed integer\n */\nconst INT8 = {\n    len: 1,\n    get(array, offset) {\n        return dv(array).getInt8(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt8(offset, value);\n        return offset + 1;\n    }\n};\n/**\n * 16-bit signed integer, Big Endian byte order\n */\nconst INT16_BE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getInt16(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt16(offset, value);\n        return offset + 2;\n    }\n};\n/**\n * 16-bit signed integer, Little Endian byte order\n */\nconst INT16_LE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getInt16(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setInt16(offset, value, true);\n        return offset + 2;\n    }\n};\n/**\n * 24-bit signed integer, Little Endian byte order\n */\nconst INT24_LE = {\n    len: 3,\n    get(array, offset) {\n        const unsigned = UINT24_LE.get(array, offset);\n        return unsigned > 0x7fffff ? unsigned - 0x1000000 : unsigned;\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint8(offset, value & 0xff);\n        dataView.setUint16(offset + 1, value >> 8, true);\n        return offset + 3;\n    }\n};\n/**\n * 24-bit signed integer, Big Endian byte order\n */\nconst INT24_BE = {\n    len: 3,\n    get(array, offset) {\n        const unsigned = UINT24_BE.get(array, offset);\n        return unsigned > 0x7fffff ? unsigned - 0x1000000 : unsigned;\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint16(offset, value >> 8);\n        dataView.setUint8(offset + 2, value & 0xff);\n        return offset + 3;\n    }\n};\n/**\n * 32-bit signed integer, Big Endian byte order\n */\nconst INT32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getInt32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * 32-bit signed integer, Big Endian byte order\n */\nconst INT32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getInt32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setInt32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * 64-bit unsigned integer, Little Endian byte order\n */\nconst UINT64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigUint64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setBigUint64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit signed integer, Little Endian byte order\n */\nconst INT64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigInt64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setBigInt64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit unsigned integer, Big Endian byte order\n */\nconst UINT64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigUint64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setBigUint64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit signed integer, Big Endian byte order\n */\nconst INT64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigInt64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setBigInt64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 16-bit (half precision) float, big endian\n */\nconst Float16_BE = {\n    len: 2,\n    get(dataView, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(dataView, offset, false, 10, this.len);\n    },\n    put(dataView, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(dataView, value, offset, false, 10, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 16-bit (half precision) float, little endian\n */\nconst Float16_LE = {\n    len: 2,\n    get(array, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(array, offset, true, 10, this.len);\n    },\n    put(array, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(array, value, offset, true, 10, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 32-bit (single precision) float, big endian\n */\nconst Float32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getFloat32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * IEEE 754 32-bit (single precision) float, little endian\n */\nconst Float32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getFloat32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * IEEE 754 64-bit (double precision) float, big endian\n */\nconst Float64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getFloat64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 64-bit (double precision) float, little endian\n */\nconst Float64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getFloat64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 80-bit (extended precision) float, big endian\n */\nconst Float80_BE = {\n    len: 10,\n    get(array, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(array, offset, false, 63, this.len);\n    },\n    put(array, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(array, value, offset, false, 63, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 80-bit (extended precision) float, little endian\n */\nconst Float80_LE = {\n    len: 10,\n    get(array, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(array, offset, true, 63, this.len);\n    },\n    put(array, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(array, value, offset, true, 63, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * Ignore a given number of bytes\n */\nclass IgnoreType {\n    /**\n     * @param len number of bytes to ignore\n     */\n    constructor(len) {\n        this.len = len;\n    }\n    // ToDo: don't read, but skip data\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    get(array, off) {\n    }\n}\nclass Uint8ArrayType {\n    constructor(len) {\n        this.len = len;\n    }\n    get(array, offset) {\n        return array.subarray(offset, offset + this.len);\n    }\n}\nclass BufferType {\n    constructor(len) {\n        this.len = len;\n    }\n    get(uint8Array, off) {\n        return node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.from(uint8Array.subarray(off, off + this.len));\n    }\n}\n/**\n * Consume a fixed number of bytes from the stream and return a string with a specified encoding.\n */\nclass StringType {\n    constructor(len, encoding) {\n        this.len = len;\n        this.encoding = encoding;\n    }\n    get(uint8Array, offset) {\n        return node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.from(uint8Array).toString(this.encoding, offset, offset + this.len);\n    }\n}\n/**\n * ANSI Latin 1 String\n * Using windows-1252 / ISO 8859-1 decoding\n */\nclass AnsiStringType {\n    constructor(len) {\n        this.len = len;\n    }\n    static decode(buffer, offset, until) {\n        let str = '';\n        for (let i = offset; i < until; ++i) {\n            str += AnsiStringType.codePointToString(AnsiStringType.singleByteDecoder(buffer[i]));\n        }\n        return str;\n    }\n    static inRange(a, min, max) {\n        return min <= a && a <= max;\n    }\n    static codePointToString(cp) {\n        if (cp <= 0xFFFF) {\n            return String.fromCharCode(cp);\n        }\n        else {\n            cp -= 0x10000;\n            return String.fromCharCode((cp >> 10) + 0xD800, (cp & 0x3FF) + 0xDC00);\n        }\n    }\n    static singleByteDecoder(bite) {\n        if (AnsiStringType.inRange(bite, 0x00, 0x7F)) {\n            return bite;\n        }\n        const codePoint = AnsiStringType.windows1252[bite - 0x80];\n        if (codePoint === null) {\n            throw Error('invaliding encoding');\n        }\n        return codePoint;\n    }\n    get(buffer, offset = 0) {\n        return AnsiStringType.decode(buffer, offset, offset + this.len);\n    }\n}\nAnsiStringType.windows1252 = [8364, 129, 8218, 402, 8222, 8230, 8224, 8225, 710, 8240, 352,\n    8249, 338, 141, 381, 143, 144, 8216, 8217, 8220, 8221, 8226, 8211, 8212, 732,\n    8482, 353, 8250, 339, 157, 382, 376, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n    169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n    185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n    201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n    217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n    233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n    248, 249, 250, 251, 252, 253, 254, 255];\n\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/token-types@5.0.1/node_modules/token-types/lib/index.js?");

/***/ }),

/***/ "./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/package.json":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/package.json ***!
  \********************************************************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = JSON.parse('{\"name\":\"seek-bzip\",\"version\":\"1.0.6\",\"contributors\":[\"C. Scott Ananian (http://cscott.net)\",\"Eli Skeggs\",\"Kevin Kwok\",\"Rob Landley (http://landley.net)\"],\"description\":\"a pure-JavaScript Node.JS module for random-access decoding bzip2 data\",\"main\":\"./lib/index.js\",\"repository\":{\"type\":\"git\",\"url\":\"https://github.com/cscott/seek-bzip.git\"},\"license\":\"MIT\",\"bin\":{\"seek-bunzip\":\"./bin/seek-bunzip\",\"seek-table\":\"./bin/seek-bzip-table\"},\"directories\":{\"test\":\"test\"},\"dependencies\":{\"commander\":\"^2.8.1\"},\"devDependencies\":{\"fibers\":\"~1.0.6\",\"mocha\":\"~2.2.5\"},\"scripts\":{\"test\":\"mocha\"}}');\n\n//# sourceURL=webpack://extract-xd/./node_modules/.pnpm/seek-bzip@1.0.6/node_modules/seek-bzip/package.json?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/create fake namespace object */
/******/ 	(() => {
/******/ 		var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);
/******/ 		var leafPrototypes;
/******/ 		// create a fake namespace object
/******/ 		// mode & 1: value is a module id, require it
/******/ 		// mode & 2: merge all properties of value into the ns
/******/ 		// mode & 4: return value when already ns object
/******/ 		// mode & 16: return value when it's Promise-like
/******/ 		// mode & 8|1: behave like require
/******/ 		__webpack_require__.t = function(value, mode) {
/******/ 			if(mode & 1) value = this(value);
/******/ 			if(mode & 8) return value;
/******/ 			if(typeof value === 'object' && value) {
/******/ 				if((mode & 4) && value.__esModule) return value;
/******/ 				if((mode & 16) && typeof value.then === 'function') return value;
/******/ 			}
/******/ 			var ns = Object.create(null);
/******/ 			__webpack_require__.r(ns);
/******/ 			var def = {};
/******/ 			leafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];
/******/ 			for(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {
/******/ 				Object.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));
/******/ 			}
/******/ 			def['default'] = () => (value);
/******/ 			__webpack_require__.d(ns, def);
/******/ 			return ns;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./index.ts");
/******/ 	
/******/ })()
;